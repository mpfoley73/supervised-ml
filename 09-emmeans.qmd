```{r}
#| include: false

library(tidyverse)
library(tidymodels)
library(gtsummary)
library(janitor)
```

# Estimated Marginal Means {#EMMs}

Estimated marginal means (EMMs) are the mean predicted values for a specified combination of predictor values. Whereas ordinary marginal means are conditional means of the raw data, EMMs are conditional means of _modeled_ data. Use the `emmeans` package to calculate EMMs.

```{r}
library(emmeans)
```

Let's work with the `mtcars` dataset. Suppose you are interested in `mpg` as the outcome variable and are exploring differences in levels of factor variable, `cyl`. Your model will control for factor variable, `gear`, and continuous variable, `disp`. 

```{r}
#| code-fold: false

my_cars <- 
  mtcars |>
  mutate(across(c(cyl, gear), factor)) |>
  select(mpg, cyl, gear, disp)
```

```{r}
#| code-fold: true

gtsummary::tbl_summary(
  my_cars,
  by = cyl,
  statistic = list(all_continuous() ~ "{mean}, {sd}"),
  digits = all_continuous() ~ 1
) |>
  add_overall() |>
  modify_header(label ~ "**Variable**") |>
  modify_spanning_header(c("stat_1", "stat_2", "stat_3") ~ "**cyl**") |>
  as_gt() |>
  gt::tab_header(title = "Summary Statistics")
```

We'll fit two models to illustrate how emmeans work: an intercept-only model and the full model.

```{r}
#| code-fold: false

fit_intercept <- 
  linear_reg() |>
  fit(mpg ~ 1, data = my_cars) |>
  extract_fit_engine()

fit_full <-
  linear_reg() |>
  fit(mpg ~ cyl + disp + gear, data = my_cars) |>
  extract_fit_engine()
```

```{r}
#| code-fold: true

gt_intercept <-
  tbl_regression(fit_intercept, intercept = TRUE, conf.int = FALSE) |>
  gtsummary::add_significance_stars(hide_se = TRUE)

gt_full <-
  tbl_regression(fit_full, intercept = TRUE, conf.int = FALSE) |>
  gtsummary::add_significance_stars(hide_se = TRUE)

tbl_merge(
  list(gt_intercept, gt_full),
  tab_spanner = c("**Intercept**", "**Full Model**")
) |>
  as_gt() |>
  gt::fmt_number(decimals = 3) |>
  gt::tab_header(title = "Regression summary")
```

Controlling for `disp` an `gear`, relative to reference level `cyl4`,  `cyl6` reduces expected `mpg` by 4.800 mpg while `cyl8` reduces it slightly more, but without statistical significance at the .05 level. One way to interpret the fit is by calculating the expected value at a set of predictor variable levels. You might fix `disp` at the dataset average, and take the combinations of levels in `cyl` and `gear`. That's nine combinations of predictors. 

```{r}
#| code-fold: false

newdata <- expand.grid(
  cyl = levels(my_cars$cyl), 
  disp = mean(my_cars$disp),
  gear = levels(my_cars$gear)
)

(my_preds <- augment(fit_full, newdata = newdata))
```

The estimated marginal mean is the mean of `my_preds$.fitted`, `r comma(mean(my_preds$.fitted), .01)`. This prediction dataset (reference grid) is what `emmeans()` uses by default. `emmeans()` makes predictions across a _reference grid_, then averages the predictions by the `specs` setting. As bonus, you get the confidence interval around the expected value. Set `specs = "1"` to predict the mean over the grid.

```{r}
#| code-fold: false

emmeans(fit_full, specs = "1")
```

You can see the reference grid or create a new one using `ref_grid()`.

```{r}
#| code-fold: false

ref_grid(fit_full)
```

Instead of averaging _over_ the levels of `cyl`, you can average _by_ each level.
 
```{r}
#| code-fold: false

(emm_cyl <- emmeans(fit_full, specs = "cyl"))
```

## Level Comparisons

### Pairwise

Calculate EMM pairwise differences with `pairs()`.

```{r}
#| code-fold: false

emmeans(fit_full, specs = "cyl") |>
  pairs()
```

Cohen's *d* effect size standardizes the differences by dividing by the model residual standard error. An effect size over .8 is large, .5 medium, and .2 small. The 95% CI crosses zero, so there may be no measurable effects here.

```{r}
#| code-fold: false

emmeans(fit_full, specs = "cyl") |> 
  eff_size(sigma = sigma(fit_full), edf = df.residual(fit_full))
```

### One vs Whole

Instead of comparing groups to each other, you might compare groups to the *whole* using a contrast. The default is to subtract the grand mean, the mean of the three EMMs, `r comma(mean(tidy(emm_cyl)$estimate), .001)`, from each EMM.

```{r}
#| code-fold: false

emmeans(fit_full, specs = "cyl") |> 
  contrast()
```

If group sizes are imbalanced, as they are here, subtract the *weighted* grand mean. The population sizes are `4` = 11, `6` = 7, `8` = 14, so the weighted grand mean is `r emm_cyl |> tidy() |> mutate(estimate = estimate * case_match(cyl, "4"~11/32, "6"~7/32, "8"~14/32)) |> pull(estimate) |> sum() |> comma(.01)`.

```{r}
#| code-fold: false

emmeans(fit_full, specs = "cyl") |> 
  contrast(wts = NA)
```

### One vs Others

The contrast shows how each leave relates to the whole. That feels strange because each level biases the whole toward its value. Instead, you can create a contrast that shows how each level relates to the other levels. The estimates below are each EMM minus the average of the other EMMs. The EMM for `cyl=4` was `r comma(tidy(emm_cyl)$estimate[1], .001)`. The average of the other two EMMs was `mean c(18.2, 21.5)` = `r comma(mean(tidy(emm_cyl)$estimate[2:3]), .001)`.

```{r}
#| code-fold: false

emmeans(fit_full, specs = "cyl") |> 
  contrast("del.eff")
```

The expected `mpg` of a car with `cyl=4` is 4.83 mpg higher than the average expected value of the other `cyl` levels. You can uses a weighted average instead with `wts = NA`.

## Nuisance Variables

By "expected", we specifically mean the _average predicted value across the reference grid_. Our grid includes the mean `disp` and the three levels of `gear`.

```{r}
#| code-fold: false

ref_grid(fit_full)
```

So the EMMs are averaging over 9 predictions:

```{r}
#| code-fold: false

ref_grid(fit_full) |> tidy()
```

That's great except that `gear` is kind of a nuisance. It would be preferable to predict on the "average" `gear`, just like we predicted on the average `disp`. Well, you can! Recall that models one-hot encode factor variables, so you get `gear3 = 0|1`, `gear4 = 0|1`, and `gear5 = 0|1`. What if instead of three combinations you predicted on `gear3=1/3`, `gear4=1/3`, and `gear5=1/3`?

```{r}
#| code-fold: false

(nuis_grid_0 <- ref_grid(fit_full, nuisance = "gear"))
```

Now we have just three predictions. Each estimate below uses the simple average of the three `gear` levels above.

```{r}
#| code-fold: false

tidy(nuis_grid_0)
```

This is closer to the "typical" car, but we can do even better by weighting the levels proportionally to their frequency (`gear3=15/32`, `gear4=12/32`, and `gear5=5/32`).

```{r}
#| code-fold: false

nuis_grid <- ref_grid(fit_full, nuisance = "gear", wt.nuis = "proportional")

tidy(nuis_grid)
```

Now the one vs others contrast is more like the "average" car, varying only the number of cylinders. Recall, the default is to weight the other two EMMs equally, and `wts = NA` weights them by `cyl` count.

```{r}
#| code-fold: false

emmeans(nuis_grid, specs = "cyl") |>
  contrast("del.eff", wts = NA) |> 
  tidy()
```

So the expected value of `cyl4` is 4.837 mpg greater than the weighted average of the other `cyl` levels.

## Reporting EMM + Contrast

Sometimes reporting model coefficients suffers from lack of context. The model fit coefficient for `cyl6` indicates it reduces the expected `mpg` by 4.800 relative to `cyl4`. That's less useful if you don't have a baseline `mpg` to compare 4.800 to. Instead, you might report that a 'representative' (mediod?) car, that is, a car with a proportional mix of all modeled car attributes, has an expected `mpg` of 20.091 (intercept-only model) and the effect of fixing `cyl = 4` is to increase this expected value by 3.174 to 23.265, and fixing `cyl = 6` decreases it 1.625 to 18.465. 

```{r}
#| code-fold: false

emmeans(nuis_grid, specs = "cyl") |> contrast(wts = NA) |> tidy()
```

We can report this in a single row.

```{r}
#| code-fold: true

contrast_color <- function(bg) {
  if_else(colorspace::contrast_ratio(bg, "black") > 
            colorspace::contrast_ratio(bg, "white"),
          "black", "white")
}

smry <- 
  bind_rows(
    ref_grid(fit_full, nuisance = c("cyl", "gear"), wt.nuis = "proportional") |> 
      emmeans(specs = "1") |> tidy() |> rename(contrast = `1`),
    emmeans(nuis_grid, specs = "cyl") |> contrast(wts = NA) |> tidy()
  ) |>
  select(contrast, estimate, adj.p.value) |>
  mutate(contrast = fct_relevel(contrast, "overall", after = 0)) |>
  arrange(contrast) |>
  mutate(
    pct = estimate / first(estimate),
    bg = case_when(
      adj.p.value < .05 & estimate < 0 ~ "firebrick",
      adj.p.value < .05 & estimate > 0 ~ "dodgerblue",
      TRUE ~ "white"
    ),
    color = contrast_color(bg)
  )

smry |>
  select(contrast, estimate) |>
  mutate(contrast = str_remove(contrast, " effect")) |>
  pivot_wider(names_from = contrast, values_from = estimate) |>
  gt::gt() |>
  gt::fmt_number(decimals = 3) |>
  gt::tab_spanner("Effect", columns = 2:3) |>
  gt::tab_header(title = "Effect of gender on estimated marginal means.") |>
  gt::tab_options(heading.align = "left") |>
  gt::tab_style(
    style = gt::cell_fill("firebrick"),
    locations = gt::cells_body(columns = which(smry$bg == "firebrick"))
  ) |>
  gt::tab_style(
    style = gt::cell_fill("dodgerblue"),
    locations = gt::cells_body(columns = which(smry$bg == "dodgerblue"))
  ) |>
  gt::tab_style(
    style = gt::cell_text("white"),
    locations = gt::cells_body(columns = which(smry$color == "white"))
  ) |>
  gt::tab_style(
    style = gt::cell_text("black"),
    locations = gt::cells_body(columns = which(smry$color == "black"))
  )
```

## Learn More

This [Very statisticious](https://aosmith.rbind.io/2019/03/25/getting-started-with-emmeans/) blog post is helpful. I also worked through the **emmeans** vignettes on [CRAN](https://cran.r-project.org/web/packages/emmeans/) and **ggeffects** on [GitHub](https://strengejacke.github.io/ggeffects/index.html).
