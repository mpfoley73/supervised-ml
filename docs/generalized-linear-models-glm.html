<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 2 Generalized Linear Models (GLM) | Supervised Machine Learning</title>
  <meta name="description" content="These are my personal notes related to supervised machine learning techniques." />
  <meta name="generator" content="bookdown 0.36 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 2 Generalized Linear Models (GLM) | Supervised Machine Learning" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="These are my personal notes related to supervised machine learning techniques." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 2 Generalized Linear Models (GLM) | Supervised Machine Learning" />
  
  <meta name="twitter:description" content="These are my personal notes related to supervised machine learning techniques." />
  

<meta name="author" content="Michael Foley" />


<meta name="date" content="2024-01-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="ordinary-least-squares.html"/>
<link rel="next" href="mixed-effects-models.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet" />
<script src="libs/tabwid-1.1.3/tabwid.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>
<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Supervised Machine Learning</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Intro</a></li>
<li class="chapter" data-level="1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html"><i class="fa fa-check"></i><b>1</b> Ordinary Least Squares</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#parameter-estimation"><i class="fa fa-check"></i><b>1.1</b> Parameter Estimation</a>
<ul>
<li class="chapter" data-level="" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#example"><i class="fa fa-check"></i>Example</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#model-assumptions"><i class="fa fa-check"></i><b>1.2</b> Model Assumptions</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#multicollinearity"><i class="fa fa-check"></i><b>1.2.1</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#prediction"><i class="fa fa-check"></i><b>1.3</b> Prediction</a></li>
<li class="chapter" data-level="1.4" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#inference"><i class="fa fa-check"></i><b>1.4</b> Inference</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#t-test"><i class="fa fa-check"></i><b>1.4.1</b> <em>t</em>-Test</a></li>
<li class="chapter" data-level="1.4.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#f-test"><i class="fa fa-check"></i><b>1.4.2</b> <em>F</em>-Test</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#interpretation"><i class="fa fa-check"></i><b>1.5</b> Interpretation</a></li>
<li class="chapter" data-level="1.6" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#model-validation"><i class="fa fa-check"></i><b>1.6</b> Model Validation</a>
<ul>
<li class="chapter" data-level="1.6.1" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#accuracy-metrics"><i class="fa fa-check"></i><b>1.6.1</b> Accuracy Metrics</a></li>
<li class="chapter" data-level="1.6.2" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#r-squared"><i class="fa fa-check"></i><b>1.6.2</b> R-Squared</a></li>
<li class="chapter" data-level="1.6.3" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#cross-validation"><i class="fa fa-check"></i><b>1.6.3</b> Cross-Validation</a></li>
<li class="chapter" data-level="1.6.4" data-path="ordinary-least-squares.html"><a href="ordinary-least-squares.html#gain-curve"><i class="fa fa-check"></i><b>1.6.4</b> Gain Curve</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html"><i class="fa fa-check"></i><b>2</b> Generalized Linear Models (GLM)</a>
<ul>
<li class="chapter" data-level="2.1" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#binomiallogistic"><i class="fa fa-check"></i><b>2.1</b> Binomial Logistic Regression</a>
<ul>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#cs1"><i class="fa fa-check"></i>Case Study</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#fit-the-model"><i class="fa fa-check"></i>Fit the Model</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#interpretation-1"><i class="fa fa-check"></i>Interpretation</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#assumptions"><i class="fa fa-check"></i>Assumptions</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#evaluate-the-fit"><i class="fa fa-check"></i>Evaluate the Fit</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#reporting"><i class="fa fa-check"></i>Reporting</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#multinomiallogistic"><i class="fa fa-check"></i><b>2.2</b> Multinomial Logistic Regression</a>
<ul>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#cs2"><i class="fa fa-check"></i>Case Study</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#fit-the-model-1"><i class="fa fa-check"></i>Fit the Model</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#interpretation-2"><i class="fa fa-check"></i>Interpretation</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#assumptions-1"><i class="fa fa-check"></i>Assumptions</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#evaluate-the-fit-1"><i class="fa fa-check"></i>Evaluate the Fit</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#reporting-1"><i class="fa fa-check"></i>Reporting</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#ordinallogistic"><i class="fa fa-check"></i><b>2.3</b> Ordinal Logistic Regression</a>
<ul>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#cs3"><i class="fa fa-check"></i>Case Study</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#fit-the-model-2"><i class="fa fa-check"></i>Fit the Model</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#assumptions-2"><i class="fa fa-check"></i>Assumptions</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#evaluate-the-fit-2"><i class="fa fa-check"></i>Evaluate the Fit</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#interpret-results"><i class="fa fa-check"></i>Interpret Results</a></li>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#reporting-2"><i class="fa fa-check"></i>Reporting</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#poissonregression"><i class="fa fa-check"></i><b>2.4</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="" data-path="generalized-linear-models-glm.html"><a href="generalized-linear-models-glm.html#cs4"><i class="fa fa-check"></i>Case Study 4</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html"><i class="fa fa-check"></i><b>3</b> Mixed Effects Models</a>
<ul>
<li class="chapter" data-level="3.1" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#lme"><i class="fa fa-check"></i><b>3.1</b> Linear Mixed Effects</a>
<ul>
<li class="chapter" data-level="" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#lme1"><i class="fa fa-check"></i>Case Study</a></li>
<li class="chapter" data-level="" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#fit-the-model-3"><i class="fa fa-check"></i>Fit the Model</a></li>
<li class="chapter" data-level="" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#interpretation-3"><i class="fa fa-check"></i>Interpretation</a></li>
<li class="chapter" data-level="" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#model-assumptions-1"><i class="fa fa-check"></i>Model Assumptions</a></li>
<li class="chapter" data-level="" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#evaluate-the-fit-3"><i class="fa fa-check"></i>Evaluate the Fit</a></li>
<li class="chapter" data-level="" data-path="mixed-effects-models.html"><a href="mixed-effects-models.html#reporting-3"><i class="fa fa-check"></i>Reporting</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="non-linear-models.html"><a href="non-linear-models.html"><i class="fa fa-check"></i><b>4</b> Non-linear Models</a>
<ul>
<li class="chapter" data-level="4.1" data-path="non-linear-models.html"><a href="non-linear-models.html#splines"><i class="fa fa-check"></i><b>4.1</b> Splines</a></li>
<li class="chapter" data-level="4.2" data-path="non-linear-models.html"><a href="non-linear-models.html#mars"><i class="fa fa-check"></i><b>4.2</b> MARS</a></li>
<li class="chapter" data-level="4.3" data-path="non-linear-models.html"><a href="non-linear-models.html#gam"><i class="fa fa-check"></i><b>4.3</b> GAM</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="regularization.html"><a href="regularization.html"><i class="fa fa-check"></i><b>5</b> Regularization</a>
<ul>
<li class="chapter" data-level="5.1" data-path="regularization.html"><a href="regularization.html#ridge"><i class="fa fa-check"></i><b>5.1</b> Ridge</a></li>
<li class="chapter" data-level="5.2" data-path="regularization.html"><a href="regularization.html#lasso"><i class="fa fa-check"></i><b>5.2</b> Lasso</a></li>
<li class="chapter" data-level="5.3" data-path="regularization.html"><a href="regularization.html#elastic-net"><i class="fa fa-check"></i><b>5.3</b> Elastic Net</a></li>
<li class="chapter" data-level="" data-path="regularization.html"><a href="regularization.html#model-summary"><i class="fa fa-check"></i>Model Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="decision-trees.html"><a href="decision-trees.html"><i class="fa fa-check"></i><b>6</b> Decision Trees</a>
<ul>
<li class="chapter" data-level="6.1" data-path="decision-trees.html"><a href="decision-trees.html#classification-tree"><i class="fa fa-check"></i><b>6.1</b> Classification Tree</a>
<ul>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#measuring-performance"><i class="fa fa-check"></i>Measuring Performance</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="decision-trees.html"><a href="decision-trees.html#regression-tree"><i class="fa fa-check"></i><b>6.2</b> Regression Tree</a>
<ul>
<li class="chapter" data-level="" data-path="decision-trees.html"><a href="decision-trees.html#measuring-performance-1"><i class="fa fa-check"></i>Measuring Performance</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="decision-trees.html"><a href="decision-trees.html#bagged-trees"><i class="fa fa-check"></i><b>6.3</b> Bagged Trees</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="decision-trees.html"><a href="decision-trees.html#bagged-classification-tree"><i class="fa fa-check"></i><b>6.3.1</b> Bagged Classification Tree</a></li>
<li class="chapter" data-level="6.3.2" data-path="decision-trees.html"><a href="decision-trees.html#bagging-regression-tree"><i class="fa fa-check"></i><b>6.3.2</b> Bagging Regression Tree</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="decision-trees.html"><a href="decision-trees.html#random-forests"><i class="fa fa-check"></i><b>6.4</b> Random Forests</a></li>
<li class="chapter" data-level="6.5" data-path="decision-trees.html"><a href="decision-trees.html#gradient-boosting"><i class="fa fa-check"></i><b>6.5</b> Gradient Boosting</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="support-vector-machines.html"><a href="support-vector-machines.html"><i class="fa fa-check"></i><b>7</b> Support Vector Machines</a>
<ul>
<li class="chapter" data-level="7.1" data-path="support-vector-machines.html"><a href="support-vector-machines.html#maximal-margin-classifier"><i class="fa fa-check"></i><b>7.1</b> Maximal Margin Classifier</a></li>
<li class="chapter" data-level="7.2" data-path="support-vector-machines.html"><a href="support-vector-machines.html#support-vector-classifier"><i class="fa fa-check"></i><b>7.2</b> Support Vector Classifier</a></li>
<li class="chapter" data-level="7.3" data-path="support-vector-machines.html"><a href="support-vector-machines.html#support-vector-machines-1"><i class="fa fa-check"></i><b>7.3</b> Support Vector Machines</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="BayesRegression.html"><a href="BayesRegression.html"><i class="fa fa-check"></i><b>8</b> Bayesian Regression</a>
<ul>
<li class="chapter" data-level="8.1" data-path="BayesRegression.html"><a href="BayesRegression.html#compared-to-frequentist-regression"><i class="fa fa-check"></i><b>8.1</b> Compared to Frequentist Regression</a></li>
<li class="chapter" data-level="8.2" data-path="BayesRegression.html"><a href="BayesRegression.html#model-evaluation"><i class="fa fa-check"></i><b>8.2</b> Model Evaluation</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="BayesRegression.html"><a href="BayesRegression.html#model-comparison"><i class="fa fa-check"></i><b>8.2.1</b> Model Comparison</a></li>
<li class="chapter" data-level="8.2.2" data-path="BayesRegression.html"><a href="BayesRegression.html#visualization"><i class="fa fa-check"></i><b>8.2.2</b> Visualization</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="EMMs.html"><a href="EMMs.html"><i class="fa fa-check"></i><b>9</b> Estimated Marginal Means</a>
<ul>
<li class="chapter" data-level="9.1" data-path="EMMs.html"><a href="EMMs.html#references"><i class="fa fa-check"></i><b>9.1</b> References</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references-1.html"><a href="references-1.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Supervised Machine Learning</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="generalized-linear-models-glm" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Chapter 2</span> Generalized Linear Models (GLM)<a href="generalized-linear-models-glm.html#generalized-linear-models-glm" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The linear regression model, <span class="math inline">\(E(y|X) = X \beta\)</span>, structured as <span class="math inline">\(y_i = X_i \beta + \epsilon_i\)</span> where <span class="math inline">\(X_i \beta = \mu_i\)</span>, assumes the response is a linear function of the predictors and the residuals are independent random variables normally distributed with zero mean and constant variance, <span class="math inline">\(\epsilon \sim N \left(0, \sigma^2 \right)\)</span>. This implies that given a set of predictors, the response is normally distributed about its expected value, <span class="math inline">\(y_i \sim N \left(\mu_i, \sigma^2 \right)\)</span>. However, there are many situations where this normality assumption does not hold. Generalized linear models (GLMs) are a generalization of the linear regression model that work with non-normal response distributions.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p>
<p>The response will not have a normal distribution if the underlying data-generating process is binomial (Section <a href="generalized-linear-models-glm.html#binomiallogistic">2.1</a>) or multinomial (Section <a href="generalized-linear-models-glm.html#multinomiallogistic">2.2</a>), ordinal (Section <a href="generalized-linear-models-glm.html#ordinallogistic">2.3</a>), Poisson (counts, Section <a href="generalized-linear-models-glm.html#poissonregression">2.4</a>), or exponential (time-to-event). In these situations the linear regression model can predict probabilities and proportions outside [0, 1], or negative counts or times. GLMs solve this problem by modeling a <em>function</em> of the expected value of <span class="math inline">\(y\)</span>, <span class="math inline">\(f(E(y|X)) = X \beta\)</span>. There are three components to a GLM: a <em>random component</em> specified by the response variable’s probability distribution (normal, binomial, etc.); a <em>systematic component</em> in the form <span class="math inline">\(X\beta\)</span>; and a <em>link function</em>, <span class="math inline">\(\eta\)</span>, that specifies the link between the random and systematic components and converts the response to a range of <span class="math inline">\([-\infty, +\infty]\)</span>.</p>
<p>Linear regression is a special case of GLM where the link function is the identity function, <span class="math inline">\(f(E(y|X)) = E(y|X)\)</span>. For binary logistic regression, the link function is the logit,</p>
<p><span class="math display">\[f(E(y|X)) = \log \left( \frac{E(y|X)}{1 - E(y|X)} \right) = \log \left( \frac{\pi}{1 - \pi} \right) = \mathrm{logit}(\pi)\]</span></p>
<p>where <span class="math inline">\(\pi\)</span> is the response probability.<a href="#fn5" class="footnote-ref" id="fnref5"><sup>5</sup></a> For multinomial logistic regression, the link function is the logit again, but with respect to the baseline level, and there is set of logits (one for each non-baseline level),</p>
<p><span class="math display">\[f(E(y|X)) = \log \left( \frac{E(y_j|X)}{E(y_{j^*}|X)} \right) = \log \left( \frac{\pi_j}{\pi_{j^*}} \right) = \mathrm{logit}(\pi_j)\]</span></p>
<p>Where <span class="math inline">\(j\)</span> is a level in the dependent variable and <span class="math inline">\(j^*\)</span> is the baseline level. For Poisson regression, the link function is</p>
<p><span class="math display">\[f(E(y|X)) = \ln (E(y|X)) = \ln(\lambda)\]</span></p>
<p>where <span class="math inline">\(\lambda\)</span> is the expected event rate. For exponential regression, the link function is</p>
<p><span class="math display">\[f(E(y|X) = -E(y|X) = -\lambda\]</span></p>
<p>where <span class="math inline">\(\lambda\)</span> is the expected time to event.</p>
<p>GLM uses maximum likelihood estimation (MLE) rather than ordinary least squares (OLS) to estimate the parameters, and thus relies on large-sample approximations.</p>
<p>Fit a GLM just like an linear model, but with the <code>glm()</code> function, specifying the distribution with the <code>family = c("gaussian", "binomial", "poisson")</code> parameter. Fit a mulinomial logistic regression model with <code>nnet::multinom()</code>.</p>
<div id="binomiallogistic" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Binomial Logistic Regression<a href="generalized-linear-models-glm.html#binomiallogistic" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Logistic regression estimates the probability that a categorical dependent variable is a particular level. The dependent variable levels can be binomial, multinomial, or ordinal. The <em>binary</em> logistic regression model is</p>
<p><span class="math display">\[y_i = \mathrm{logit}(\pi_i) = \log \left( \frac{\pi_i}{1 - \pi_i} \right) = X_i \beta\]</span></p>
<p>where <span class="math inline">\(\pi_i\)</span> is the response <span class="math inline">\(i\)</span>’s binary level probability. The model predicts the <em>log odds</em> of the level. Why do this? The range of outcomes need to be between 0 and 1, and a sigmoid function, <span class="math inline">\(f(y) = 1 / \left(1 + e^y \right)\)</span>, does that. If the <em>log odds</em> of the level equals <span class="math inline">\(X_i\beta\)</span>, then the <em>odds</em> of the level equals <span class="math inline">\(e^{X\beta}\)</span>. You can solve for <span class="math inline">\(\pi_i\)</span> to get <span class="math inline">\(\pi = \mathrm{odds} / (\mathrm{odds} + 1)\)</span>. Substituting,</p>
<p><span class="math display">\[\pi_i = \frac{\exp(y_i)}{1 + \exp(y_i)} = \frac{e^{X_i\beta}}{1 + e^{X_i\beta}}\]</span></p>
<p>which you can simplify to <span class="math inline">\(\pi_i = 1 / (1 + e^{-X_i\beta})\)</span>, a sigmoid function. The upshot is <span class="math inline">\(X\beta\)</span> is the functional relationship between the independent variables and <em>a function of the response</em>, not the response itself.</p>
<p>The model parameters are estimated either by <em>iteratively reweighted least squares optimization</em> or by <em>maximum likelihood estimation</em> (MLE). MLE maximizes the probability produced by a set of parameters <span class="math inline">\(\beta\)</span> given a data set and probability distribution.<a href="#fn6" class="footnote-ref" id="fnref6"><sup>6</sup></a> In logistic regression the probability distribution is the binomial and each observation is the outcome of a single Bernoulli trial.</p>
<p><span class="math display">\[L(\beta; y, X) = \prod_{i=1}^n \pi_i^{y_i}(1 - \pi_i)^{(1-y_i)} = \prod_{i=1}^n\frac{\exp(y_i X_i \beta)}{1 + \exp(X_i \beta)}.\]</span></p>
<p>In practice, multiplying many small probabilities can be unstable, so MLE optimizes the log likelihood instead.</p>
<p><span class="math display">\[\begin{align}
l(\beta; y, X) &amp;= \sum_{i = 1}^n \left(y_i \log(\pi_i) + (1 - y_i) \log(1 - \pi_i) \right) \\
               &amp;= \sum_{i = 1}^n \left(y_i X_i \beta - \log(1 + e^{X_i\beta}) \right)
\end{align}\]</span></p>
<p>Sometimes you will see the <em>cost function</em> optimized. The cost function is the negative of of the log likelihood function.</p>
<p><strong>Assumptions</strong></p>
<p>The binomial logistic regression model requires a dichotomous dependent variable and independent observations. The sample size should be large, at least 10 observations per dependent variable level and independent variable. There are three conditions related to the data distribution: i) the logit transformation must be linearly related to any continuous independent variables, ii) there must be no multicollinearity, and iii) there must be no influential outliers.</p>
<p>Be aware of over-dispersion, a common issue with GLM. For a binomial logistic regression, the response variable should be distributed <span class="math inline">\(y_i \sim \mathrm{Bin}(n_i, \pi_i)\)</span> with <span class="math inline">\(\mu_i = n_i \pi_i\)</span> and <span class="math inline">\(\sigma^2 = \pi (1 - \pi)\)</span>. Over-dispersion means the data shows evidence of variance greater than <span class="math inline">\(\sigma^2\)</span>.</p>
<div id="cs1" class="section level3 unnumbered hasAnchor">
<h3>Case Study<a href="generalized-linear-models-glm.html#cs1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This case study uses the <a href="https://statistics.laerd.com/">Laerd Statistics</a> article on binomial logistic regression <a href="https://statistics.laerd.com/premium/spss/spss-files/logistic-regression.sav">data set</a>. A study investigates the relationship between the incidence of heart disease (Yes|No) and age, weight, gender, and maximal aerobic capacity using data from <em>n</em> = 100 participants.</p>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="generalized-linear-models-glm.html#cb74-1" tabindex="-1"></a>cs1 <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb74-2"><a href="generalized-linear-models-glm.html#cb74-2" tabindex="-1"></a></span>
<span id="cb74-3"><a href="generalized-linear-models-glm.html#cb74-3" tabindex="-1"></a>cs1<span class="sc">$</span>dat <span class="ot">&lt;-</span> foreign<span class="sc">::</span><span class="fu">read.spss</span>(<span class="st">&quot;./input/logistic-regression.sav&quot;</span>, <span class="at">to.data.frame =</span> <span class="cn">TRUE</span>)</span>
<span id="cb74-4"><a href="generalized-linear-models-glm.html#cb74-4" tabindex="-1"></a></span>
<span id="cb74-5"><a href="generalized-linear-models-glm.html#cb74-5" tabindex="-1"></a>cs1<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb74-6"><a href="generalized-linear-models-glm.html#cb74-6" tabindex="-1"></a>  gtsummary<span class="sc">::</span><span class="fu">tbl_summary</span>(</span>
<span id="cb74-7"><a href="generalized-linear-models-glm.html#cb74-7" tabindex="-1"></a>    <span class="at">by =</span> heart_disease,</span>
<span id="cb74-8"><a href="generalized-linear-models-glm.html#cb74-8" tabindex="-1"></a>    <span class="at">include =</span> <span class="sc">-</span>caseno,</span>
<span id="cb74-9"><a href="generalized-linear-models-glm.html#cb74-9" tabindex="-1"></a>    <span class="at">percent =</span> <span class="st">&quot;row&quot;</span>,</span>
<span id="cb74-10"><a href="generalized-linear-models-glm.html#cb74-10" tabindex="-1"></a>    <span class="at">statistic =</span> <span class="fu">list</span>(gtsummary<span class="sc">::</span><span class="fu">all_continuous</span>() <span class="sc">~</span> <span class="st">&quot;{mean}, {sd}&quot;</span>)</span>
<span id="cb74-11"><a href="generalized-linear-models-glm.html#cb74-11" tabindex="-1"></a>  )</span></code></pre></div>
<div id="fybehlmray" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#fybehlmray table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#fybehlmray thead, #fybehlmray tbody, #fybehlmray tfoot, #fybehlmray tr, #fybehlmray td, #fybehlmray th {
  border-style: none;
}

#fybehlmray p {
  margin: 0;
  padding: 0;
}

#fybehlmray .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#fybehlmray .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#fybehlmray .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#fybehlmray .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#fybehlmray .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#fybehlmray .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#fybehlmray .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#fybehlmray .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#fybehlmray .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#fybehlmray .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#fybehlmray .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#fybehlmray .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#fybehlmray .gt_spanner_row {
  border-bottom-style: hidden;
}

#fybehlmray .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#fybehlmray .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#fybehlmray .gt_from_md > :first-child {
  margin-top: 0;
}

#fybehlmray .gt_from_md > :last-child {
  margin-bottom: 0;
}

#fybehlmray .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#fybehlmray .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#fybehlmray .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#fybehlmray .gt_row_group_first td {
  border-top-width: 2px;
}

#fybehlmray .gt_row_group_first th {
  border-top-width: 2px;
}

#fybehlmray .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#fybehlmray .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#fybehlmray .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#fybehlmray .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#fybehlmray .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#fybehlmray .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#fybehlmray .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#fybehlmray .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#fybehlmray .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#fybehlmray .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#fybehlmray .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#fybehlmray .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#fybehlmray .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#fybehlmray .gt_left {
  text-align: left;
}

#fybehlmray .gt_center {
  text-align: center;
}

#fybehlmray .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#fybehlmray .gt_font_normal {
  font-weight: normal;
}

#fybehlmray .gt_font_bold {
  font-weight: bold;
}

#fybehlmray .gt_font_italic {
  font-style: italic;
}

#fybehlmray .gt_super {
  font-size: 65%;
}

#fybehlmray .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#fybehlmray .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#fybehlmray .gt_indent_1 {
  text-indent: 5px;
}

#fybehlmray .gt_indent_2 {
  text-indent: 10px;
}

#fybehlmray .gt_indent_3 {
  text-indent: 15px;
}

#fybehlmray .gt_indent_4 {
  text-indent: 20px;
}

#fybehlmray .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Characteristic&lt;/strong&gt;"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;No&lt;/strong&gt;, N = 65&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>No</strong>, N = 65<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Yes&lt;/strong&gt;, N = 35&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>Yes</strong>, N = 35<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="label" class="gt_row gt_left">age</td>
<td headers="stat_1" class="gt_row gt_center">39, 8</td>
<td headers="stat_2" class="gt_row gt_center">45, 9</td></tr>
    <tr><td headers="label" class="gt_row gt_left">weight</td>
<td headers="stat_1" class="gt_row gt_center">77, 14</td>
<td headers="stat_2" class="gt_row gt_center">85, 15</td></tr>
    <tr><td headers="label" class="gt_row gt_left">gender</td>
<td headers="stat_1" class="gt_row gt_center"><br /></td>
<td headers="stat_2" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Female</td>
<td headers="stat_1" class="gt_row gt_center">29 (78%)</td>
<td headers="stat_2" class="gt_row gt_center">8 (22%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Male</td>
<td headers="stat_1" class="gt_row gt_center">36 (57%)</td>
<td headers="stat_2" class="gt_row gt_center">27 (43%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">VO2max</td>
<td headers="stat_1" class="gt_row gt_center">45, 9</td>
<td headers="stat_2" class="gt_row gt_center">41, 6</td></tr>
  </tbody>
  
  <tfoot class="gt_footnotes">
    <tr>
      <td class="gt_footnote" colspan="3"><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span> Mean, SD; n (%)</td>
    </tr>
  </tfoot>
</table>
</div>
<p><br></p>
<p>Overall, men are twice as likely to have heart disease. Male odds are .43/.57 = 0.8 and female odds are .22/.78 = 0.3, an male-to-female odds ratio of 2.7.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="generalized-linear-models-glm.html#cb75-1" tabindex="-1"></a>cs1<span class="sc">$</span>dat <span class="sc">%&gt;%</span> gtsummary<span class="sc">::</span><span class="fu">tbl_cross</span>(<span class="at">row =</span> heart_disease, <span class="at">col =</span> gender, <span class="at">percent =</span> <span class="st">&quot;col&quot;</span>) </span></code></pre></div>
<div id="tvynywchpl" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#tvynywchpl table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#tvynywchpl thead, #tvynywchpl tbody, #tvynywchpl tfoot, #tvynywchpl tr, #tvynywchpl td, #tvynywchpl th {
  border-style: none;
}

#tvynywchpl p {
  margin: 0;
  padding: 0;
}

#tvynywchpl .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#tvynywchpl .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#tvynywchpl .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#tvynywchpl .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#tvynywchpl .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#tvynywchpl .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tvynywchpl .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#tvynywchpl .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#tvynywchpl .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#tvynywchpl .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#tvynywchpl .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#tvynywchpl .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#tvynywchpl .gt_spanner_row {
  border-bottom-style: hidden;
}

#tvynywchpl .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#tvynywchpl .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#tvynywchpl .gt_from_md > :first-child {
  margin-top: 0;
}

#tvynywchpl .gt_from_md > :last-child {
  margin-bottom: 0;
}

#tvynywchpl .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#tvynywchpl .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#tvynywchpl .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#tvynywchpl .gt_row_group_first td {
  border-top-width: 2px;
}

#tvynywchpl .gt_row_group_first th {
  border-top-width: 2px;
}

#tvynywchpl .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#tvynywchpl .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#tvynywchpl .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#tvynywchpl .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tvynywchpl .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#tvynywchpl .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#tvynywchpl .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#tvynywchpl .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#tvynywchpl .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tvynywchpl .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#tvynywchpl .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#tvynywchpl .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#tvynywchpl .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#tvynywchpl .gt_left {
  text-align: left;
}

#tvynywchpl .gt_center {
  text-align: center;
}

#tvynywchpl .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#tvynywchpl .gt_font_normal {
  font-weight: normal;
}

#tvynywchpl .gt_font_bold {
  font-weight: bold;
}

#tvynywchpl .gt_font_italic {
  font-style: italic;
}

#tvynywchpl .gt_super {
  font-size: 65%;
}

#tvynywchpl .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#tvynywchpl .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#tvynywchpl .gt_indent_1 {
  text-indent: 5px;
}

#tvynywchpl .gt_indent_2 {
  text-indent: 10px;
}

#tvynywchpl .gt_indent_3 {
  text-indent: 15px;
}

#tvynywchpl .gt_indent_4 {
  text-indent: 20px;
}

#tvynywchpl .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    
    <tr class="gt_col_headings gt_spanner_row">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="2" colspan="1" scope="col" id=""></th>
      <th class="gt_center gt_columns_top_border gt_column_spanner_outer" rowspan="1" colspan="2" scope="colgroup" id="gender">
        <span class="gt_column_spanner">gender</span>
      </th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="2" colspan="1" scope="col" id="Total">Total</th>
    </tr>
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="Female">Female</th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="Male">Male</th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="label" class="gt_row gt_left">heart_disease</td>
<td headers="stat_1" class="gt_row gt_center"><br /></td>
<td headers="stat_2" class="gt_row gt_center"><br /></td>
<td headers="stat_0" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    No</td>
<td headers="stat_1" class="gt_row gt_center">29 (78%)</td>
<td headers="stat_2" class="gt_row gt_center">36 (57%)</td>
<td headers="stat_0" class="gt_row gt_center">65 (65%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Yes</td>
<td headers="stat_1" class="gt_row gt_center">8 (22%)</td>
<td headers="stat_2" class="gt_row gt_center">27 (43%)</td>
<td headers="stat_0" class="gt_row gt_center">35 (35%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">Total</td>
<td headers="stat_1" class="gt_row gt_center">37 (100%)</td>
<td headers="stat_2" class="gt_row gt_center">63 (100%)</td>
<td headers="stat_0" class="gt_row gt_center">100 (100%)</td></tr>
  </tbody>
  
  
</table>
</div>
<p>Age, weight, and poor max aerobic capacity are positively associated with heart disease.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="generalized-linear-models-glm.html#cb76-1" tabindex="-1"></a>cs1<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb76-2"><a href="generalized-linear-models-glm.html#cb76-2" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(age, weight, VO2max)) <span class="sc">%&gt;%</span></span>
<span id="cb76-3"><a href="generalized-linear-models-glm.html#cb76-3" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> heart_disease, <span class="at">y =</span> value)) <span class="sc">+</span> </span>
<span id="cb76-4"><a href="generalized-linear-models-glm.html#cb76-4" tabindex="-1"></a>  <span class="fu">geom_boxplot</span>(<span class="at">outlier.shape =</span> <span class="cn">NA</span>) <span class="sc">+</span></span>
<span id="cb76-5"><a href="generalized-linear-models-glm.html#cb76-5" tabindex="-1"></a>  <span class="fu">geom_jitter</span>(<span class="fu">aes</span>(<span class="at">color =</span> name)) <span class="sc">+</span></span>
<span id="cb76-6"><a href="generalized-linear-models-glm.html#cb76-6" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="at">facets =</span> <span class="fu">vars</span>(name), <span class="at">scales =</span> <span class="st">&quot;free_y&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-54-1.png" width="672" /></p>
<div class="rmdnote">
<p>Consider centering the continuous variables around their means to facilitate model interpretation. The intercept term in the fitted model would represent a reasonable condition, not a zero-aged, zero-weighted person with no aerobic capacity. This is the way to go if you want to present your findings in the framework of a baseline probability (or odds) and the incremental effects of the independent variables. You might also standardize the continuous vars to get a more meaningful increment. On the other hand, if you want to use your model for predicting outcomes, you’ll have to back out of the centering when you predict values.</p>
</div>
<p>If your model is predictive rather than inferential, split the data into training/testing data sets.</p>
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="generalized-linear-models-glm.html#cb77-1" tabindex="-1"></a><span class="co"># For reproducibility</span></span>
<span id="cb77-2"><a href="generalized-linear-models-glm.html#cb77-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb77-3"><a href="generalized-linear-models-glm.html#cb77-3" tabindex="-1"></a></span>
<span id="cb77-4"><a href="generalized-linear-models-glm.html#cb77-4" tabindex="-1"></a>(x <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(cs1<span class="sc">$</span>dat, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> heart_disease))</span>
<span id="cb77-5"><a href="generalized-linear-models-glm.html#cb77-5" tabindex="-1"></a><span class="do">## &lt;Training/Testing/Total&gt;</span></span>
<span id="cb77-6"><a href="generalized-linear-models-glm.html#cb77-6" tabindex="-1"></a><span class="do">## &lt;69/31/100&gt;</span></span>
<span id="cb77-7"><a href="generalized-linear-models-glm.html#cb77-7" tabindex="-1"></a></span>
<span id="cb77-8"><a href="generalized-linear-models-glm.html#cb77-8" tabindex="-1"></a>cs1<span class="sc">$</span>dat_training <span class="ot">&lt;-</span> <span class="fu">training</span>(x)</span>
<span id="cb77-9"><a href="generalized-linear-models-glm.html#cb77-9" tabindex="-1"></a><span class="fu">dim</span>(cs1<span class="sc">$</span>dat_training)</span>
<span id="cb77-10"><a href="generalized-linear-models-glm.html#cb77-10" tabindex="-1"></a><span class="do">## [1] 69  6</span></span>
<span id="cb77-11"><a href="generalized-linear-models-glm.html#cb77-11" tabindex="-1"></a></span>
<span id="cb77-12"><a href="generalized-linear-models-glm.html#cb77-12" tabindex="-1"></a>cs1<span class="sc">$</span>dat_testing <span class="ot">&lt;-</span> <span class="fu">testing</span>(x)</span>
<span id="cb77-13"><a href="generalized-linear-models-glm.html#cb77-13" tabindex="-1"></a><span class="fu">dim</span>(cs1<span class="sc">$</span>dat_testing)</span>
<span id="cb77-14"><a href="generalized-linear-models-glm.html#cb77-14" tabindex="-1"></a><span class="do">## [1] 31  6</span></span></code></pre></div>
</div>
<div id="fit-the-model" class="section level3 unnumbered hasAnchor">
<h3>Fit the Model<a href="generalized-linear-models-glm.html#fit-the-model" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Fit the model using the tidymodels framework. If you want to continue using the classic methodology, the glm object is inside the tidymodels fit. The model fit returns a brief summary with the coefficients and model diagnostics.</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="generalized-linear-models-glm.html#cb78-1" tabindex="-1"></a>cs1<span class="sc">$</span>model <span class="ot">&lt;-</span> </span>
<span id="cb78-2"><a href="generalized-linear-models-glm.html#cb78-2" tabindex="-1"></a>  <span class="fu">logistic_reg</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb78-3"><a href="generalized-linear-models-glm.html#cb78-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glm&quot;</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb78-4"><a href="generalized-linear-models-glm.html#cb78-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) </span>
<span id="cb78-5"><a href="generalized-linear-models-glm.html#cb78-5" tabindex="-1"></a></span>
<span id="cb78-6"><a href="generalized-linear-models-glm.html#cb78-6" tabindex="-1"></a>cs1<span class="sc">$</span>fit <span class="ot">&lt;-</span></span>
<span id="cb78-7"><a href="generalized-linear-models-glm.html#cb78-7" tabindex="-1"></a>  cs1<span class="sc">$</span>model <span class="sc">%&gt;%</span></span>
<span id="cb78-8"><a href="generalized-linear-models-glm.html#cb78-8" tabindex="-1"></a>  <span class="fu">fit</span>(heart_disease <span class="sc">~</span> age <span class="sc">+</span> weight <span class="sc">+</span> VO2max <span class="sc">+</span> gender, <span class="at">data =</span> cs1<span class="sc">$</span>dat)</span>
<span id="cb78-9"><a href="generalized-linear-models-glm.html#cb78-9" tabindex="-1"></a></span>
<span id="cb78-10"><a href="generalized-linear-models-glm.html#cb78-10" tabindex="-1"></a><span class="co"># The fit object returned by glm(). You&#39;ll need this for interpretation and </span></span>
<span id="cb78-11"><a href="generalized-linear-models-glm.html#cb78-11" tabindex="-1"></a><span class="co"># checking assumptions.</span></span>
<span id="cb78-12"><a href="generalized-linear-models-glm.html#cb78-12" tabindex="-1"></a>cs1<span class="sc">$</span>result <span class="ot">&lt;-</span></span>
<span id="cb78-13"><a href="generalized-linear-models-glm.html#cb78-13" tabindex="-1"></a>  cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span></span>
<span id="cb78-14"><a href="generalized-linear-models-glm.html#cb78-14" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>()</span>
<span id="cb78-15"><a href="generalized-linear-models-glm.html#cb78-15" tabindex="-1"></a></span>
<span id="cb78-16"><a href="generalized-linear-models-glm.html#cb78-16" tabindex="-1"></a><span class="co"># If you are fitting a predictive model, use the training set.</span></span>
<span id="cb78-17"><a href="generalized-linear-models-glm.html#cb78-17" tabindex="-1"></a>cs1<span class="sc">$</span>fit_training <span class="ot">&lt;-</span></span>
<span id="cb78-18"><a href="generalized-linear-models-glm.html#cb78-18" tabindex="-1"></a>  cs1<span class="sc">$</span>model <span class="sc">%&gt;%</span></span>
<span id="cb78-19"><a href="generalized-linear-models-glm.html#cb78-19" tabindex="-1"></a>  <span class="fu">fit</span>(heart_disease <span class="sc">~</span> age <span class="sc">+</span> weight <span class="sc">+</span> VO2max <span class="sc">+</span> gender, <span class="at">data =</span> cs1<span class="sc">$</span>dat_training)</span>
<span id="cb78-20"><a href="generalized-linear-models-glm.html#cb78-20" tabindex="-1"></a></span>
<span id="cb78-21"><a href="generalized-linear-models-glm.html#cb78-21" tabindex="-1"></a>cs1<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## 
## Call:
## stats::glm(formula = heart_disease ~ age + weight + VO2max + 
##     gender, family = stats::binomial, data = data)
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -1.676469   3.336079  -0.503  0.61530   
## age          0.085098   0.028160   3.022  0.00251 **
## weight       0.005727   0.022442   0.255  0.79858   
## VO2max      -0.099024   0.047944  -2.065  0.03889 * 
## genderMale   1.949639   0.842413   2.314  0.02065 * 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## (Dispersion parameter for binomial family taken to be 1)
## 
##     Null deviance: 129.49  on 99  degrees of freedom
## Residual deviance: 102.09  on 95  degrees of freedom
## AIC: 112.09
## 
## Number of Fisher Scoring iterations: 5</code></pre>
<p>The null deviance, G^2, is the likelihood ratio of the intercept-only model with 69 rows - 1 parameter = 99 degrees of freedom. It is the sum of the squared deviance residuals. The residual deviance is the likelihood ratio of the full model with 100 - 5 parameters = 95 degrees of freedom.</p>
<p>The residual deviance is distributed chi-squared and can be used to test whether the model differs from the saturated model (model with as many coefficients as observations, G^2 = 0, <em>df</em> = 0) where <span class="math inline">\(H_0\)</span> = no difference. The deviance test for lack of fit fails to reject the null hypothesis.</p>
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="generalized-linear-models-glm.html#cb80-1" tabindex="-1"></a><span class="co"># G^2 calculations</span></span>
<span id="cb80-2"><a href="generalized-linear-models-glm.html#cb80-2" tabindex="-1"></a>cs1<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">residuals</span>(<span class="at">type =</span> <span class="st">&quot;deviance&quot;</span>) <span class="sc">%&gt;%</span> .<span class="sc">^</span><span class="dv">2</span> <span class="sc">%&gt;%</span> <span class="fu">sum</span>()</span>
<span id="cb80-3"><a href="generalized-linear-models-glm.html#cb80-3" tabindex="-1"></a><span class="do">## [1] 102.0878</span></span>
<span id="cb80-4"><a href="generalized-linear-models-glm.html#cb80-4" tabindex="-1"></a>cs1<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">deviance</span>()</span>
<span id="cb80-5"><a href="generalized-linear-models-glm.html#cb80-5" tabindex="-1"></a><span class="do">## [1] 102.0878</span></span>
<span id="cb80-6"><a href="generalized-linear-models-glm.html#cb80-6" tabindex="-1"></a></span>
<span id="cb80-7"><a href="generalized-linear-models-glm.html#cb80-7" tabindex="-1"></a><span class="co"># df</span></span>
<span id="cb80-8"><a href="generalized-linear-models-glm.html#cb80-8" tabindex="-1"></a><span class="fu">df.residual</span>(cs1<span class="sc">$</span>result)</span>
<span id="cb80-9"><a href="generalized-linear-models-glm.html#cb80-9" tabindex="-1"></a><span class="do">## [1] 95</span></span>
<span id="cb80-10"><a href="generalized-linear-models-glm.html#cb80-10" tabindex="-1"></a></span>
<span id="cb80-11"><a href="generalized-linear-models-glm.html#cb80-11" tabindex="-1"></a><span class="co"># G^2 is distributed chi-squared with df degrees of freedom</span></span>
<span id="cb80-12"><a href="generalized-linear-models-glm.html#cb80-12" tabindex="-1"></a><span class="fu">pchisq</span>(<span class="fu">deviance</span>(cs1<span class="sc">$</span>result), <span class="at">df =</span> <span class="fu">df.residual</span>(cs1<span class="sc">$</span>result), <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb80-13"><a href="generalized-linear-models-glm.html#cb80-13" tabindex="-1"></a><span class="do">## [1] 0.2911469</span></span>
<span id="cb80-14"><a href="generalized-linear-models-glm.html#cb80-14" tabindex="-1"></a>vcdExtra<span class="sc">::</span><span class="fu">LRstats</span>(cs1<span class="sc">$</span>result)</span>
<span id="cb80-15"><a href="generalized-linear-models-glm.html#cb80-15" tabindex="-1"></a><span class="do">## Likelihood summary table:</span></span>
<span id="cb80-16"><a href="generalized-linear-models-glm.html#cb80-16" tabindex="-1"></a><span class="do">##               AIC    BIC LR Chisq Df Pr(&gt;Chisq)</span></span>
<span id="cb80-17"><a href="generalized-linear-models-glm.html#cb80-17" tabindex="-1"></a><span class="do">## cs1$result 112.09 125.11   102.09 95     0.2911</span></span></code></pre></div>
<p>These two deviances, the null and residual, are shown in the ANOVA summary. An ANOVA table shows the change in deviance from successively adding each variable to the model.</p>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="generalized-linear-models-glm.html#cb81-1" tabindex="-1"></a><span class="fu">anova</span>(cs1<span class="sc">$</span>result)</span></code></pre></div>
<pre><code>## Analysis of Deviance Table
## 
## Model: binomial, link: logit
## 
## Response: heart_disease
## 
## Terms added sequentially (first to last)
## 
## 
##        Df Deviance Resid. Df Resid. Dev
## NULL                      99     129.49
## age     1  11.9074        98     117.58
## weight  1   9.1820        97     108.40
## VO2max  1   0.5045        96     107.89
## gender  1   5.8076        95     102.09</code></pre>
<p>Deviance residuals are one of four residuals you can calculate from a binary logistic regression.<a href="#fn7" class="footnote-ref" id="fnref7"><sup>7</sup></a> One is the <em>raw residual</em>, <span class="math inline">\(\epsilon_i = y_i - \hat{p}_i\)</span>, where <span class="math inline">\(\hat{p}_i\)</span> is the predicted probability. Another is the <em>Pearson residual</em>, <span class="math inline">\(r_i = \frac{\epsilon_i}{\sqrt{\hat{p}_i(1 - \hat{p}_i)}}\)</span>, the raw residual rescaled by dividing by the estimated standard deviation of a binomial distribution with 1 trial<a href="#fn8" class="footnote-ref" id="fnref8"><sup>8</sup></a>. A third is the <em>standardized Pearson residual</em>, <span class="math inline">\(rs_i = r_i / \sqrt{1 - \hat{h}_i}\)</span>, the Pearson residual adjusted for the leverage of the predictors using the hat-values. Hat-values measure the predictor distances from the mean. This residual is especially useful to evaluate model fit because if the model fits well, these residuals have a standard normal distribution. Finally, there are the <em>deviance residuals</em>, <span class="math inline">\(d_i = \mathrm{sign}(\epsilon_i) \left[ -2(y_i \log \hat{p}_i + (1 - y_i) \log (1 - \hat{p}_i)) \right]^{.5}\)</span>. Deviance Residuals measure how much the estimated probabilities differ from the observed proportions of success. You want deviance residuals to be evenly distributed (in absolute values, 1Q <span class="math inline">\(\approx\)</span> 3Q, min <span class="math inline">\(\approx\)</span> max). You also want the min and max to be &lt;3 because deviance residuals are roughly approximated by a standard normal distribution.</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="generalized-linear-models-glm.html#cb83-1" tabindex="-1"></a><span class="fu">bind_rows</span>(</span>
<span id="cb83-2"><a href="generalized-linear-models-glm.html#cb83-2" tabindex="-1"></a>  <span class="at">Raw =</span> cs1<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">residuals</span>(<span class="at">type =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">summary</span>(),</span>
<span id="cb83-3"><a href="generalized-linear-models-glm.html#cb83-3" tabindex="-1"></a>  <span class="at">Pearson =</span> cs1<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">residuals</span>(<span class="at">type =</span> <span class="st">&quot;pearson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">summary</span>(),</span>
<span id="cb83-4"><a href="generalized-linear-models-glm.html#cb83-4" tabindex="-1"></a>  <span class="st">`</span><span class="at">Standardized Pearson</span><span class="st">`</span> <span class="ot">=</span> cs1<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">rstandard</span>(<span class="at">type =</span> <span class="st">&quot;pearson&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">summary</span>(),</span>
<span id="cb83-5"><a href="generalized-linear-models-glm.html#cb83-5" tabindex="-1"></a>  <span class="at">Deviance =</span> cs1<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">residuals</span>(<span class="at">type =</span> <span class="st">&quot;deviance&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">summary</span>(),</span>
<span id="cb83-6"><a href="generalized-linear-models-glm.html#cb83-6" tabindex="-1"></a>  <span class="at">.id =</span> <span class="st">&quot;Residual&quot;</span></span>
<span id="cb83-7"><a href="generalized-linear-models-glm.html#cb83-7" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## # A tibble: 4 × 7
##   Residual             Min.        `1st Qu.`   Median      Mean  `3rd Qu.` Max. 
##   &lt;chr&gt;                &lt;table[1d]&gt; &lt;table[1d]&gt; &lt;table[1d]&gt; &lt;tab&gt; &lt;table[1&gt; &lt;tab&gt;
## 1 Raw                  -0.7954587  -0.2500077  -0.1061849  -8.0… 0.3532839 0.91…
## 2 Pearson              -1.9720520  -0.5773622  -0.3446596  -1.8… 0.7391867 3.34…
## 3 Standardized Pearson -2.1794172  -0.5918874  -0.3521058  -2.1… 0.7592960 3.39…
## 4 Deviance             -1.7815642  -0.7585405  -0.4738051  -8.0… 0.9336278 2.23…</code></pre>
</div>
<div id="interpretation-1" class="section level3 unnumbered hasAnchor">
<h3>Interpretation<a href="generalized-linear-models-glm.html#interpretation-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Before we look at the coefficient estimations, consider what it is they are predicting: the log odds of the binary response. To see what that means, plug in values for the explanatory variables to get predictions. <span class="math inline">\(\hat{y}\)</span> is the log odds of having heart disease.</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="generalized-linear-models-glm.html#cb85-1" tabindex="-1"></a>(mean_person <span class="ot">&lt;-</span> </span>
<span id="cb85-2"><a href="generalized-linear-models-glm.html#cb85-2" tabindex="-1"></a>  cs1<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb85-3"><a href="generalized-linear-models-glm.html#cb85-3" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>caseno) <span class="sc">%&gt;%</span></span>
<span id="cb85-4"><a href="generalized-linear-models-glm.html#cb85-4" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">.by =</span> gender, <span class="fu">across</span>(<span class="fu">where</span>(is.numeric), mean)))</span>
<span id="cb85-5"><a href="generalized-linear-models-glm.html#cb85-5" tabindex="-1"></a><span class="do">##   gender      age   weight   VO2max</span></span>
<span id="cb85-6"><a href="generalized-linear-models-glm.html#cb85-6" tabindex="-1"></a><span class="do">## 1   Male 40.79365 84.83270 46.40095</span></span>
<span id="cb85-7"><a href="generalized-linear-models-glm.html#cb85-7" tabindex="-1"></a><span class="do">## 2 Female 41.62162 70.85324 38.91135</span></span>
<span id="cb85-8"><a href="generalized-linear-models-glm.html#cb85-8" tabindex="-1"></a></span>
<span id="cb85-9"><a href="generalized-linear-models-glm.html#cb85-9" tabindex="-1"></a>pred_log_odds <span class="ot">&lt;-</span> cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span> <span class="fu">predict</span>(<span class="at">new_data =</span> mean_person, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span>
<span id="cb85-10"><a href="generalized-linear-models-glm.html#cb85-10" tabindex="-1"></a><span class="fu">names</span>(pred_log_odds) <span class="ot">&lt;-</span> mean_person<span class="sc">$</span>gender</span>
<span id="cb85-11"><a href="generalized-linear-models-glm.html#cb85-11" tabindex="-1"></a>pred_log_odds</span>
<span id="cb85-12"><a href="generalized-linear-models-glm.html#cb85-12" tabindex="-1"></a><span class="do">##       Male     Female </span></span>
<span id="cb85-13"><a href="generalized-linear-models-glm.html#cb85-13" tabindex="-1"></a><span class="do">## -0.3643411 -1.5819310</span></span></code></pre></div>
<p>Exponentiate to get the <strong>odds</strong>, <span class="math inline">\(\exp (\hat{y}) = \frac{\pi}{1 - \pi}\)</span>.</p>
<div class="sourceCode" id="cb86"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb86-1"><a href="generalized-linear-models-glm.html#cb86-1" tabindex="-1"></a>(pred_odds <span class="ot">&lt;-</span> <span class="fu">exp</span>(pred_log_odds))</span></code></pre></div>
<pre><code>##      Male    Female 
## 0.6946542 0.2055777</code></pre>
<p>Solve for <span class="math inline">\(\pi = \frac{\exp (\hat{y})}{1 + \exp (\hat{y})}\)</span> to get the <strong>probability</strong>. Do the math, or use <code>predict(type = "prob")</code>.</p>
<div class="sourceCode" id="cb88"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb88-1"><a href="generalized-linear-models-glm.html#cb88-1" tabindex="-1"></a>(pred_prob <span class="ot">&lt;-</span> pred_odds <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> pred_odds))</span>
<span id="cb88-2"><a href="generalized-linear-models-glm.html#cb88-2" tabindex="-1"></a><span class="do">##      Male    Female </span></span>
<span id="cb88-3"><a href="generalized-linear-models-glm.html#cb88-3" tabindex="-1"></a><span class="do">## 0.4099091 0.1705222</span></span>
<span id="cb88-4"><a href="generalized-linear-models-glm.html#cb88-4" tabindex="-1"></a>cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span> <span class="fu">predict</span>(<span class="at">new_data =</span> mean_person, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb88-5"><a href="generalized-linear-models-glm.html#cb88-5" tabindex="-1"></a><span class="do">## # A tibble: 2 × 2</span></span>
<span id="cb88-6"><a href="generalized-linear-models-glm.html#cb88-6" tabindex="-1"></a><span class="do">##   .pred_No .pred_Yes</span></span>
<span id="cb88-7"><a href="generalized-linear-models-glm.html#cb88-7" tabindex="-1"></a><span class="do">##      &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb88-8"><a href="generalized-linear-models-glm.html#cb88-8" tabindex="-1"></a><span class="do">## 1    0.590     0.410</span></span>
<span id="cb88-9"><a href="generalized-linear-models-glm.html#cb88-9" tabindex="-1"></a><span class="do">## 2    0.829     0.171</span></span></code></pre></div>
<p>Now let’s interpret the coefficients.</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="generalized-linear-models-glm.html#cb89-1" tabindex="-1"></a>cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 5 × 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept) -1.68       3.34      -0.503 0.615  
## 2 age          0.0851     0.0282     3.02  0.00251
## 3 weight       0.00573    0.0224     0.255 0.799  
## 4 VO2max      -0.0990     0.0479    -2.07  0.0389 
## 5 genderMale   1.95       0.842      2.31  0.0206</code></pre>
<p>The intercept term is the log-odds of heart disease for the reference case. The reference case in the model is <code>gender</code> = “Female”, <code>age</code> = 0, <code>weight</code> = 0, and <code>VO2max</code> = 0. If the data was centered, the reference case would actually meaningful.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="generalized-linear-models-glm.html#cb91-1" tabindex="-1"></a>cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span></span>
<span id="cb91-2"><a href="generalized-linear-models-glm.html#cb91-2" tabindex="-1"></a>  <span class="fu">predict</span>(<span class="at">new_data =</span> <span class="fu">list</span>(<span class="at">age =</span> <span class="dv">0</span>, <span class="at">weight =</span> <span class="dv">0</span>, <span class="at">VO2max =</span> <span class="dv">0</span>, <span class="at">gender =</span> <span class="st">&quot;Female&quot;</span>), </span>
<span id="cb91-3"><a href="generalized-linear-models-glm.html#cb91-3" tabindex="-1"></a>          <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>)</span></code></pre></div>
<pre><code>##         1 
## -1.676469</code></pre>
<p>Column “statistic” is the Wald <span class="math inline">\(z\)</span> statistic, <span class="math inline">\(z = \hat{\beta} / SE(\hat{\beta})\)</span>. Its square is the Wald chi-squared statistic. The <em>p</em>-value is the area to the right of <span class="math inline">\(z^2\)</span> in the <span class="math inline">\(\chi_1^2\)</span> density curve:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="generalized-linear-models-glm.html#cb93-1" tabindex="-1"></a>cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span> </span>
<span id="cb93-2"><a href="generalized-linear-models-glm.html#cb93-2" tabindex="-1"></a>  <span class="fu">tidy</span>() <span class="sc">%&gt;%</span></span>
<span id="cb93-3"><a href="generalized-linear-models-glm.html#cb93-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">p.chisq =</span> <span class="fu">map_dbl</span>(statistic, <span class="sc">~</span><span class="fu">pchisq</span>(.<span class="sc">^</span><span class="dv">2</span>, <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb93-4"><a href="generalized-linear-models-glm.html#cb93-4" tabindex="-1"></a>  <span class="fu">pull</span>(p.chisq)</span></code></pre></div>
<pre><code>## [1] 0.615297092 0.002511644 0.798578389 0.038885956 0.020648470</code></pre>
<p>Interpret the coefficient estimates as the change in the log odds of <span class="math inline">\(y\)</span> due to a one unit change in <span class="math inline">\(x\)</span>. If <span class="math inline">\(\delta = x_a - x_b\)</span>, then a <span class="math inline">\(\delta\)</span> change in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\delta \hat{\beta}\)</span> change in the log odds of <span class="math inline">\(y\)</span>. <span class="math inline">\(\beta\)</span> is the log odds ratio of <span class="math inline">\(x_a\)</span> vs <span class="math inline">\(x_b\)</span>.</p>
<p><span class="math display">\[\log \left(\pi / (1 - \pi) |_{x = x_a} \right) - \log \left(\pi / (1 - \pi) |_{x = x_b} \right) = \log \left( \frac{\pi / (1 - \pi) |_{x = x_a}}{\pi / (1 - \pi) |_{x = x_b}} \right) = \delta \hat{\beta}\]</span></p>
<p>The <em>exponential</em> of the coefficient estimates is the change in the <em>odds</em> of <span class="math inline">\(y\)</span> due to a <span class="math inline">\(\delta\)</span> change in <span class="math inline">\(x\)</span>. <span class="math inline">\(\exp \beta\)</span> is the odds ratio of <span class="math inline">\(x_a\)</span> vs <span class="math inline">\(x_b\)</span>.</p>
<p><span class="math display">\[\mathrm{odds}(y) = e^{\delta \hat{\beta}}\]</span></p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="generalized-linear-models-glm.html#cb95-1" tabindex="-1"></a>cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span> <span class="fu">tidy</span>(<span class="at">exponentiate =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## # A tibble: 5 × 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept)    0.187    3.34      -0.503 0.615  
## 2 age            1.09     0.0282     3.02  0.00251
## 3 weight         1.01     0.0224     0.255 0.799  
## 4 VO2max         0.906    0.0479    -2.07  0.0389 
## 5 genderMale     7.03     0.842      2.31  0.0206</code></pre>
<p>All covariates held equal, a male’s log odds of heart disease are 1.95 times that of a female’s (log(OR)). A male’s odds are 7.03 times that of a female’s (OR). Of course, all covariate’s are <em>not</em> equal - males are heavier and have higher VO2max. Let’s run the calculations with the mean predictor values for male and female.</p>
<div class="sourceCode" id="cb97"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb97-1"><a href="generalized-linear-models-glm.html#cb97-1" tabindex="-1"></a><span class="co"># Log OR</span></span>
<span id="cb97-2"><a href="generalized-linear-models-glm.html#cb97-2" tabindex="-1"></a>pred_log_odds[<span class="st">&quot;Male&quot;</span>] <span class="sc">/</span> pred_log_odds[<span class="st">&quot;Female&quot;</span>]</span>
<span id="cb97-3"><a href="generalized-linear-models-glm.html#cb97-3" tabindex="-1"></a><span class="do">##      Male </span></span>
<span id="cb97-4"><a href="generalized-linear-models-glm.html#cb97-4" tabindex="-1"></a><span class="do">## 0.2303142</span></span>
<span id="cb97-5"><a href="generalized-linear-models-glm.html#cb97-5" tabindex="-1"></a></span>
<span id="cb97-6"><a href="generalized-linear-models-glm.html#cb97-6" tabindex="-1"></a><span class="co"># OR</span></span>
<span id="cb97-7"><a href="generalized-linear-models-glm.html#cb97-7" tabindex="-1"></a>pred_odds[<span class="st">&quot;Male&quot;</span>] <span class="sc">/</span> pred_odds[<span class="st">&quot;Female&quot;</span>]</span>
<span id="cb97-8"><a href="generalized-linear-models-glm.html#cb97-8" tabindex="-1"></a><span class="do">##     Male </span></span>
<span id="cb97-9"><a href="generalized-linear-models-glm.html#cb97-9" tabindex="-1"></a><span class="do">## 3.379034</span></span></code></pre></div>
<p>A one-unit increase in any of the continuous independent variables is interpreted similarly. The reference level is unimportant since the change is constant across the range of values. A one year increase in age increases the log-odds of heart disease by a factor of 0.09, and the odds by a factor of 1.09. To calculate the effect of a <em>decade</em> increase in age, multiply <span class="math inline">\(\beta\)</span> by 10 before exponentiating, or raise the exponentiated coeficient by 10. The effect of a 10-year increase in age is to increase the odds of heart disease by 2.34. The odds double every ten years.</p>
<p><code>oddsratio::or_glm()</code> is a handy way to calculate odds ratios from arbitrary increments to the predictors. Here are the ORs of a 10-year age change, 10 kg weight change, and VO2max change of 5.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="generalized-linear-models-glm.html#cb98-1" tabindex="-1"></a>oddsratio<span class="sc">::</span><span class="fu">or_glm</span>(</span>
<span id="cb98-2"><a href="generalized-linear-models-glm.html#cb98-2" tabindex="-1"></a>  cs1<span class="sc">$</span>dat, </span>
<span id="cb98-3"><a href="generalized-linear-models-glm.html#cb98-3" tabindex="-1"></a>  cs1<span class="sc">$</span>result, </span>
<span id="cb98-4"><a href="generalized-linear-models-glm.html#cb98-4" tabindex="-1"></a>  <span class="at">incr =</span> <span class="fu">list</span>(<span class="at">age =</span> <span class="dv">10</span>, <span class="at">weight =</span> <span class="dv">25</span>, <span class="at">VO2max =</span> <span class="sc">-</span><span class="dv">12</span>)</span>
<span id="cb98-5"><a href="generalized-linear-models-glm.html#cb98-5" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>##    predictor oddsratio ci_low (2.5) ci_high (97.5)          increment
## 1        age     2.342        1.391          4.270                 10
## 2     weight     1.154        0.381          3.572                 25
## 3     VO2max     3.281       11.033          1.124                -12
## 4 genderMale     7.026        1.428         40.155 Indicator variable</code></pre>
<p>Notice that the predicted probabilities have the sigmoidal shape of the binary relationship.</p>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="generalized-linear-models-glm.html#cb100-1" tabindex="-1"></a><span class="fu">augment</span>(cs1<span class="sc">$</span>fit, <span class="at">new_data =</span> cs1<span class="sc">$</span>dat, <span class="at">type =</span> <span class="st">&quot;raw&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb100-2"><a href="generalized-linear-models-glm.html#cb100-2" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> age, <span class="at">color =</span> gender)) <span class="sc">+</span></span>
<span id="cb100-3"><a href="generalized-linear-models-glm.html#cb100-3" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> <span class="fu">as.numeric</span>(heart_disease <span class="sc">==</span> <span class="st">&quot;Yes&quot;</span>))) <span class="sc">+</span></span>
<span id="cb100-4"><a href="generalized-linear-models-glm.html#cb100-4" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> .pred_Yes), <span class="at">shape =</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb100-5"><a href="generalized-linear-models-glm.html#cb100-5" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="fu">aes</span>(<span class="at">y =</span> .pred_Yes), <span class="at">se =</span> <span class="cn">FALSE</span>) <span class="sc">+</span></span>
<span id="cb100-6"><a href="generalized-linear-models-glm.html#cb100-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Age&quot;</span>,</span>
<span id="cb100-7"><a href="generalized-linear-models-glm.html#cb100-7" tabindex="-1"></a>       <span class="at">y =</span> <span class="cn">NULL</span>,</span>
<span id="cb100-8"><a href="generalized-linear-models-glm.html#cb100-8" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Binary Fitted Line Plot&quot;</span>) <span class="sc">+</span></span>
<span id="cb100-9"><a href="generalized-linear-models-glm.html#cb100-9" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">breaks =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>), <span class="at">labels =</span> <span class="fu">c</span>(<span class="st">&quot;Healthy&quot;</span>, <span class="st">&quot;Heart Disease&quot;</span>)) <span class="sc">+</span></span>
<span id="cb100-10"><a href="generalized-linear-models-glm.html#cb100-10" tabindex="-1"></a>  <span class="fu">theme_light</span>() <span class="sc">+</span></span>
<span id="cb100-11"><a href="generalized-linear-models-glm.html#cb100-11" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;right&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-69-1.png" width="672" /></p>
</div>
<div id="assumptions" class="section level3 unnumbered hasAnchor">
<h3>Assumptions<a href="generalized-linear-models-glm.html#assumptions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Four assumptions relate to the study design: (1) the dependent variable is dichotomous; (2) the observations are independent; (3) the categories of all nominal variables are mutually exclusive and exhaustive; and (4) there are at least 10 observations per dependent variable level and independent variable. These assumptions are all valid here. Three more assumptions related to the data distribution:</p>
<ul>
<li><p>There is a linear relationship between the logit transformation and the continuous independent variables. Test with a plot and with Box-Tidwell.</p></li>
<li><p>There is no independent variable multicollinearity. Test with correlation coefficients and variance inflation factors (VIF).</p></li>
<li><p>There are no influential outliers. Test with Cook’s distance.</p></li>
</ul>
<p>Test the linearity assumption first. There are two ways to do this (do both). First, fit your model, then plot the <em>fitted values</em> against the continuous predictors. This is the GLM analog to OLS bivariate analysis, except now the dependent variable is the <em>logit</em> transformation. These plotted relationships look pretty linear.</p>
<div class="sourceCode" id="cb101"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb101-1"><a href="generalized-linear-models-glm.html#cb101-1" tabindex="-1"></a>cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span></span>
<span id="cb101-2"><a href="generalized-linear-models-glm.html#cb101-2" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">new_data =</span> cs1<span class="sc">$</span>dat) <span class="sc">%&gt;%</span></span>
<span id="cb101-3"><a href="generalized-linear-models-glm.html#cb101-3" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="fu">c</span>(age, weight, VO2max)) <span class="sc">%&gt;%</span></span>
<span id="cb101-4"><a href="generalized-linear-models-glm.html#cb101-4" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> value, <span class="at">y =</span> .pred_Yes)) <span class="sc">+</span></span>
<span id="cb101-5"><a href="generalized-linear-models-glm.html#cb101-5" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb101-6"><a href="generalized-linear-models-glm.html#cb101-6" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="at">facets =</span> <span class="fu">vars</span>(name), <span class="at">scales =</span> <span class="st">&quot;free_x&quot;</span>) <span class="sc">+</span></span>
<span id="cb101-7"><a href="generalized-linear-models-glm.html#cb101-7" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">formula =</span> <span class="st">&quot;y~x&quot;</span>) <span class="sc">+</span></span>
<span id="cb101-8"><a href="generalized-linear-models-glm.html#cb101-8" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Linearity Test: predicted vs continuous predictors&quot;</span>, <span class="at">x =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-70-1.png" width="672" /></p>
<p>The second test for linearity is the Box-Tidwell approach. Add transformations of the continuous independent variables to the model, <span class="math inline">\(x_{Tx} = x \log x\)</span>, then test their significance level in the fit.</p>
<div class="sourceCode" id="cb102"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb102-1"><a href="generalized-linear-models-glm.html#cb102-1" tabindex="-1"></a><span class="co"># Using non-centered vars to avoid log(0) errors.</span></span>
<span id="cb102-2"><a href="generalized-linear-models-glm.html#cb102-2" tabindex="-1"></a>x <span class="ot">&lt;-</span> </span>
<span id="cb102-3"><a href="generalized-linear-models-glm.html#cb102-3" tabindex="-1"></a>  cs1<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb102-4"><a href="generalized-linear-models-glm.html#cb102-4" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb102-5"><a href="generalized-linear-models-glm.html#cb102-5" tabindex="-1"></a>    <span class="at">age_tx =</span> <span class="fu">log</span>(age) <span class="sc">*</span> age,</span>
<span id="cb102-6"><a href="generalized-linear-models-glm.html#cb102-6" tabindex="-1"></a>    <span class="at">weight_tx =</span> <span class="fu">log</span>(weight) <span class="sc">*</span> weight,</span>
<span id="cb102-7"><a href="generalized-linear-models-glm.html#cb102-7" tabindex="-1"></a>    <span class="at">VO2max_tx =</span> <span class="fu">log</span>(VO2max) <span class="sc">*</span> VO2max</span>
<span id="cb102-8"><a href="generalized-linear-models-glm.html#cb102-8" tabindex="-1"></a>  )</span>
<span id="cb102-9"><a href="generalized-linear-models-glm.html#cb102-9" tabindex="-1"></a></span>
<span id="cb102-10"><a href="generalized-linear-models-glm.html#cb102-10" tabindex="-1"></a>cs1<span class="sc">$</span>boxtidwell_fit <span class="ot">&lt;-</span> </span>
<span id="cb102-11"><a href="generalized-linear-models-glm.html#cb102-11" tabindex="-1"></a>  <span class="fu">logistic_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb102-12"><a href="generalized-linear-models-glm.html#cb102-12" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glm&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb102-13"><a href="generalized-linear-models-glm.html#cb102-13" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb102-14"><a href="generalized-linear-models-glm.html#cb102-14" tabindex="-1"></a>  <span class="fu">fit</span>(heart_disease <span class="sc">~</span> age <span class="sc">+</span> weight <span class="sc">+</span> VO2max <span class="sc">+</span> gender <span class="sc">+</span> </span>
<span id="cb102-15"><a href="generalized-linear-models-glm.html#cb102-15" tabindex="-1"></a>        age_tx <span class="sc">+</span> weight_tx <span class="sc">+</span> VO2max_tx, </span>
<span id="cb102-16"><a href="generalized-linear-models-glm.html#cb102-16" tabindex="-1"></a>      <span class="at">data =</span> x)</span>
<span id="cb102-17"><a href="generalized-linear-models-glm.html#cb102-17" tabindex="-1"></a></span>
<span id="cb102-18"><a href="generalized-linear-models-glm.html#cb102-18" tabindex="-1"></a>cs1<span class="sc">$</span>boxtidwell_fit <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 8 × 5
##   term        estimate std.error statistic p.value
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;
## 1 (Intercept) -40.6       21.7      -1.87   0.0615
## 2 age           2.73       1.10      2.47   0.0135
## 3 weight        0.144      0.783     0.184  0.854 
## 4 VO2max        1.32       1.82      0.724  0.469 
## 5 genderMale    1.85       0.922     2.01   0.0443
## 6 age_tx       -0.543      0.227    -2.40   0.0164
## 7 weight_tx    -0.0266     0.146    -0.182  0.855 
## 8 VO2max_tx    -0.301      0.382    -0.788  0.431</code></pre>
<p>Focus on the three transformed variables. <code>age_tx</code> is the only one with a <em>p</em>-value nearly &lt;.05, but it is customary to apply a Bonferroni adjustment when testing for linearity. There are eight predictors in the model (including the intercept term), so the Bonferroni adjusted <em>p</em>-value for <code>age_tx</code> is multiplied by 8. Do not reject the null hypothesis of linearity.</p>
<p>If the relationship <em>was</em> nonlinear, you could try transforming the variable by raising it to <span class="math inline">\(\lambda = 1 + b / \gamma\)</span> where <span class="math inline">\(b\)</span> is the estimated coefficient of the model without the interaction terms, and <span class="math inline">\(\gamma\)</span> is the estimated coefficient of the interaction term of the model with interactions. For <code>age</code>, <span class="math inline">\(b\)</span> is 0.085 and <span class="math inline">\(\gamma\)</span> is -0.543, so <span class="math inline">\(\lambda\)</span> = 0.843. This is approximately 1 (no transformation). It appears to be customary to apply general transformations like .5 (square root), 1/3 (cube root), ln, and the reciprocal.</p>
<p>Now check for multicollinearity. Variance inflation factors (VIF) estimate how much the variance of a regression coefficient is inflated due to multicollinearity. When independent variables are correlated, it is difficult to say which variable really influences the dependent variable. The VIF for variable <span class="math inline">\(i\)</span> is</p>
<p><span class="math display">\[
\mathrm{VIF}_i = \frac{1}{1 - R_i^2}
\]</span></p>
<p>where <span class="math inline">\(R_i^2\)</span> is the coefficient of determination (i.e., the proportion of dependent variance explained by the model) of a regression of <span class="math inline">\(X_i\)</span> against all of the other predictors, <span class="math inline">\(X_i = X_{j \ne i} \beta + \epsilon\)</span>. If <span class="math inline">\(X_i\)</span> is totally unrelated to its covariates, then <span class="math inline">\(R_i^2\)</span> will be zero and <span class="math inline">\(\mathrm{VIF}_i\)</span> will be 1. If <span class="math inline">\(R_i^2\)</span> is .8, <span class="math inline">\(\mathrm{VIF}_i\)</span> will be 5. The rule of thumb is that <span class="math inline">\(R_i^2 \le 5\)</span> is tolerable, and <span class="math inline">\(R_i^2 &gt; 5\)</span> is “highly correlated” and you have to do something about it. These are excellent.</p>
<div class="sourceCode" id="cb104"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb104-1"><a href="generalized-linear-models-glm.html#cb104-1" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">vif</span>(cs1<span class="sc">$</span>result)</span></code></pre></div>
<pre><code>##      age   weight   VO2max   gender 
## 1.035274 1.900575 2.167067 2.502538</code></pre>
<p>Try calculating the <span class="math inline">\(\mathrm{VIF}\)</span> for <code>age</code>.</p>
<div class="rmdnote">
<p>I don’t know why this doesn’t work. It <em>would</em> work if the underlying model was OLS instead of GLM. The answer seems to be related to GVIF vs VIF, but I didn’t figure it out.)</p>
</div>
<div class="sourceCode" id="cb106"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb106-1"><a href="generalized-linear-models-glm.html#cb106-1" tabindex="-1"></a>r2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(age <span class="sc">~</span> weight <span class="sc">+</span> VO2max <span class="sc">+</span> gender, <span class="at">data =</span> cs1<span class="sc">$</span>dat_training) <span class="sc">%&gt;%</span></span>
<span id="cb106-2"><a href="generalized-linear-models-glm.html#cb106-2" tabindex="-1"></a>  <span class="fu">summary</span>() <span class="sc">%&gt;%</span> <span class="fu">pluck</span>(<span class="st">&quot;r.squared&quot;</span>)</span>
<span id="cb106-3"><a href="generalized-linear-models-glm.html#cb106-3" tabindex="-1"></a></span>
<span id="cb106-4"><a href="generalized-linear-models-glm.html#cb106-4" tabindex="-1"></a>(vif <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">-</span> r2))</span>
<span id="cb106-5"><a href="generalized-linear-models-glm.html#cb106-5" tabindex="-1"></a><span class="do">## [1] 1.049814</span></span></code></pre></div>
<p>Now check for influential outliers. Predict the response probabilities and filter for the predictions more than two standard deviations from the actual value and a Cook’s Distance greater than 4/N = 0.04.<a href="#fn9" class="footnote-ref" id="fnref9"><sup>9</sup></a> Cook’s distance measures how much predicted values change when observation <em>i</em> is removed from the data. Only two fitted values were both an outlier and influential, row ids 59 and 70. An index plot of Cook’s Distance shows the two points at the far left. You might examine the observations for validity. Otherwise, proceed and explain that there were two standardized residuals with value of 2.01 and 2.27 standard deviations which were kept in the analysis.</p>
<div class="sourceCode" id="cb107"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb107-1"><a href="generalized-linear-models-glm.html#cb107-1" tabindex="-1"></a><span class="fu">augment</span>(cs1<span class="sc">$</span>result) <span class="sc">%&gt;%</span></span>
<span id="cb107-2"><a href="generalized-linear-models-glm.html#cb107-2" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb107-3"><a href="generalized-linear-models-glm.html#cb107-3" tabindex="-1"></a>    <span class="at">id =</span> <span class="fu">row_number</span>(),</span>
<span id="cb107-4"><a href="generalized-linear-models-glm.html#cb107-4" tabindex="-1"></a>    <span class="at">outlier =</span> <span class="fu">if_else</span>(<span class="fu">abs</span>(.std.resid) <span class="sc">&gt;=</span> <span class="dv">2</span>, <span class="st">&quot;Outlier&quot;</span>, <span class="st">&quot;Other&quot;</span>),</span>
<span id="cb107-5"><a href="generalized-linear-models-glm.html#cb107-5" tabindex="-1"></a>    <span class="at">influential =</span> <span class="fu">if_else</span>(.cooksd <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">nrow</span>(cs1<span class="sc">$</span>dat), <span class="st">&quot;Influential&quot;</span>, <span class="st">&quot;Other&quot;</span>),</span>
<span id="cb107-6"><a href="generalized-linear-models-glm.html#cb107-6" tabindex="-1"></a>    <span class="at">status =</span> <span class="fu">case_when</span>(</span>
<span id="cb107-7"><a href="generalized-linear-models-glm.html#cb107-7" tabindex="-1"></a>      outlier <span class="sc">==</span> <span class="st">&quot;Outlier&quot;</span> <span class="sc">&amp;</span> influential <span class="sc">==</span> <span class="st">&quot;Influential&quot;</span> <span class="sc">~</span> <span class="st">&quot;Influential Outlier&quot;</span>,</span>
<span id="cb107-8"><a href="generalized-linear-models-glm.html#cb107-8" tabindex="-1"></a>      outlier <span class="sc">==</span> <span class="st">&quot;Outlier&quot;</span> <span class="sc">~</span> <span class="st">&quot;Outlier&quot;</span>,</span>
<span id="cb107-9"><a href="generalized-linear-models-glm.html#cb107-9" tabindex="-1"></a>      influential <span class="sc">==</span> <span class="st">&quot;Influential&quot;</span> <span class="sc">~</span> <span class="st">&quot;Influential&quot;</span>,</span>
<span id="cb107-10"><a href="generalized-linear-models-glm.html#cb107-10" tabindex="-1"></a>      <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;Other&quot;</span></span>
<span id="cb107-11"><a href="generalized-linear-models-glm.html#cb107-11" tabindex="-1"></a>    )</span>
<span id="cb107-12"><a href="generalized-linear-models-glm.html#cb107-12" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb107-13"><a href="generalized-linear-models-glm.html#cb107-13" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .cooksd)) <span class="sc">+</span></span>
<span id="cb107-14"><a href="generalized-linear-models-glm.html#cb107-14" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> status)) <span class="sc">+</span></span>
<span id="cb107-15"><a href="generalized-linear-models-glm.html#cb107-15" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">if_else</span>(influential <span class="sc">==</span> <span class="st">&quot;Influential&quot;</span>, id, <span class="cn">NA_integer_</span>)), </span>
<span id="cb107-16"><a href="generalized-linear-models-glm.html#cb107-16" tabindex="-1"></a>            <span class="at">check_overlap =</span> <span class="cn">TRUE</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">nudge_x =</span> .<span class="dv">025</span>) <span class="sc">+</span></span>
<span id="cb107-17"><a href="generalized-linear-models-glm.html#cb107-17" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">nrow</span>(cs1<span class="sc">$</span>dat), <span class="at">linetype =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">&quot;goldenrod&quot;</span>) <span class="sc">+</span> </span>
<span id="cb107-18"><a href="generalized-linear-models-glm.html#cb107-18" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;Influential Outlier&quot;</span> <span class="ot">=</span> <span class="st">&quot;firebrick&quot;</span>, </span>
<span id="cb107-19"><a href="generalized-linear-models-glm.html#cb107-19" tabindex="-1"></a>                                <span class="st">&quot;Influential&quot;</span> <span class="ot">=</span> <span class="st">&quot;goldenrod&quot;</span>,</span>
<span id="cb107-20"><a href="generalized-linear-models-glm.html#cb107-20" tabindex="-1"></a>                                <span class="st">&quot;Outlier&quot;</span> <span class="ot">=</span> <span class="st">&quot;slategray&quot;</span>,</span>
<span id="cb107-21"><a href="generalized-linear-models-glm.html#cb107-21" tabindex="-1"></a>                                <span class="st">&quot;Other&quot;</span> <span class="ot">=</span> <span class="st">&quot;black&quot;</span>)) <span class="sc">+</span></span>
<span id="cb107-22"><a href="generalized-linear-models-glm.html#cb107-22" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;right&quot;</span>) <span class="sc">+</span></span>
<span id="cb107-23"><a href="generalized-linear-models-glm.html#cb107-23" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Index Plot of Cook&#39;s Distance.&quot;</span>,</span>
<span id="cb107-24"><a href="generalized-linear-models-glm.html#cb107-24" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Row id labeled for values &gt; 4 / N.&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
</div>
<div id="evaluate-the-fit" class="section level3 unnumbered hasAnchor">
<h3>Evaluate the Fit<a href="generalized-linear-models-glm.html#evaluate-the-fit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are several ways to evaluate the model fit.</p>
<ul>
<li>The likelihood ratio test</li>
<li>Pseudo R-squared<a href="#fn10" class="footnote-ref" id="fnref10"><sup>10</sup></a>.</li>
<li>Accuracy measures</li>
<li>Gain and ROC curves</li>
</ul>
<p>The <strong>likelihood ratio test</strong> compares the log likelihood of the fitted model to an intercept-only model.</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="generalized-linear-models-glm.html#cb108-1" tabindex="-1"></a>intercept_only <span class="ot">&lt;-</span></span>
<span id="cb108-2"><a href="generalized-linear-models-glm.html#cb108-2" tabindex="-1"></a>  <span class="fu">logistic_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb108-3"><a href="generalized-linear-models-glm.html#cb108-3" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;glm&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb108-4"><a href="generalized-linear-models-glm.html#cb108-4" tabindex="-1"></a>  <span class="fu">set_mode</span>(<span class="st">&quot;classification&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb108-5"><a href="generalized-linear-models-glm.html#cb108-5" tabindex="-1"></a>  <span class="fu">fit</span>(heart_disease <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> cs1<span class="sc">$</span>dat)</span>
<span id="cb108-6"><a href="generalized-linear-models-glm.html#cb108-6" tabindex="-1"></a></span>
<span id="cb108-7"><a href="generalized-linear-models-glm.html#cb108-7" tabindex="-1"></a>(cs1<span class="sc">$</span>lrtest <span class="ot">&lt;-</span> lmtest<span class="sc">::</span><span class="fu">lrtest</span>(cs1<span class="sc">$</span>result, intercept_only<span class="sc">$</span>fit))</span></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: heart_disease ~ age + weight + VO2max + gender
## Model 2: heart_disease ~ 1
##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)    
## 1   5 -51.044                         
## 2   1 -64.745 -4 27.402  1.649e-05 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The fitted model is significant, <span class="math inline">\(\chi^2\)</span>(4) = 27.4, <em>p</em> &lt; .001. Calculate the pseuedo-R2 with <code>DescTools::PseudoR2()</code>.</p>
<div class="rmdnote">
<p>I Can’t get this to work in the tidymodels framework. Using <code>glm()</code> for now.</p>
</div>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="generalized-linear-models-glm.html#cb110-1" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">glm</span>(heart_disease <span class="sc">~</span> age <span class="sc">+</span> weight <span class="sc">+</span> VO2max <span class="sc">+</span> gender, </span>
<span id="cb110-2"><a href="generalized-linear-models-glm.html#cb110-2" tabindex="-1"></a>         <span class="at">data =</span> cs1<span class="sc">$</span>dat,</span>
<span id="cb110-3"><a href="generalized-linear-models-glm.html#cb110-3" tabindex="-1"></a>         <span class="at">family =</span> <span class="st">&quot;binomial&quot;</span>)</span>
<span id="cb110-4"><a href="generalized-linear-models-glm.html#cb110-4" tabindex="-1"></a>cs1<span class="sc">$</span>pseudo_r2 <span class="ot">&lt;-</span> DescTools<span class="sc">::</span><span class="fu">PseudoR2</span>(x, <span class="at">which =</span> <span class="fu">c</span>(<span class="st">&quot;CoxSnell&quot;</span>, <span class="st">&quot;Nagelkerke&quot;</span>, <span class="st">&quot;McFadden&quot;</span>))</span>
<span id="cb110-5"><a href="generalized-linear-models-glm.html#cb110-5" tabindex="-1"></a></span>
<span id="cb110-6"><a href="generalized-linear-models-glm.html#cb110-6" tabindex="-1"></a>cs1<span class="sc">$</span>pseudo_r2</span></code></pre></div>
<pre><code>##   CoxSnell Nagelkerke   McFadden 
##  0.2396799  0.3301044  0.2116126</code></pre>
<p>Laerd interprets this as the model explained 33.0% (Nagelkerke R2) of the variance in heart disease. This is how your would interpret R2 in an OLS model. <a href="https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/">UCLA</a> points out that the various pseudo R-squareds measure other aspects of the model and are unique to the measured quantity. A pseudo R-squared is not very informative on its own; it is useful for comparing models. Accuracy measures formed by the cross-tabulation of observed and predicted classes is the better way to go.</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="generalized-linear-models-glm.html#cb112-1" tabindex="-1"></a>cs1<span class="sc">$</span>conf_mat <span class="ot">&lt;-</span></span>
<span id="cb112-2"><a href="generalized-linear-models-glm.html#cb112-2" tabindex="-1"></a>  cs1<span class="sc">$</span>fit <span class="sc">%&gt;%</span> </span>
<span id="cb112-3"><a href="generalized-linear-models-glm.html#cb112-3" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">new_data =</span> cs1<span class="sc">$</span>dat) <span class="sc">%&gt;%</span></span>
<span id="cb112-4"><a href="generalized-linear-models-glm.html#cb112-4" tabindex="-1"></a>  <span class="co"># conf_mat requires truth to be first level of the factor variable.</span></span>
<span id="cb112-5"><a href="generalized-linear-models-glm.html#cb112-5" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="fu">across</span>(<span class="fu">c</span>(heart_disease, .pred_class), <span class="sc">~</span><span class="fu">fct_relevel</span>(., <span class="st">&quot;Yes&quot;</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb112-6"><a href="generalized-linear-models-glm.html#cb112-6" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> heart_disease, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb112-7"><a href="generalized-linear-models-glm.html#cb112-7" tabindex="-1"></a></span>
<span id="cb112-8"><a href="generalized-linear-models-glm.html#cb112-8" tabindex="-1"></a>cs1<span class="sc">$</span>conf_mat</span>
<span id="cb112-9"><a href="generalized-linear-models-glm.html#cb112-9" tabindex="-1"></a><span class="do">##           Truth</span></span>
<span id="cb112-10"><a href="generalized-linear-models-glm.html#cb112-10" tabindex="-1"></a><span class="do">## Prediction Yes No</span></span>
<span id="cb112-11"><a href="generalized-linear-models-glm.html#cb112-11" tabindex="-1"></a><span class="do">##        Yes  16 10</span></span>
<span id="cb112-12"><a href="generalized-linear-models-glm.html#cb112-12" tabindex="-1"></a><span class="do">##        No   19 55</span></span>
<span id="cb112-13"><a href="generalized-linear-models-glm.html#cb112-13" tabindex="-1"></a></span>
<span id="cb112-14"><a href="generalized-linear-models-glm.html#cb112-14" tabindex="-1"></a>cs1<span class="sc">$</span>conf_mat <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span>
<span id="cb112-15"><a href="generalized-linear-models-glm.html#cb112-15" tabindex="-1"></a><span class="do">## # A tibble: 13 × 3</span></span>
<span id="cb112-16"><a href="generalized-linear-models-glm.html#cb112-16" tabindex="-1"></a><span class="do">##    .metric              .estimator .estimate</span></span>
<span id="cb112-17"><a href="generalized-linear-models-glm.html#cb112-17" tabindex="-1"></a><span class="do">##    &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;</span></span>
<span id="cb112-18"><a href="generalized-linear-models-glm.html#cb112-18" tabindex="-1"></a><span class="do">##  1 accuracy             binary         0.71 </span></span>
<span id="cb112-19"><a href="generalized-linear-models-glm.html#cb112-19" tabindex="-1"></a><span class="do">##  2 kap                  binary         0.322</span></span>
<span id="cb112-20"><a href="generalized-linear-models-glm.html#cb112-20" tabindex="-1"></a><span class="do">##  3 sens                 binary         0.457</span></span>
<span id="cb112-21"><a href="generalized-linear-models-glm.html#cb112-21" tabindex="-1"></a><span class="do">##  4 spec                 binary         0.846</span></span>
<span id="cb112-22"><a href="generalized-linear-models-glm.html#cb112-22" tabindex="-1"></a><span class="do">##  5 ppv                  binary         0.615</span></span>
<span id="cb112-23"><a href="generalized-linear-models-glm.html#cb112-23" tabindex="-1"></a><span class="do">##  6 npv                  binary         0.743</span></span>
<span id="cb112-24"><a href="generalized-linear-models-glm.html#cb112-24" tabindex="-1"></a><span class="do">##  7 mcc                  binary         0.330</span></span>
<span id="cb112-25"><a href="generalized-linear-models-glm.html#cb112-25" tabindex="-1"></a><span class="do">##  8 j_index              binary         0.303</span></span>
<span id="cb112-26"><a href="generalized-linear-models-glm.html#cb112-26" tabindex="-1"></a><span class="do">##  9 bal_accuracy         binary         0.652</span></span>
<span id="cb112-27"><a href="generalized-linear-models-glm.html#cb112-27" tabindex="-1"></a><span class="do">## 10 detection_prevalence binary         0.26 </span></span>
<span id="cb112-28"><a href="generalized-linear-models-glm.html#cb112-28" tabindex="-1"></a><span class="do">## 11 precision            binary         0.615</span></span>
<span id="cb112-29"><a href="generalized-linear-models-glm.html#cb112-29" tabindex="-1"></a><span class="do">## 12 recall               binary         0.457</span></span>
<span id="cb112-30"><a href="generalized-linear-models-glm.html#cb112-30" tabindex="-1"></a><span class="do">## 13 f_meas               binary         0.525</span></span>
<span id="cb112-31"><a href="generalized-linear-models-glm.html#cb112-31" tabindex="-1"></a></span>
<span id="cb112-32"><a href="generalized-linear-models-glm.html#cb112-32" tabindex="-1"></a>cs1<span class="sc">$</span>conf_mat <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>()</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p>The model accuracy, 71.0%, is the percent of observations correctly classified. The sensitivity, 45.7%, is the accuracy with regard to predicting positive cases. The specificity, 84.6%, is the accuracy with regard to predicting negative cases. If you are fitting a predictive model, use the testing data set for this.</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="generalized-linear-models-glm.html#cb113-1" tabindex="-1"></a>cs1<span class="sc">$</span>fit_training <span class="sc">%&gt;%</span> </span>
<span id="cb113-2"><a href="generalized-linear-models-glm.html#cb113-2" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">new_data =</span> cs1<span class="sc">$</span>dat_testing) <span class="sc">%&gt;%</span></span>
<span id="cb113-3"><a href="generalized-linear-models-glm.html#cb113-3" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> heart_disease, <span class="at">estimate =</span> .pred_class)</span></code></pre></div>
<pre><code>##           Truth
## Prediction No Yes
##        No  16   5
##        Yes  4   6</code></pre>
<p>Finally, plot the <a href="https://community.tibco.com/wiki/gains-vs-roc-curves-do-you-understand-difference">gain curve or ROC curve</a>. In the <strong>gain curve</strong>, the x-axis is the fraction of items seen when sorted by the predicted value, and the y-axis is the cumulatively summed true outcome. The “wizard” curve is the gain curve when the data is sorted by the true outcome. If the model’s gain curve is close to the wizard curve, then the model predicts the response well. The gray area is the “gain” over a random prediction.</p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="generalized-linear-models-glm.html#cb115-1" tabindex="-1"></a>cs1<span class="sc">$</span>dat_testing <span class="sc">%&gt;%</span></span>
<span id="cb115-2"><a href="generalized-linear-models-glm.html#cb115-2" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(cs1<span class="sc">$</span>fit, <span class="at">new_data =</span> cs1<span class="sc">$</span>dat_testing, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb115-3"><a href="generalized-linear-models-glm.html#cb115-3" tabindex="-1"></a>  <span class="co"># event_level = &quot;second&quot; sets the second level as success</span></span>
<span id="cb115-4"><a href="generalized-linear-models-glm.html#cb115-4" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">gain_curve</span>(.pred_Yes, <span class="at">truth =</span> heart_disease, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb115-5"><a href="generalized-linear-models-glm.html#cb115-5" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb115-6"><a href="generalized-linear-models-glm.html#cb115-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Gain Curve&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-80-1.png" width="672" /></p>
<p>11 of the 31 participants had heart disease in the test data set.</p>
<ul>
<li>The gain curve encountered 6 heart disease cases (50%) within the first 8 observations (55%). It encountered all 11 heart disease cases on the 18th observation.</li>
<li>The bottom of the grey area is the outcome of a random model. Only half the heart disease cases would be observed within 50% of the observations.<br />
</li>
<li>The top of the grey area is the outcome of the perfect model, the “wizard curve”. Half the heart disease cases would be observed in 6/30=20% of the observations.</li>
</ul>
<p>The <strong>ROC</strong> (Receiver Operating Characteristics) curve plots sensitivity vs specificity at varying cut-off values for the probability ranging from 0 to 1. Ideally, you want very little trade-off between sensitivity and specificity, with a curve hugging the left and top axes.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="generalized-linear-models-glm.html#cb116-1" tabindex="-1"></a>cs1<span class="sc">$</span>dat_testing <span class="sc">%&gt;%</span></span>
<span id="cb116-2"><a href="generalized-linear-models-glm.html#cb116-2" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(cs1<span class="sc">$</span>fit, <span class="at">new_data =</span> cs1<span class="sc">$</span>dat_testing, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb116-3"><a href="generalized-linear-models-glm.html#cb116-3" tabindex="-1"></a>  <span class="co"># event_level = &quot;second&quot; sets the second level as success</span></span>
<span id="cb116-4"><a href="generalized-linear-models-glm.html#cb116-4" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">roc_curve</span>(.pred_Yes, <span class="at">truth =</span> heart_disease, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb116-5"><a href="generalized-linear-models-glm.html#cb116-5" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb116-6"><a href="generalized-linear-models-glm.html#cb116-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;ROC Curve&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-81-1.png" width="672" /></p>
</div>
<div id="reporting" class="section level3 unnumbered hasAnchor">
<h3>Reporting<a href="generalized-linear-models-glm.html#reporting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>A binomial logistic regression was performed to ascertain the effects of age, weight, gender and VO2max on the likelihood that participants have heart disease. Linearity of the continuous variables with respect to the logit of the dependent variable was assessed via the Box-Tidwell (1962) procedure. A Bonferroni correction was applied using all eight terms in the model resulting in statistical significance being accepted when <em>p</em> &lt; 0.00625 (Tabachnick &amp; Fidell, 2014). Based on this assessment, all continuous independent variables were found to be linearly related to the logit of the dependent variable. There were two standardized residuals with value of 2.01 and 2.27 standard deviations, which were kept in the analysis. The logistic regression model was statistically significant, χ2(4) = 27.40, p &lt; .001. The model explained 33.0% (Nagelkerke R2) of the variance in heart disease and correctly classified 71.0% of cases. Sensitivity was 45.7%, specificity was 84.6%, positive predictive value was and negative predictive value was . Of the five predictor variables only three were statistically significant: age, gender and VO2max (as shown in Table 1). Females had 0.14 times lower odds to exhibit heart disease than males. Increasing age was associated with an increased likelihood of exhibiting heart disease, but increasing VO2max was associated with a reduction in the likelihood of exhibiting heart disease.</p>
</blockquote>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="generalized-linear-models-glm.html#cb117-1" tabindex="-1"></a>gtsummary<span class="sc">::</span><span class="fu">tbl_regression</span>(</span>
<span id="cb117-2"><a href="generalized-linear-models-glm.html#cb117-2" tabindex="-1"></a>  cs1<span class="sc">$</span>fit,</span>
<span id="cb117-3"><a href="generalized-linear-models-glm.html#cb117-3" tabindex="-1"></a>  <span class="at">exponentiate =</span> <span class="cn">TRUE</span></span>
<span id="cb117-4"><a href="generalized-linear-models-glm.html#cb117-4" tabindex="-1"></a>)</span></code></pre></div>
<div id="dmevsytvyn" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#dmevsytvyn table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#dmevsytvyn thead, #dmevsytvyn tbody, #dmevsytvyn tfoot, #dmevsytvyn tr, #dmevsytvyn td, #dmevsytvyn th {
  border-style: none;
}

#dmevsytvyn p {
  margin: 0;
  padding: 0;
}

#dmevsytvyn .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#dmevsytvyn .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#dmevsytvyn .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#dmevsytvyn .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#dmevsytvyn .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dmevsytvyn .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dmevsytvyn .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#dmevsytvyn .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#dmevsytvyn .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#dmevsytvyn .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#dmevsytvyn .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#dmevsytvyn .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#dmevsytvyn .gt_spanner_row {
  border-bottom-style: hidden;
}

#dmevsytvyn .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#dmevsytvyn .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#dmevsytvyn .gt_from_md > :first-child {
  margin-top: 0;
}

#dmevsytvyn .gt_from_md > :last-child {
  margin-bottom: 0;
}

#dmevsytvyn .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#dmevsytvyn .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#dmevsytvyn .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#dmevsytvyn .gt_row_group_first td {
  border-top-width: 2px;
}

#dmevsytvyn .gt_row_group_first th {
  border-top-width: 2px;
}

#dmevsytvyn .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dmevsytvyn .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#dmevsytvyn .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#dmevsytvyn .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dmevsytvyn .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#dmevsytvyn .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#dmevsytvyn .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#dmevsytvyn .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#dmevsytvyn .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#dmevsytvyn .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dmevsytvyn .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#dmevsytvyn .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#dmevsytvyn .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#dmevsytvyn .gt_left {
  text-align: left;
}

#dmevsytvyn .gt_center {
  text-align: center;
}

#dmevsytvyn .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#dmevsytvyn .gt_font_normal {
  font-weight: normal;
}

#dmevsytvyn .gt_font_bold {
  font-weight: bold;
}

#dmevsytvyn .gt_font_italic {
  font-style: italic;
}

#dmevsytvyn .gt_super {
  font-size: 65%;
}

#dmevsytvyn .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#dmevsytvyn .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#dmevsytvyn .gt_indent_1 {
  text-indent: 5px;
}

#dmevsytvyn .gt_indent_2 {
  text-indent: 10px;
}

#dmevsytvyn .gt_indent_3 {
  text-indent: 15px;
}

#dmevsytvyn .gt_indent_4 {
  text-indent: 20px;
}

#dmevsytvyn .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Characteristic&lt;/strong&gt;"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;OR&lt;/strong&gt;&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>OR</strong><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;95% CI&lt;/strong&gt;&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>95% CI</strong><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;p-value&lt;/strong&gt;"><strong>p-value</strong></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="label" class="gt_row gt_left">age</td>
<td headers="estimate" class="gt_row gt_center">1.09</td>
<td headers="ci" class="gt_row gt_center">1.03, 1.16</td>
<td headers="p.value" class="gt_row gt_center">0.003</td></tr>
    <tr><td headers="label" class="gt_row gt_left">weight</td>
<td headers="estimate" class="gt_row gt_center">1.01</td>
<td headers="ci" class="gt_row gt_center">0.96, 1.05</td>
<td headers="p.value" class="gt_row gt_center">0.8</td></tr>
    <tr><td headers="label" class="gt_row gt_left">VO2max</td>
<td headers="estimate" class="gt_row gt_center">0.91</td>
<td headers="ci" class="gt_row gt_center">0.82, 0.99</td>
<td headers="p.value" class="gt_row gt_center">0.039</td></tr>
    <tr><td headers="label" class="gt_row gt_left">gender</td>
<td headers="estimate" class="gt_row gt_center"><br /></td>
<td headers="ci" class="gt_row gt_center"><br /></td>
<td headers="p.value" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Female</td>
<td headers="estimate" class="gt_row gt_center">—</td>
<td headers="ci" class="gt_row gt_center">—</td>
<td headers="p.value" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Male</td>
<td headers="estimate" class="gt_row gt_center">7.03</td>
<td headers="ci" class="gt_row gt_center">1.43, 40.2</td>
<td headers="p.value" class="gt_row gt_center">0.021</td></tr>
  </tbody>
  
  <tfoot class="gt_footnotes">
    <tr>
      <td class="gt_footnote" colspan="4"><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span> OR = Odds Ratio, CI = Confidence Interval</td>
    </tr>
  </tfoot>
</table>
</div>
</div>
</div>
<div id="multinomiallogistic" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Multinomial Logistic Regression<a href="generalized-linear-models-glm.html#multinomiallogistic" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The <em>multinomial</em> logistic regression model is <span class="math inline">\(J - 1\)</span> baseline logits,</p>
<p><span class="math display">\[y_i = \log \left( \frac{\pi_{ij}}{\pi_{ij^*}} \right) = X_i \beta_j, \hspace{5mm} j \ne j^*\]</span></p>
<p>where <span class="math inline">\(j\)</span> is a level of the multinomial response variable. Whereas binomial logistic regression models the <em>log odds</em> of the response level, multinomial logistic regression models the <em>log relative risk</em>, the probability relative to the baseline <span class="math inline">\(j^*\)</span> level.<a href="#fn11" class="footnote-ref" id="fnref11"><sup>11</sup></a></p>
<p>Interpret the <span class="math inline">\(k^{th}\)</span> element of <span class="math inline">\(\beta_j\)</span> as the increase in log relative risk of <span class="math inline">\(Y_i = j\)</span> relative to <span class="math inline">\(Y_i = j^*\)</span> given a one-unit increase in the <span class="math inline">\(k^{th}\)</span> element of <span class="math inline">\(X\)</span>, holding the other terms constant. The individual probabilities, <span class="math inline">\(\pi_{ij}\)</span>, are</p>
<p><span class="math display">\[\pi_{ij} = \frac{\exp(y_{ij})}{1 + \sum_{j \ne j^*} \exp(y_{ij})} = \frac{e^{X_i\beta_j}}{1 + \sum_{j \ne j^*} e^{X_i\beta_j}}\]</span></p>
<p>and for the baseline category,</p>
<p><span class="math display">\[\pi_{ij^*} = \frac{1}{1 + \sum_{j \ne j^*} \exp(y_{ij})} = \frac{1}{1 + \sum_{j \ne j^*} e^{X_i\beta_j}}\]</span></p>
<p><strong>Assumptions</strong></p>
<p>Multinomial logistic regression applies when the dependent variable is categorical. It presumes a linear relationship between the log relative risk of the dependent variable and <span class="math inline">\(X\)</span> with residuals <span class="math inline">\(\epsilon\)</span> that are independent. It also assumes there is no severe multicollinearity in the predictors, and there is independence of irrelevant alternatives (IIA). IIA means the relative likelihood of being in one category compared to the base category would not change if you added other categories.</p>
<div id="cs2" class="section level3 unnumbered hasAnchor">
<h3>Case Study<a href="generalized-linear-models-glm.html#cs2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This case study uses the data set from <a href="https://stats.oarc.ucla.edu/r/dae/multinomial-logistic-regression/">this UCLA tutorial</a>. A study measures the association between students’ academic program (academic, general, and vocational) and their socioeconomic status (SES) (low, middle, high) and writing score.</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="generalized-linear-models-glm.html#cb118-1" tabindex="-1"></a><span class="fu">download.file</span>(</span>
<span id="cb118-2"><a href="generalized-linear-models-glm.html#cb118-2" tabindex="-1"></a>  <span class="st">&quot;https://stats.idre.ucla.edu/stat/data/hsbdemo.dta&quot;</span>,</span>
<span id="cb118-3"><a href="generalized-linear-models-glm.html#cb118-3" tabindex="-1"></a>  <span class="st">&quot;./input/hsbdemo.dta&quot;</span>,</span>
<span id="cb118-4"><a href="generalized-linear-models-glm.html#cb118-4" tabindex="-1"></a>  <span class="at">mode =</span> <span class="st">&quot;wb&quot;</span></span>
<span id="cb118-5"><a href="generalized-linear-models-glm.html#cb118-5" tabindex="-1"></a>)</span></code></pre></div>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="generalized-linear-models-glm.html#cb119-1" tabindex="-1"></a>cs2 <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb119-2"><a href="generalized-linear-models-glm.html#cb119-2" tabindex="-1"></a></span>
<span id="cb119-3"><a href="generalized-linear-models-glm.html#cb119-3" tabindex="-1"></a>cs2<span class="sc">$</span>dat <span class="ot">&lt;-</span> foreign<span class="sc">::</span><span class="fu">read.dta</span>(<span class="st">&quot;./input/hsbdemo.dta&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb119-4"><a href="generalized-linear-models-glm.html#cb119-4" tabindex="-1"></a>  <span class="co"># Just keep cols relevant to study</span></span>
<span id="cb119-5"><a href="generalized-linear-models-glm.html#cb119-5" tabindex="-1"></a>  <span class="fu">select</span>(id, prog, ses, write) <span class="sc">%&gt;%</span></span>
<span id="cb119-6"><a href="generalized-linear-models-glm.html#cb119-6" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">prog =</span> <span class="fu">fct_relevel</span>(prog, <span class="st">&quot;academic&quot;</span>, <span class="at">after =</span> <span class="dv">0</span>))</span>
<span id="cb119-7"><a href="generalized-linear-models-glm.html#cb119-7" tabindex="-1"></a></span>
<span id="cb119-8"><a href="generalized-linear-models-glm.html#cb119-8" tabindex="-1"></a>cs2<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb119-9"><a href="generalized-linear-models-glm.html#cb119-9" tabindex="-1"></a>  gtsummary<span class="sc">::</span><span class="fu">tbl_summary</span>(</span>
<span id="cb119-10"><a href="generalized-linear-models-glm.html#cb119-10" tabindex="-1"></a>    <span class="at">by =</span> prog,</span>
<span id="cb119-11"><a href="generalized-linear-models-glm.html#cb119-11" tabindex="-1"></a>    <span class="at">include =</span> <span class="fu">c</span>(prog, ses, write),</span>
<span id="cb119-12"><a href="generalized-linear-models-glm.html#cb119-12" tabindex="-1"></a>    <span class="at">statistic =</span> <span class="fu">list</span>(gtsummary<span class="sc">::</span><span class="fu">all_continuous</span>() <span class="sc">~</span> <span class="st">&quot;{mean}, {sd}&quot;</span>)</span>
<span id="cb119-13"><a href="generalized-linear-models-glm.html#cb119-13" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb119-14"><a href="generalized-linear-models-glm.html#cb119-14" tabindex="-1"></a>  gtsummary<span class="sc">::</span><span class="fu">add_overall</span>()</span></code></pre></div>
<div id="tkywhnumbk" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#tkywhnumbk table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#tkywhnumbk thead, #tkywhnumbk tbody, #tkywhnumbk tfoot, #tkywhnumbk tr, #tkywhnumbk td, #tkywhnumbk th {
  border-style: none;
}

#tkywhnumbk p {
  margin: 0;
  padding: 0;
}

#tkywhnumbk .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#tkywhnumbk .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#tkywhnumbk .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#tkywhnumbk .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#tkywhnumbk .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#tkywhnumbk .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tkywhnumbk .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#tkywhnumbk .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#tkywhnumbk .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#tkywhnumbk .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#tkywhnumbk .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#tkywhnumbk .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#tkywhnumbk .gt_spanner_row {
  border-bottom-style: hidden;
}

#tkywhnumbk .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#tkywhnumbk .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#tkywhnumbk .gt_from_md > :first-child {
  margin-top: 0;
}

#tkywhnumbk .gt_from_md > :last-child {
  margin-bottom: 0;
}

#tkywhnumbk .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#tkywhnumbk .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#tkywhnumbk .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#tkywhnumbk .gt_row_group_first td {
  border-top-width: 2px;
}

#tkywhnumbk .gt_row_group_first th {
  border-top-width: 2px;
}

#tkywhnumbk .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#tkywhnumbk .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#tkywhnumbk .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#tkywhnumbk .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tkywhnumbk .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#tkywhnumbk .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#tkywhnumbk .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#tkywhnumbk .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#tkywhnumbk .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#tkywhnumbk .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#tkywhnumbk .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#tkywhnumbk .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#tkywhnumbk .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#tkywhnumbk .gt_left {
  text-align: left;
}

#tkywhnumbk .gt_center {
  text-align: center;
}

#tkywhnumbk .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#tkywhnumbk .gt_font_normal {
  font-weight: normal;
}

#tkywhnumbk .gt_font_bold {
  font-weight: bold;
}

#tkywhnumbk .gt_font_italic {
  font-style: italic;
}

#tkywhnumbk .gt_super {
  font-size: 65%;
}

#tkywhnumbk .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#tkywhnumbk .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#tkywhnumbk .gt_indent_1 {
  text-indent: 5px;
}

#tkywhnumbk .gt_indent_2 {
  text-indent: 10px;
}

#tkywhnumbk .gt_indent_3 {
  text-indent: 15px;
}

#tkywhnumbk .gt_indent_4 {
  text-indent: 20px;
}

#tkywhnumbk .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Characteristic&lt;/strong&gt;"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Overall&lt;/strong&gt;, N = 200&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>Overall</strong>, N = 200<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;academic&lt;/strong&gt;, N = 105&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>academic</strong>, N = 105<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;general&lt;/strong&gt;, N = 45&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>general</strong>, N = 45<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;vocation&lt;/strong&gt;, N = 50&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>vocation</strong>, N = 50<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="label" class="gt_row gt_left">ses</td>
<td headers="stat_0" class="gt_row gt_center"><br /></td>
<td headers="stat_1" class="gt_row gt_center"><br /></td>
<td headers="stat_2" class="gt_row gt_center"><br /></td>
<td headers="stat_3" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    low</td>
<td headers="stat_0" class="gt_row gt_center">47 (24%)</td>
<td headers="stat_1" class="gt_row gt_center">19 (18%)</td>
<td headers="stat_2" class="gt_row gt_center">16 (36%)</td>
<td headers="stat_3" class="gt_row gt_center">12 (24%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">    middle</td>
<td headers="stat_0" class="gt_row gt_center">95 (48%)</td>
<td headers="stat_1" class="gt_row gt_center">44 (42%)</td>
<td headers="stat_2" class="gt_row gt_center">20 (44%)</td>
<td headers="stat_3" class="gt_row gt_center">31 (62%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">    high</td>
<td headers="stat_0" class="gt_row gt_center">58 (29%)</td>
<td headers="stat_1" class="gt_row gt_center">42 (40%)</td>
<td headers="stat_2" class="gt_row gt_center">9 (20%)</td>
<td headers="stat_3" class="gt_row gt_center">7 (14%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">write</td>
<td headers="stat_0" class="gt_row gt_center">53, 9</td>
<td headers="stat_1" class="gt_row gt_center">56, 8</td>
<td headers="stat_2" class="gt_row gt_center">51, 9</td>
<td headers="stat_3" class="gt_row gt_center">47, 9</td></tr>
  </tbody>
  
  <tfoot class="gt_footnotes">
    <tr>
      <td class="gt_footnote" colspan="5"><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span> n (%); Mean, SD</td>
    </tr>
  </tfoot>
</table>
</div>
<p><br></p>
<p>Conduct a brief exploratory analysis to establish your expectations. Academic programs are associated with higher writing scores and SES. General and vocational programs are the opposite, although SES has opposing effects for general (increased probability) and vocational (decreased probability).</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="generalized-linear-models-glm.html#cb120-1" tabindex="-1"></a>cs2<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb120-2"><a href="generalized-linear-models-glm.html#cb120-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">write_bin =</span> <span class="fu">cut</span>(write, <span class="at">breaks =</span> <span class="dv">5</span>, <span class="at">dig.lab =</span> <span class="dv">1</span>, <span class="at">right =</span> <span class="cn">FALSE</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb120-3"><a href="generalized-linear-models-glm.html#cb120-3" tabindex="-1"></a>  <span class="fu">count</span>(prog, ses, write_bin) <span class="sc">%&gt;%</span></span>
<span id="cb120-4"><a href="generalized-linear-models-glm.html#cb120-4" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">.by =</span> <span class="fu">c</span>(ses, write_bin), <span class="at">prob =</span> n <span class="sc">/</span> <span class="fu">sum</span>(n)) <span class="sc">%&gt;%</span></span>
<span id="cb120-5"><a href="generalized-linear-models-glm.html#cb120-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> write_bin, <span class="at">y =</span> prob, <span class="at">color =</span> ses)) <span class="sc">+</span></span>
<span id="cb120-6"><a href="generalized-linear-models-glm.html#cb120-6" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb120-7"><a href="generalized-linear-models-glm.html#cb120-7" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="fu">aes</span>(<span class="at">group =</span> ses)) <span class="sc">+</span></span>
<span id="cb120-8"><a href="generalized-linear-models-glm.html#cb120-8" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="at">facets =</span> <span class="fu">vars</span>(prog)) <span class="sc">+</span></span>
<span id="cb120-9"><a href="generalized-linear-models-glm.html#cb120-9" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;top&quot;</span>) <span class="sc">+</span></span>
<span id="cb120-10"><a href="generalized-linear-models-glm.html#cb120-10" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Program Proportions by SES&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-85-1.png" width="672" /></p>
<p>If your model is predictive rather than inferential, split the data into training/testing data sets.</p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="generalized-linear-models-glm.html#cb121-1" tabindex="-1"></a><span class="co"># For reproducibility</span></span>
<span id="cb121-2"><a href="generalized-linear-models-glm.html#cb121-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">123</span>)</span>
<span id="cb121-3"><a href="generalized-linear-models-glm.html#cb121-3" tabindex="-1"></a></span>
<span id="cb121-4"><a href="generalized-linear-models-glm.html#cb121-4" tabindex="-1"></a>(x <span class="ot">&lt;-</span> <span class="fu">initial_split</span>(cs2<span class="sc">$</span>dat, <span class="at">prop =</span> <span class="fl">0.7</span>, <span class="at">strata =</span> prog))</span>
<span id="cb121-5"><a href="generalized-linear-models-glm.html#cb121-5" tabindex="-1"></a><span class="do">## &lt;Training/Testing/Total&gt;</span></span>
<span id="cb121-6"><a href="generalized-linear-models-glm.html#cb121-6" tabindex="-1"></a><span class="do">## &lt;139/61/200&gt;</span></span>
<span id="cb121-7"><a href="generalized-linear-models-glm.html#cb121-7" tabindex="-1"></a></span>
<span id="cb121-8"><a href="generalized-linear-models-glm.html#cb121-8" tabindex="-1"></a>cs2<span class="sc">$</span>dat_training <span class="ot">&lt;-</span> <span class="fu">training</span>(x)</span>
<span id="cb121-9"><a href="generalized-linear-models-glm.html#cb121-9" tabindex="-1"></a><span class="fu">dim</span>(cs2<span class="sc">$</span>dat_training)</span>
<span id="cb121-10"><a href="generalized-linear-models-glm.html#cb121-10" tabindex="-1"></a><span class="do">## [1] 139   4</span></span>
<span id="cb121-11"><a href="generalized-linear-models-glm.html#cb121-11" tabindex="-1"></a></span>
<span id="cb121-12"><a href="generalized-linear-models-glm.html#cb121-12" tabindex="-1"></a>cs2<span class="sc">$</span>dat_testing <span class="ot">&lt;-</span> <span class="fu">testing</span>(x)</span>
<span id="cb121-13"><a href="generalized-linear-models-glm.html#cb121-13" tabindex="-1"></a><span class="fu">dim</span>(cs2<span class="sc">$</span>dat_testing)</span>
<span id="cb121-14"><a href="generalized-linear-models-glm.html#cb121-14" tabindex="-1"></a><span class="do">## [1] 61  4</span></span></code></pre></div>
</div>
<div id="fit-the-model-1" class="section level3 unnumbered hasAnchor">
<h3>Fit the Model<a href="generalized-linear-models-glm.html#fit-the-model-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The multinomial logitistic regression model engines all seem to be related to neural networks and advise that predictors be set on a common scale by normalizing. I have only one predictor other than SES in this model, but I’ll normalize it anyway. Normalizing <code>write</code> will also facilitate model interpretation. The intercept will represent a reasonable condition (average writing score) and a one-unit increase in <code>write</code> will represent a 1 SD increase in writing.</p>
<div class="rmdnote">
<p>This case study will use both the <code>parsnip</code> package to fit a model directly to a data set, and the <code>recipes</code> package to preprocess the data. <code>parsnip</code> is fine for most applications and it seems to be better supported by other functions, like <code>tidy()</code>, so stick with it for inferential applications. <code>recipes</code> has the advantage of being able to process data in a workflow, so you don’t have to transform new data to make predictions. See more uses of <code>recipes</code> on the <a href="https://www.tidymodels.org/start/recipes/">tidy models documentation</a>.</p>
</div>
<p>Let’s first use <code>parsnip</code> to fit the full data set for an inferential application.</p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="generalized-linear-models-glm.html#cb122-1" tabindex="-1"></a><span class="co"># Create the model. This much is the same for parsnip or recipes.</span></span>
<span id="cb122-2"><a href="generalized-linear-models-glm.html#cb122-2" tabindex="-1"></a>cs2<span class="sc">$</span>model <span class="ot">&lt;-</span></span>
<span id="cb122-3"><a href="generalized-linear-models-glm.html#cb122-3" tabindex="-1"></a>  <span class="fu">multinom_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb122-4"><a href="generalized-linear-models-glm.html#cb122-4" tabindex="-1"></a>  <span class="fu">set_engine</span>(<span class="st">&quot;nnet&quot;</span>)</span>
<span id="cb122-5"><a href="generalized-linear-models-glm.html#cb122-5" tabindex="-1"></a></span>
<span id="cb122-6"><a href="generalized-linear-models-glm.html#cb122-6" tabindex="-1"></a><span class="co"># For parsnip, you need to normalize the data explicitly. nnet requires dummy</span></span>
<span id="cb122-7"><a href="generalized-linear-models-glm.html#cb122-7" tabindex="-1"></a><span class="co"># vars for factor predictors, but thankfully parsnip does that implicitly. </span></span>
<span id="cb122-8"><a href="generalized-linear-models-glm.html#cb122-8" tabindex="-1"></a><span class="co"># However, I want the outcome variable base level to be &quot;academic&quot; and while</span></span>
<span id="cb122-9"><a href="generalized-linear-models-glm.html#cb122-9" tabindex="-1"></a><span class="co"># recipes can do that in pre-processing, I have to do it manually for parsnip.</span></span>
<span id="cb122-10"><a href="generalized-linear-models-glm.html#cb122-10" tabindex="-1"></a>cs2<span class="sc">$</span>dat_normalized <span class="ot">&lt;-</span></span>
<span id="cb122-11"><a href="generalized-linear-models-glm.html#cb122-11" tabindex="-1"></a>  cs2<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb122-12"><a href="generalized-linear-models-glm.html#cb122-12" tabindex="-1"></a>  <span class="co"># Cast to numeric, otherwise scale() returns an nmatrix. :(</span></span>
<span id="cb122-13"><a href="generalized-linear-models-glm.html#cb122-13" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">write =</span> <span class="fu">as.numeric</span>(<span class="fu">scale</span>(write, <span class="at">center =</span> <span class="cn">TRUE</span>, <span class="at">scale =</span> <span class="cn">TRUE</span>)))</span>
<span id="cb122-14"><a href="generalized-linear-models-glm.html#cb122-14" tabindex="-1"></a></span>
<span id="cb122-15"><a href="generalized-linear-models-glm.html#cb122-15" tabindex="-1"></a><span class="co"># Fit the whole data set for an explanatory model.</span></span>
<span id="cb122-16"><a href="generalized-linear-models-glm.html#cb122-16" tabindex="-1"></a>cs2<span class="sc">$</span>fit <span class="ot">&lt;-</span></span>
<span id="cb122-17"><a href="generalized-linear-models-glm.html#cb122-17" tabindex="-1"></a>  cs2<span class="sc">$</span>model <span class="sc">%&gt;%</span></span>
<span id="cb122-18"><a href="generalized-linear-models-glm.html#cb122-18" tabindex="-1"></a>  <span class="fu">fit</span>(prog <span class="sc">~</span> ses <span class="sc">+</span> write, <span class="at">data =</span> cs2<span class="sc">$</span>dat_normalized)</span>
<span id="cb122-19"><a href="generalized-linear-models-glm.html#cb122-19" tabindex="-1"></a></span>
<span id="cb122-20"><a href="generalized-linear-models-glm.html#cb122-20" tabindex="-1"></a><span class="co"># Extract the fit object returned by the engine. Use for interpretation and </span></span>
<span id="cb122-21"><a href="generalized-linear-models-glm.html#cb122-21" tabindex="-1"></a><span class="co"># checking assumptions.</span></span>
<span id="cb122-22"><a href="generalized-linear-models-glm.html#cb122-22" tabindex="-1"></a>cs2<span class="sc">$</span>result <span class="ot">&lt;-</span></span>
<span id="cb122-23"><a href="generalized-linear-models-glm.html#cb122-23" tabindex="-1"></a>  cs2<span class="sc">$</span>fit <span class="sc">%&gt;%</span></span>
<span id="cb122-24"><a href="generalized-linear-models-glm.html#cb122-24" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>()</span></code></pre></div>
<p>In parallel, let’s use <code>recipes</code> to fit a predictive model to the training data. The model object is already created, so we just need to pair a recipe object with a workflow.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="generalized-linear-models-glm.html#cb123-1" tabindex="-1"></a>cs2<span class="sc">$</span>rec <span class="ot">&lt;-</span></span>
<span id="cb123-2"><a href="generalized-linear-models-glm.html#cb123-2" tabindex="-1"></a>  <span class="co"># The `data` argument can be the base data, or training, or even testing. </span></span>
<span id="cb123-3"><a href="generalized-linear-models-glm.html#cb123-3" tabindex="-1"></a>  <span class="co"># recipe() only uses it to catalog variable names and data types.</span></span>
<span id="cb123-4"><a href="generalized-linear-models-glm.html#cb123-4" tabindex="-1"></a>  <span class="fu">recipe</span>(prog <span class="sc">~</span> ses <span class="sc">+</span> write, <span class="at">data =</span> cs2<span class="sc">$</span>dat) <span class="sc">%&gt;%</span></span>
<span id="cb123-5"><a href="generalized-linear-models-glm.html#cb123-5" tabindex="-1"></a>  <span class="co"># You could have specified the formula as prog ~ ., then assigned roles. E.g.,</span></span>
<span id="cb123-6"><a href="generalized-linear-models-glm.html#cb123-6" tabindex="-1"></a>  <span class="co"># Keep &quot;id&quot; in data set, but don&#39;t use it in the model like this:</span></span>
<span id="cb123-7"><a href="generalized-linear-models-glm.html#cb123-7" tabindex="-1"></a>  <span class="co"># update_role(id, new_role = &quot;ID&quot;) %&gt;%</span></span>
<span id="cb123-8"><a href="generalized-linear-models-glm.html#cb123-8" tabindex="-1"></a>  <span class="co"># Unlike parsnip, recipe does not automatically create dummy vars.</span></span>
<span id="cb123-9"><a href="generalized-linear-models-glm.html#cb123-9" tabindex="-1"></a>  <span class="fu">step_dummy</span>(<span class="fu">all_nominal_predictors</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb123-10"><a href="generalized-linear-models-glm.html#cb123-10" tabindex="-1"></a>  <span class="co"># Not relevant here, but good practice: if a factor level has few values, it may</span></span>
<span id="cb123-11"><a href="generalized-linear-models-glm.html#cb123-11" tabindex="-1"></a>  <span class="co"># not appear in the training set. If so, its dummy will contain a single value</span></span>
<span id="cb123-12"><a href="generalized-linear-models-glm.html#cb123-12" tabindex="-1"></a>  <span class="co"># (0). You can prevent that by dropping zero-value cols.</span></span>
<span id="cb123-13"><a href="generalized-linear-models-glm.html#cb123-13" tabindex="-1"></a>  <span class="fu">step_zv</span>(<span class="fu">all_predictors</span>()) <span class="sc">%&gt;%</span></span>
<span id="cb123-14"><a href="generalized-linear-models-glm.html#cb123-14" tabindex="-1"></a>  <span class="co"># Set the reference level of the outcome here if you want.</span></span>
<span id="cb123-15"><a href="generalized-linear-models-glm.html#cb123-15" tabindex="-1"></a>  <span class="fu">step_relevel</span>(prog, <span class="at">ref_level =</span> <span class="st">&quot;academic&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb123-16"><a href="generalized-linear-models-glm.html#cb123-16" tabindex="-1"></a>  <span class="co"># Normalize write.</span></span>
<span id="cb123-17"><a href="generalized-linear-models-glm.html#cb123-17" tabindex="-1"></a>  <span class="fu">step_normalize</span>(write)</span>
<span id="cb123-18"><a href="generalized-linear-models-glm.html#cb123-18" tabindex="-1"></a></span>
<span id="cb123-19"><a href="generalized-linear-models-glm.html#cb123-19" tabindex="-1"></a><span class="co"># The workflow pairs the model and recipe.</span></span>
<span id="cb123-20"><a href="generalized-linear-models-glm.html#cb123-20" tabindex="-1"></a>cs2<span class="sc">$</span>wflow <span class="ot">&lt;-</span></span>
<span id="cb123-21"><a href="generalized-linear-models-glm.html#cb123-21" tabindex="-1"></a>  <span class="fu">workflow</span>() <span class="sc">%&gt;%</span></span>
<span id="cb123-22"><a href="generalized-linear-models-glm.html#cb123-22" tabindex="-1"></a>  <span class="fu">add_model</span>(cs2<span class="sc">$</span>model) <span class="sc">%&gt;%</span></span>
<span id="cb123-23"><a href="generalized-linear-models-glm.html#cb123-23" tabindex="-1"></a>  <span class="fu">add_recipe</span>(cs2<span class="sc">$</span>rec)</span>
<span id="cb123-24"><a href="generalized-linear-models-glm.html#cb123-24" tabindex="-1"></a></span>
<span id="cb123-25"><a href="generalized-linear-models-glm.html#cb123-25" tabindex="-1"></a><span class="co"># Fit the training data set for a predictive model.</span></span>
<span id="cb123-26"><a href="generalized-linear-models-glm.html#cb123-26" tabindex="-1"></a>cs2<span class="sc">$</span>fit_training <span class="ot">&lt;-</span></span>
<span id="cb123-27"><a href="generalized-linear-models-glm.html#cb123-27" tabindex="-1"></a>  cs2<span class="sc">$</span>wflow <span class="sc">%&gt;%</span></span>
<span id="cb123-28"><a href="generalized-linear-models-glm.html#cb123-28" tabindex="-1"></a>  <span class="fu">fit</span>(<span class="at">data =</span> cs2<span class="sc">$</span>dat_training)</span>
<span id="cb123-29"><a href="generalized-linear-models-glm.html#cb123-29" tabindex="-1"></a></span>
<span id="cb123-30"><a href="generalized-linear-models-glm.html#cb123-30" tabindex="-1"></a><span class="co"># You can&#39;t extract the engine fit and pipe into summary. Seems like a bug</span></span>
<span id="cb123-31"><a href="generalized-linear-models-glm.html#cb123-31" tabindex="-1"></a><span class="co"># cs2$result_training &lt;- cs2$fit_training %&gt;% extract_fit_engine()</span></span></code></pre></div>
<p>Let’s look at the explanatory model summary object. The model produces a set of coefficient estimates for each non-reference level of the dependent variable. The <code>nnet</code> engine presents the coefficient estimates, then their standard errors as a second section, but does not present the <em>z</em>-statistic or <em>p</em>-values!</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="generalized-linear-models-glm.html#cb124-1" tabindex="-1"></a>cs2<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## Call:
## nnet::multinom(formula = prog ~ ses + write, data = data, trace = FALSE)
## 
## Coefficients:
##          (Intercept)  sesmiddle    seshigh      write
## general   -0.2049851 -0.5332857 -1.1628363 -0.5490814
## vocation  -0.7771705  0.2913906 -0.9826773 -1.0767939
## 
## Std. Errors:
##          (Intercept) sesmiddle   seshigh     write
## general    0.3491296 0.4437324 0.5142201 0.2029457
## vocation   0.4111072 0.4763734 0.5955665 0.2106132
## 
## Residual Deviance: 359.9635 
## AIC: 375.9635</code></pre>
<p>The residual deviance is <span class="math inline">\(G^2 = 2 \sum_{i,j}y_{ij} \log \frac{y_{ij}}{\hat{\pi}_{ij}}\)</span>. Another model diagnostic is the log-likelihood, <span class="math inline">\(-G^2 / 2\)</span> (not shown) and AIC. More on these in the Model Fit section.</p>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="generalized-linear-models-glm.html#cb126-1" tabindex="-1"></a><span class="fu">deviance</span>(cs2<span class="sc">$</span>result)</span>
<span id="cb126-2"><a href="generalized-linear-models-glm.html#cb126-2" tabindex="-1"></a><span class="do">## [1] 359.9635</span></span>
<span id="cb126-3"><a href="generalized-linear-models-glm.html#cb126-3" tabindex="-1"></a><span class="fu">logLik</span>(cs2<span class="sc">$</span>result, <span class="at">sum =</span> <span class="cn">TRUE</span>)</span>
<span id="cb126-4"><a href="generalized-linear-models-glm.html#cb126-4" tabindex="-1"></a><span class="do">## &#39;log Lik.&#39; -179.9817 (df=8)</span></span></code></pre></div>
<p>The Wald <em>z</em>-statistic is <span class="math inline">\(z = \hat{\beta} / SE(\hat{\beta})\)</span>. Its square is the Wald chi-squared statistic. The <em>p</em>-value is the area to the right of <span class="math inline">\(z^2\)</span> in the <span class="math inline">\(\chi_1^2\)</span> density curve. Get these from <code>tidy()</code>.</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="generalized-linear-models-glm.html#cb127-1" tabindex="-1"></a>cs2<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">tidy</span>()</span></code></pre></div>
<pre><code>## # A tibble: 8 × 6
##   y.level  term        estimate std.error statistic     p.value
##   &lt;chr&gt;    &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;       &lt;dbl&gt;
## 1 general  (Intercept)   -0.205     0.349    -0.587 0.557      
## 2 general  sesmiddle     -0.533     0.444    -1.20  0.229      
## 3 general  seshigh       -1.16      0.514    -2.26  0.0237     
## 4 general  write         -0.549     0.203    -2.71  0.00682    
## 5 vocation (Intercept)   -0.777     0.411    -1.89  0.0587     
## 6 vocation sesmiddle      0.291     0.476     0.612 0.541      
## 7 vocation seshigh       -0.983     0.596    -1.65  0.0989     
## 8 vocation write         -1.08      0.211    -5.11  0.000000318</code></pre>
</div>
<div id="interpretation-2" class="section level3 unnumbered hasAnchor">
<h3>Interpretation<a href="generalized-linear-models-glm.html#interpretation-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Start with interpreting the dependent variable. The model fits the <strong>log relative risk</strong> of belonging to program <span class="math inline">\(j \in\)</span> [vocation, general] vs. <span class="math inline">\(j^*\)</span> = academic. However, <code>predict()</code> returns either the risk (<code>type</code> = “probs”) or outcome (<code>type</code> = “class), not the log relative risk. Plug in values for the predictor variables to get predictions. The relative risk is <span class="math inline">\(RR = \exp (\hat{y}_j) = \pi_j / \pi_{j^*}\)</span>. We see here that a student of low SES and mean writing score is less likely to be in a general or vocation program than an academic program.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="generalized-linear-models-glm.html#cb129-1" tabindex="-1"></a>(risk <span class="ot">&lt;-</span> <span class="fu">predict</span>(cs2<span class="sc">$</span>result, <span class="at">newdata =</span> <span class="fu">list</span>(<span class="at">ses =</span> <span class="st">&quot;low&quot;</span>, <span class="at">write =</span> <span class="dv">0</span>), <span class="at">type =</span> <span class="st">&quot;probs&quot;</span>))</span>
<span id="cb129-2"><a href="generalized-linear-models-glm.html#cb129-2" tabindex="-1"></a><span class="do">##  academic   general  vocation </span></span>
<span id="cb129-3"><a href="generalized-linear-models-glm.html#cb129-3" tabindex="-1"></a><span class="do">## 0.4396833 0.3581922 0.2021246</span></span>
<span id="cb129-4"><a href="generalized-linear-models-glm.html#cb129-4" tabindex="-1"></a></span>
<span id="cb129-5"><a href="generalized-linear-models-glm.html#cb129-5" tabindex="-1"></a><span class="co"># Relative risk.</span></span>
<span id="cb129-6"><a href="generalized-linear-models-glm.html#cb129-6" tabindex="-1"></a>(rr <span class="ot">&lt;-</span> risk[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">/</span> risk[<span class="dv">1</span>])</span>
<span id="cb129-7"><a href="generalized-linear-models-glm.html#cb129-7" tabindex="-1"></a><span class="do">##   general  vocation </span></span>
<span id="cb129-8"><a href="generalized-linear-models-glm.html#cb129-8" tabindex="-1"></a><span class="do">## 0.8146595 0.4597049</span></span>
<span id="cb129-9"><a href="generalized-linear-models-glm.html#cb129-9" tabindex="-1"></a></span>
<span id="cb129-10"><a href="generalized-linear-models-glm.html#cb129-10" tabindex="-1"></a><span class="co"># Log-relative risk (the modeled outcome)</span></span>
<span id="cb129-11"><a href="generalized-linear-models-glm.html#cb129-11" tabindex="-1"></a>(log_rr <span class="ot">&lt;-</span> <span class="fu">log</span>(rr))</span>
<span id="cb129-12"><a href="generalized-linear-models-glm.html#cb129-12" tabindex="-1"></a><span class="do">##    general   vocation </span></span>
<span id="cb129-13"><a href="generalized-linear-models-glm.html#cb129-13" tabindex="-1"></a><span class="do">## -0.2049851 -0.7771705</span></span></code></pre></div>
<p>Move on to the coefficients. Interpret <span class="math inline">\(\hat{\beta}\)</span> as the change in the <em>log relative risk</em> of <span class="math inline">\(y_j\)</span> relative to <span class="math inline">\(y_{j^*}\)</span> due to a <span class="math inline">\(\delta\)</span> = one unit change in <span class="math inline">\(x\)</span>. A <span class="math inline">\(\delta = x_a - x_b\)</span> change in <span class="math inline">\(x\)</span> is associated with a <span class="math inline">\(\delta \hat{\beta}\)</span> change. <span class="math inline">\(\delta\beta\)</span> is the log relative risk ratio.</p>
<p><span class="math display">\[\log \left(\pi_j / \pi_{j^*} |_{x = x_a} \right) - \log \left(\pi_j / \pi_{j^*} |_{x = x_b} \right) = \log \left( \frac{\pi_j / \pi_{j^*} |_{x = x_a}}{\pi_j / \pi_{j^*} |_{x = x_b}} \right) = \delta \hat{\beta}\]</span></p>
<p>The exponential of <span class="math inline">\(\hat{\beta}\)</span> is the change in the <em>relative risk</em> of <span class="math inline">\(y_j\)</span> relative to <span class="math inline">\(y_{j^*}\)</span> due to a <span class="math inline">\(\delta\)</span> = one unit change in <span class="math inline">\(x\)</span>. <span class="math inline">\(\exp \delta \beta\)</span> is the relative risk ratio.</p>
<p><span class="math display">\[\pi_j / \pi_{j^*} |_{x = x_a} = \exp{\delta \hat{\beta}}\]</span></p>
<p>The intercept term is the log-relative risk of <span class="math inline">\(y_j\)</span> relative to <span class="math inline">\(y_{j^*}\)</span> for the reference case. The reference case in the model is <code>ses</code> = “low” and <code>write</code> centered at 52.8. Notice how the intercept matches the predicted values above.</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="generalized-linear-models-glm.html#cb130-1" tabindex="-1"></a>(ref_log_rr <span class="ot">&lt;-</span> <span class="fu">coef</span>(cs2<span class="sc">$</span>result)[,<span class="st">&quot;(Intercept)&quot;</span>])</span>
<span id="cb130-2"><a href="generalized-linear-models-glm.html#cb130-2" tabindex="-1"></a><span class="do">##    general   vocation </span></span>
<span id="cb130-3"><a href="generalized-linear-models-glm.html#cb130-3" tabindex="-1"></a><span class="do">## -0.2049851 -0.7771705</span></span>
<span id="cb130-4"><a href="generalized-linear-models-glm.html#cb130-4" tabindex="-1"></a></span>
<span id="cb130-5"><a href="generalized-linear-models-glm.html#cb130-5" tabindex="-1"></a><span class="co"># From log-relative risk to relative risk.</span></span>
<span id="cb130-6"><a href="generalized-linear-models-glm.html#cb130-6" tabindex="-1"></a>(ref_rr <span class="ot">&lt;-</span> <span class="fu">exp</span>(ref_log_rr))</span>
<span id="cb130-7"><a href="generalized-linear-models-glm.html#cb130-7" tabindex="-1"></a><span class="do">##   general  vocation </span></span>
<span id="cb130-8"><a href="generalized-linear-models-glm.html#cb130-8" tabindex="-1"></a><span class="do">## 0.8146595 0.4597049</span></span></code></pre></div>
<p>The log relative risks of a low SES student with a 52.8 writing score being in program general vs academic is <span class="math inline">\(\hat{y} = \mathrm{Intercept}_1\)</span> = -0.205, and <span class="math inline">\(\hat{y} = \mathrm{Intercept}_2\)</span> = -0.777 for vocation vs academic. The corresponding relative risks are <span class="math inline">\(\exp(\hat{y}_j)\)</span> = 0.815 and 0.460. The expected probabilities are 44.0%, 35.8%, and 20.2% for academic, general, and vocation respectively.</p>
<p>If SES was high instead of low, the expected probabilities of being in program general vs academic would be 70.1%, 17.8%, and 12.1% for academic, general, and vocation respectively.</p>
<p>What if the writing score increases by 1 SD (one unit)? The log RR of being in program general vs academic change by a factor of <code>coef(cs2$result)["general", "write"]</code> = -0.549, RR = 0.577. For program vocation vs academic, it would change by a factor of -1.077, RR = 0.341. To get a 2 SD increase, multiply the coefficient by 2, then exponentiate. The two RRs would then be 0.333 and 0.116.</p>
<p>Visualize the parameter estimates by plotting the predicted values.</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="generalized-linear-models-glm.html#cb131-1" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(</span>
<span id="cb131-2"><a href="generalized-linear-models-glm.html#cb131-2" tabindex="-1"></a>  <span class="at">ses =</span> <span class="fu">levels</span>(cs2<span class="sc">$</span>dat<span class="sc">$</span>ses),</span>
<span id="cb131-3"><a href="generalized-linear-models-glm.html#cb131-3" tabindex="-1"></a>  <span class="at">write =</span> <span class="fu">seq</span>(<span class="at">from =</span> <span class="fu">round</span>(<span class="fu">min</span>(cs2<span class="sc">$</span>dat_normalized<span class="sc">$</span>write)), </span>
<span id="cb131-4"><a href="generalized-linear-models-glm.html#cb131-4" tabindex="-1"></a>              <span class="at">to =</span> <span class="fu">round</span>(<span class="fu">max</span>(cs2<span class="sc">$</span>dat_normalized<span class="sc">$</span>write)), </span>
<span id="cb131-5"><a href="generalized-linear-models-glm.html#cb131-5" tabindex="-1"></a>              <span class="at">by =</span> <span class="dv">1</span>)</span>
<span id="cb131-6"><a href="generalized-linear-models-glm.html#cb131-6" tabindex="-1"></a>)</span>
<span id="cb131-7"><a href="generalized-linear-models-glm.html#cb131-7" tabindex="-1"></a></span>
<span id="cb131-8"><a href="generalized-linear-models-glm.html#cb131-8" tabindex="-1"></a><span class="fu">bind_cols</span>(</span>
<span id="cb131-9"><a href="generalized-linear-models-glm.html#cb131-9" tabindex="-1"></a>  new_data,</span>
<span id="cb131-10"><a href="generalized-linear-models-glm.html#cb131-10" tabindex="-1"></a>  <span class="fu">predict</span>(cs2<span class="sc">$</span>fit, <span class="at">new_data =</span> new_data, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)</span>
<span id="cb131-11"><a href="generalized-linear-models-glm.html#cb131-11" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb131-12"><a href="generalized-linear-models-glm.html#cb131-12" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="sc">-</span><span class="fu">c</span>(ses, write), <span class="at">names_to =</span> <span class="st">&quot;prog&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;probability&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb131-13"><a href="generalized-linear-models-glm.html#cb131-13" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> write, <span class="at">y =</span> probability, <span class="at">color =</span> ses)) <span class="sc">+</span></span>
<span id="cb131-14"><a href="generalized-linear-models-glm.html#cb131-14" tabindex="-1"></a>  <span class="fu">geom_line</span>() <span class="sc">+</span> </span>
<span id="cb131-15"><a href="generalized-linear-models-glm.html#cb131-15" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="at">facets =</span> <span class="fu">vars</span>(prog))</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-95-1.png" width="672" /></p>
</div>
<div id="assumptions-1" class="section level3 unnumbered hasAnchor">
<h3>Assumptions<a href="generalized-linear-models-glm.html#assumptions-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Four assumptions relate to the study design: (1) the dependent variable is multinomial; (2) the observations are independent; (3) the categories of all nominal variables are mutually exclusive and exhaustive; and (4) there are at least 10 observations per dependent variable level and independent variable. These assumptions are all valid. Three more assumptions related to the data distribution:</p>
<ul>
<li><p>There is a linear relationship between the logit transformation and the continuous independent variables. Test with a plot and with Box-Tidwell.</p></li>
<li><p>There is no independent variable multicollinearity. Test with correlation coefficients and variance inflation factors (VIF).</p></li>
<li><p>There are no influential outliers. Test with Cook’s distance.</p></li>
</ul>
<p>There are two ways to test for linearity (do both). First, plot the <em>fitted values</em> against the continuous predictors. This is the GLM analog to OLS bivariate analysis, except now the dependent variable is the <em>logit</em> transformation. These plotted relationships look good, except that in the <code>prog</code> = general level, writing score appears to interact with SES.</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="generalized-linear-models-glm.html#cb132-1" tabindex="-1"></a>cs2<span class="sc">$</span>fit <span class="sc">%&gt;%</span></span>
<span id="cb132-2"><a href="generalized-linear-models-glm.html#cb132-2" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">new_data =</span> cs2<span class="sc">$</span>dat_normalized) <span class="sc">%&gt;%</span></span>
<span id="cb132-3"><a href="generalized-linear-models-glm.html#cb132-3" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="fu">c</span>(.pred_academic<span class="sc">:</span>.pred_vocation), <span class="at">values_to =</span> <span class="st">&quot;.fitted&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb132-4"><a href="generalized-linear-models-glm.html#cb132-4" tabindex="-1"></a>  <span class="fu">filter</span>(<span class="fu">str_detect</span>(name, <span class="fu">as.character</span>(prog))) <span class="sc">%&gt;%</span></span>
<span id="cb132-5"><a href="generalized-linear-models-glm.html#cb132-5" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> write, <span class="at">y =</span> .fitted, <span class="at">color =</span> ses)) <span class="sc">+</span></span>
<span id="cb132-6"><a href="generalized-linear-models-glm.html#cb132-6" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb132-7"><a href="generalized-linear-models-glm.html#cb132-7" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="at">facets =</span> <span class="fu">vars</span>(prog), <span class="at">scales =</span> <span class="st">&quot;free_x&quot;</span>) <span class="sc">+</span></span>
<span id="cb132-8"><a href="generalized-linear-models-glm.html#cb132-8" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="at">formula =</span> <span class="st">&quot;y~x&quot;</span>) <span class="sc">+</span></span>
<span id="cb132-9"><a href="generalized-linear-models-glm.html#cb132-9" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Linearity Test: predicted vs continuous predictors&quot;</span>, <span class="at">x =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-96-1.png" width="672" /></p>
<p>The second test for linearity is the Box-Tidwell approach. Add transformations of the continuous independent variables to the model, <span class="math inline">\(x_{Tx} = x \log x\)</span>, then test their significance level in the fit. Focus on the transformed variable. <code>write_tx</code> has a <em>p</em>-value &lt;.05 for general. It is customary to apply a Bonferroni adjustment when testing for linearity. There are ten predictors in the model (including the intercept terms), so the Bonferroni adjusted <em>p</em>-values for <code>write_tx</code> are multiplied by 10. We should reject the null hypothesis of linearity because the adjusted p.value is still below .05.</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="generalized-linear-models-glm.html#cb133-1" tabindex="-1"></a><span class="co"># Using non-centered vars to avoid log(0) errors.</span></span>
<span id="cb133-2"><a href="generalized-linear-models-glm.html#cb133-2" tabindex="-1"></a>cs2<span class="sc">$</span>boxtidwell <span class="ot">&lt;-</span> cs2<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb133-3"><a href="generalized-linear-models-glm.html#cb133-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">write_tx =</span> <span class="fu">log</span>(write) <span class="sc">*</span> write) <span class="sc">%&gt;%</span></span>
<span id="cb133-4"><a href="generalized-linear-models-glm.html#cb133-4" tabindex="-1"></a>  <span class="fu">fit</span>(cs2<span class="sc">$</span>model, prog <span class="sc">~</span> ses <span class="sc">+</span> write <span class="sc">+</span> write_tx, <span class="at">data =</span> .)</span>
<span id="cb133-5"><a href="generalized-linear-models-glm.html#cb133-5" tabindex="-1"></a></span>
<span id="cb133-6"><a href="generalized-linear-models-glm.html#cb133-6" tabindex="-1"></a><span class="fu">tidy</span>(cs2<span class="sc">$</span>boxtidwell) <span class="sc">%&gt;%</span> <span class="fu">filter</span>(term <span class="sc">==</span> <span class="st">&quot;write_tx&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">adj_p =</span> p.value <span class="sc">*</span> <span class="dv">10</span>)</span></code></pre></div>
<pre><code>## # A tibble: 2 × 7
##   y.level  term     estimate std.error statistic p.value  adj_p
##   &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt;  &lt;dbl&gt;
## 1 general  write_tx   0.0713    0.0231     3.09  0.00198 0.0198
## 2 vocation write_tx   0.0125    0.0239     0.522 0.601   6.01</code></pre>
<p>If the relationship is nonlinear, you can try transforming the variable by raising it to <span class="math inline">\(\lambda = 1 + b / \gamma\)</span> where <span class="math inline">\(b\)</span> is the estimated coefficient of the model without the interaction terms, and <span class="math inline">\(\gamma\)</span> is the estimated coefficient of the interaction term of the model with interactions. For <code>write</code>, <span class="math inline">\(b\)</span> is for general and <span class="math inline">\(\gamma\)</span> is , so <span class="math inline">\(\lambda\)</span> = 1 + / = . It seems customary to apply general transformations like .5 (square root), 1/3 (cube root), ln, and the reciprocal, so maybe try raising <code>write_c</code> to . It seems in this case that the better solution is to add an interaction between <code>write_c</code> and <code>ses</code> to the model. I’m not going to pursue this further here.</p>
<p>Check for multicollinearity using variance inflation factors (VIF). VIFs estimate how much the variance of a regression coefficient is inflated due to multicollinearity. When independent variables are correlated, it is difficult to say which variable really influences the dependent variable. The VIF for variable <span class="math inline">\(i\)</span> is</p>
<p><span class="math display">\[
\mathrm{VIF}_i = \frac{1}{1 - R_i^2}
\]</span></p>
<p>where <span class="math inline">\(R_i^2\)</span> is the coefficient of determination (i.e., the proportion of dependent variance explained by the model) of a regression of <span class="math inline">\(X_i\)</span> against all of the other predictors, <span class="math inline">\(X_i = X_{j \ne i} \beta + \epsilon\)</span>. If <span class="math inline">\(X_i\)</span> is totally unrelated to its covariates, then <span class="math inline">\(R_i^2\)</span> will be zero and <span class="math inline">\(\mathrm{VIF}_i\)</span> will be 1. If <span class="math inline">\(R_i^2\)</span> is .8, <span class="math inline">\(\mathrm{VIF}_i\)</span> will be 5. The rule of thumb is that <span class="math inline">\(R_i^2 \le 5\)</span> is tolerable, and <span class="math inline">\(R_i^2 &gt; 5\)</span> is “highly correlated” and you have to do something about it. <code>car::vif()</code> doesn’t work for multinomial logistic regression. The model type is not actually important here - we’re concerned about the covariate relationships. Below, I successively collapse the dependent variable into two-levels, then fit a binomial logistic regression and pipe that into <code>car::vif()</code>.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="generalized-linear-models-glm.html#cb135-1" tabindex="-1"></a>tmp_fit_general <span class="ot">&lt;-</span></span>
<span id="cb135-2"><a href="generalized-linear-models-glm.html#cb135-2" tabindex="-1"></a>  <span class="fu">logistic_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb135-3"><a href="generalized-linear-models-glm.html#cb135-3" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb135-4"><a href="generalized-linear-models-glm.html#cb135-4" tabindex="-1"></a>    prog <span class="sc">~</span> ses <span class="sc">+</span> write, </span>
<span id="cb135-5"><a href="generalized-linear-models-glm.html#cb135-5" tabindex="-1"></a>    <span class="at">data =</span> cs2<span class="sc">$</span>dat_normalized <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">prog =</span> <span class="fu">fct_collapse</span>(prog, <span class="at">vocation =</span> <span class="st">&quot;academic&quot;</span>))</span>
<span id="cb135-6"><a href="generalized-linear-models-glm.html#cb135-6" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb135-7"><a href="generalized-linear-models-glm.html#cb135-7" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>() </span>
<span id="cb135-8"><a href="generalized-linear-models-glm.html#cb135-8" tabindex="-1"></a></span>
<span id="cb135-9"><a href="generalized-linear-models-glm.html#cb135-9" tabindex="-1"></a>tmp_fit_general <span class="sc">%&gt;%</span> car<span class="sc">::</span><span class="fu">vif</span>()</span>
<span id="cb135-10"><a href="generalized-linear-models-glm.html#cb135-10" tabindex="-1"></a><span class="do">##           GVIF Df GVIF^(1/(2*Df))</span></span>
<span id="cb135-11"><a href="generalized-linear-models-glm.html#cb135-11" tabindex="-1"></a><span class="do">## ses   1.037207  2        1.009175</span></span>
<span id="cb135-12"><a href="generalized-linear-models-glm.html#cb135-12" tabindex="-1"></a><span class="do">## write 1.037207  1        1.018433</span></span>
<span id="cb135-13"><a href="generalized-linear-models-glm.html#cb135-13" tabindex="-1"></a></span>
<span id="cb135-14"><a href="generalized-linear-models-glm.html#cb135-14" tabindex="-1"></a>tmp_fit_vocation <span class="ot">&lt;-</span> </span>
<span id="cb135-15"><a href="generalized-linear-models-glm.html#cb135-15" tabindex="-1"></a>  <span class="fu">logistic_reg</span>() <span class="sc">%&gt;%</span></span>
<span id="cb135-16"><a href="generalized-linear-models-glm.html#cb135-16" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb135-17"><a href="generalized-linear-models-glm.html#cb135-17" tabindex="-1"></a>    prog <span class="sc">~</span> ses <span class="sc">+</span> write, </span>
<span id="cb135-18"><a href="generalized-linear-models-glm.html#cb135-18" tabindex="-1"></a>    <span class="at">data =</span> cs2<span class="sc">$</span>dat_normalized <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">prog =</span> <span class="fu">fct_collapse</span>(prog, <span class="at">general =</span> <span class="st">&quot;academic&quot;</span>))</span>
<span id="cb135-19"><a href="generalized-linear-models-glm.html#cb135-19" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb135-20"><a href="generalized-linear-models-glm.html#cb135-20" tabindex="-1"></a>  <span class="fu">extract_fit_engine</span>()</span>
<span id="cb135-21"><a href="generalized-linear-models-glm.html#cb135-21" tabindex="-1"></a></span>
<span id="cb135-22"><a href="generalized-linear-models-glm.html#cb135-22" tabindex="-1"></a>tmp_fit_vocation <span class="sc">%&gt;%</span> car<span class="sc">::</span><span class="fu">vif</span>()</span>
<span id="cb135-23"><a href="generalized-linear-models-glm.html#cb135-23" tabindex="-1"></a><span class="do">##           GVIF Df GVIF^(1/(2*Df))</span></span>
<span id="cb135-24"><a href="generalized-linear-models-glm.html#cb135-24" tabindex="-1"></a><span class="do">## ses   1.020017  2        1.004967</span></span>
<span id="cb135-25"><a href="generalized-linear-models-glm.html#cb135-25" tabindex="-1"></a><span class="do">## write 1.020017  1        1.009959</span></span></code></pre></div>
<p>Check for influential outliers. Outliers are predicted values greater than two standard deviations from the actual value. Influential points have a Cook’s Distance greater than 4/N (4 / 200 = 0.02.<a href="#fn12" class="footnote-ref" id="fnref12"><sup>12</sup></a> Influential outliers are both. There is no simple way to do this for the multinomial regression because neither VGAM nor nnet support the <code>augment()</code> generic. Instead, I will use the two <em>binomial logistic</em> regressions from the VIF diagnostic.</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="generalized-linear-models-glm.html#cb136-1" tabindex="-1"></a>outlier_dat <span class="ot">&lt;-</span></span>
<span id="cb136-2"><a href="generalized-linear-models-glm.html#cb136-2" tabindex="-1"></a>  <span class="fu">bind_rows</span>(</span>
<span id="cb136-3"><a href="generalized-linear-models-glm.html#cb136-3" tabindex="-1"></a>    <span class="at">general =</span> <span class="fu">augment</span>(tmp_fit_general, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>),</span>
<span id="cb136-4"><a href="generalized-linear-models-glm.html#cb136-4" tabindex="-1"></a>    <span class="at">vocation =</span> <span class="fu">augment</span>(tmp_fit_vocation, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>),</span>
<span id="cb136-5"><a href="generalized-linear-models-glm.html#cb136-5" tabindex="-1"></a>    <span class="at">.id =</span> <span class="st">&quot;logit&quot;</span></span>
<span id="cb136-6"><a href="generalized-linear-models-glm.html#cb136-6" tabindex="-1"></a>  ) <span class="sc">%&gt;%</span></span>
<span id="cb136-7"><a href="generalized-linear-models-glm.html#cb136-7" tabindex="-1"></a>  <span class="fu">mutate</span>(</span>
<span id="cb136-8"><a href="generalized-linear-models-glm.html#cb136-8" tabindex="-1"></a>    <span class="at">id =</span> <span class="fu">row_number</span>(),</span>
<span id="cb136-9"><a href="generalized-linear-models-glm.html#cb136-9" tabindex="-1"></a>    <span class="at">outlier =</span> <span class="fu">if_else</span>(<span class="fu">abs</span>(.std.resid) <span class="sc">&gt;=</span> <span class="dv">2</span>, <span class="st">&quot;Outlier&quot;</span>, <span class="st">&quot;Other&quot;</span>),</span>
<span id="cb136-10"><a href="generalized-linear-models-glm.html#cb136-10" tabindex="-1"></a>    <span class="at">influential =</span> <span class="fu">if_else</span>(.cooksd <span class="sc">&gt;</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">nrow</span>(cs1<span class="sc">$</span>dat), <span class="st">&quot;Influential&quot;</span>, <span class="st">&quot;Other&quot;</span>),</span>
<span id="cb136-11"><a href="generalized-linear-models-glm.html#cb136-11" tabindex="-1"></a>    <span class="at">status =</span> <span class="fu">case_when</span>(</span>
<span id="cb136-12"><a href="generalized-linear-models-glm.html#cb136-12" tabindex="-1"></a>      outlier <span class="sc">==</span> <span class="st">&quot;Outlier&quot;</span> <span class="sc">&amp;</span> influential <span class="sc">==</span> <span class="st">&quot;Influential&quot;</span> <span class="sc">~</span> <span class="st">&quot;Influential Outlier&quot;</span>,</span>
<span id="cb136-13"><a href="generalized-linear-models-glm.html#cb136-13" tabindex="-1"></a>      outlier <span class="sc">==</span> <span class="st">&quot;Outlier&quot;</span> <span class="sc">~</span> <span class="st">&quot;Outlier&quot;</span>,</span>
<span id="cb136-14"><a href="generalized-linear-models-glm.html#cb136-14" tabindex="-1"></a>      influential <span class="sc">==</span> <span class="st">&quot;Influential&quot;</span> <span class="sc">~</span> <span class="st">&quot;Influential&quot;</span>,</span>
<span id="cb136-15"><a href="generalized-linear-models-glm.html#cb136-15" tabindex="-1"></a>      <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;Other&quot;</span></span>
<span id="cb136-16"><a href="generalized-linear-models-glm.html#cb136-16" tabindex="-1"></a>    ),</span>
<span id="cb136-17"><a href="generalized-linear-models-glm.html#cb136-17" tabindex="-1"></a>    <span class="at">status =</span> <span class="fu">factor</span>(status, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;Influential&quot;</span>, <span class="st">&quot;Outlier&quot;</span>, <span class="st">&quot;Influential Outlier&quot;</span>, <span class="st">&quot;Other&quot;</span>))</span>
<span id="cb136-18"><a href="generalized-linear-models-glm.html#cb136-18" tabindex="-1"></a>  )</span>
<span id="cb136-19"><a href="generalized-linear-models-glm.html#cb136-19" tabindex="-1"></a></span>
<span id="cb136-20"><a href="generalized-linear-models-glm.html#cb136-20" tabindex="-1"></a>outlier_dat <span class="sc">%&gt;%</span></span>
<span id="cb136-21"><a href="generalized-linear-models-glm.html#cb136-21" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> .fitted, <span class="at">y =</span> .cooksd)) <span class="sc">+</span></span>
<span id="cb136-22"><a href="generalized-linear-models-glm.html#cb136-22" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> status)) <span class="sc">+</span></span>
<span id="cb136-23"><a href="generalized-linear-models-glm.html#cb136-23" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> <span class="fu">if_else</span>(influential <span class="sc">==</span> <span class="st">&quot;Influential&quot;</span>, id, <span class="cn">NA_integer_</span>)), </span>
<span id="cb136-24"><a href="generalized-linear-models-glm.html#cb136-24" tabindex="-1"></a>            <span class="at">check_overlap =</span> <span class="cn">TRUE</span>, <span class="at">size =</span> <span class="dv">3</span>, <span class="at">nudge_x =</span> .<span class="dv">025</span>) <span class="sc">+</span></span>
<span id="cb136-25"><a href="generalized-linear-models-glm.html#cb136-25" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">4</span> <span class="sc">/</span> <span class="fu">nrow</span>(cs1<span class="sc">$</span>dat), <span class="at">linetype =</span> <span class="dv">2</span>, <span class="at">color =</span> <span class="st">&quot;goldenrod&quot;</span>) <span class="sc">+</span> </span>
<span id="cb136-26"><a href="generalized-linear-models-glm.html#cb136-26" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;Influential Outlier&quot;</span> <span class="ot">=</span> <span class="st">&quot;firebrick&quot;</span>, </span>
<span id="cb136-27"><a href="generalized-linear-models-glm.html#cb136-27" tabindex="-1"></a>                                <span class="st">&quot;Influential&quot;</span> <span class="ot">=</span> <span class="st">&quot;goldenrod&quot;</span>,</span>
<span id="cb136-28"><a href="generalized-linear-models-glm.html#cb136-28" tabindex="-1"></a>                                <span class="st">&quot;Outlier&quot;</span> <span class="ot">=</span> <span class="st">&quot;salmon&quot;</span>,</span>
<span id="cb136-29"><a href="generalized-linear-models-glm.html#cb136-29" tabindex="-1"></a>                                <span class="st">&quot;Other&quot;</span> <span class="ot">=</span> <span class="st">&quot;black&quot;</span>)) <span class="sc">+</span></span>
<span id="cb136-30"><a href="generalized-linear-models-glm.html#cb136-30" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;right&quot;</span>) <span class="sc">+</span></span>
<span id="cb136-31"><a href="generalized-linear-models-glm.html#cb136-31" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Index Plot of Cook&#39;s Distance.&quot;</span>,</span>
<span id="cb136-32"><a href="generalized-linear-models-glm.html#cb136-32" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Row id labeled for influential points.&quot;</span>) <span class="sc">+</span></span>
<span id="cb136-33"><a href="generalized-linear-models-glm.html#cb136-33" tabindex="-1"></a>  <span class="fu">facet_wrap</span>(<span class="at">facets =</span> <span class="fu">vars</span>(logit), <span class="at">ncol =</span> <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## Warning: Removed 396 rows containing missing values (`geom_text()`).</code></pre>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-99-1.png" width="672" /></p>
<p>No fitted values were influential outliers in the first fit, and only two were influential outliers in the second fit.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="generalized-linear-models-glm.html#cb138-1" tabindex="-1"></a>(cs2<span class="sc">$</span>outliers <span class="ot">&lt;-</span></span>
<span id="cb138-2"><a href="generalized-linear-models-glm.html#cb138-2" tabindex="-1"></a>  outlier_dat <span class="sc">%&gt;%</span> <span class="fu">filter</span>(status <span class="sc">==</span> <span class="st">&quot;Influential Outlier&quot;</span>) <span class="sc">%&gt;%</span> <span class="fu">pull</span>(.std.resid))</span></code></pre></div>
<pre><code>## [1] 2.202098 2.593458</code></pre>
<p>An index plot of Cook’s Distance shows the two points at the far left. You might examine the observations for validity. Otherwise, proceed and explain that there were two standardized residuals with value of 2.20 and 2.59 standard deviations which were kept in the analysis.</p>
</div>
<div id="evaluate-the-fit-1" class="section level3 unnumbered hasAnchor">
<h3>Evaluate the Fit<a href="generalized-linear-models-glm.html#evaluate-the-fit-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are several ways to evaluate the model fit.</p>
<ul>
<li>Deviance and chi-squared tests for lack of fit</li>
<li>The likelihood ratio test</li>
<li>Pseudo R-squared<a href="#fn13" class="footnote-ref" id="fnref13"><sup>13</sup></a>.</li>
<li>Accuracy measures</li>
<li>Gain and ROC curves</li>
</ul>
<p>The <strong>deviance test</strong> for lack of fit and the <strong>likelihood ratio test</strong> are residuals tests. The deviance residual is defined as <span class="math inline">\(d_i = \mathrm{sign}(\epsilon_i) \left[ -2(y_i \log \hat{\pi}_i + (1 - y_i) \log (1 - \hat{\pi}_i)) \right]^{.5}\)</span>. The model deviance, <span class="math inline">\(G^2\)</span>, is the sum of the squared deviance residuals. It also equals <span class="math inline">\(G^2 = 2 \sum_{i,j}y_{ij} \log \frac{y_{ij}}{\hat{\pi}_{ij}}\)</span>. You can calculate them by hand.</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="generalized-linear-models-glm.html#cb140-1" tabindex="-1"></a><span class="co"># Actual values (1s and 0s for three response levels)</span></span>
<span id="cb140-2"><a href="generalized-linear-models-glm.html#cb140-2" tabindex="-1"></a>y <span class="ot">&lt;-</span> cs2<span class="sc">$</span>dat <span class="sc">%&gt;%</span> </span>
<span id="cb140-3"><a href="generalized-linear-models-glm.html#cb140-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">val =</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb140-4"><a href="generalized-linear-models-glm.html#cb140-4" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> prog, <span class="at">values_from =</span> val, <span class="at">values_fill =</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb140-5"><a href="generalized-linear-models-glm.html#cb140-5" tabindex="-1"></a>  <span class="fu">select</span>(<span class="fu">levels</span>(cs2<span class="sc">$</span>dat<span class="sc">$</span>prog)) <span class="sc">%&gt;%</span></span>
<span id="cb140-6"><a href="generalized-linear-models-glm.html#cb140-6" tabindex="-1"></a>  <span class="fu">as.matrix</span>()</span>
<span id="cb140-7"><a href="generalized-linear-models-glm.html#cb140-7" tabindex="-1"></a></span>
<span id="cb140-8"><a href="generalized-linear-models-glm.html#cb140-8" tabindex="-1"></a><span class="co"># Predicted values (probabilities for three response levels)</span></span>
<span id="cb140-9"><a href="generalized-linear-models-glm.html#cb140-9" tabindex="-1"></a>pi <span class="ot">&lt;-</span> <span class="fu">predict</span>(cs2<span class="sc">$</span>result, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>) <span class="sc">*</span> <span class="dv">1</span></span>
<span id="cb140-10"><a href="generalized-linear-models-glm.html#cb140-10" tabindex="-1"></a></span>
<span id="cb140-11"><a href="generalized-linear-models-glm.html#cb140-11" tabindex="-1"></a><span class="co"># Raw residuals, by hand or by formula</span></span>
<span id="cb140-12"><a href="generalized-linear-models-glm.html#cb140-12" tabindex="-1"></a><span class="co"># e &lt;- y - pi</span></span>
<span id="cb140-13"><a href="generalized-linear-models-glm.html#cb140-13" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">residuals</span>(cs2<span class="sc">$</span>result, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span>
<span id="cb140-14"><a href="generalized-linear-models-glm.html#cb140-14" tabindex="-1"></a></span>
<span id="cb140-15"><a href="generalized-linear-models-glm.html#cb140-15" tabindex="-1"></a><span class="co"># Deviance residuals</span></span>
<span id="cb140-16"><a href="generalized-linear-models-glm.html#cb140-16" tabindex="-1"></a>d <span class="ot">&lt;-</span> <span class="fu">sign</span>(e) <span class="sc">*</span> <span class="fu">sqrt</span>(<span class="sc">-</span><span class="dv">2</span> <span class="sc">*</span> y <span class="sc">*</span> <span class="fu">log</span>(pi) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> y) <span class="sc">*</span> <span class="fu">log</span>(<span class="dv">1</span> <span class="sc">-</span> pi))</span>
<span id="cb140-17"><a href="generalized-linear-models-glm.html#cb140-17" tabindex="-1"></a></span>
<span id="cb140-18"><a href="generalized-linear-models-glm.html#cb140-18" tabindex="-1"></a>(g2 <span class="ot">&lt;-</span> <span class="fu">sum</span>(d<span class="sc">^</span><span class="dv">2</span>, <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span>
<span id="cb140-19"><a href="generalized-linear-models-glm.html#cb140-19" tabindex="-1"></a><span class="do">## [1] 359.9635</span></span>
<span id="cb140-20"><a href="generalized-linear-models-glm.html#cb140-20" tabindex="-1"></a>(g2 <span class="ot">&lt;-</span> <span class="dv">2</span> <span class="sc">*</span> <span class="fu">sum</span>(y <span class="sc">*</span> <span class="fu">log</span>(y <span class="sc">/</span> pi), <span class="at">na.rm =</span> <span class="cn">TRUE</span>))</span>
<span id="cb140-21"><a href="generalized-linear-models-glm.html#cb140-21" tabindex="-1"></a><span class="do">## [1] 359.9635</span></span>
<span id="cb140-22"><a href="generalized-linear-models-glm.html#cb140-22" tabindex="-1"></a>(g2 <span class="ot">&lt;-</span> <span class="fu">deviance</span>(cs2<span class="sc">$</span>result))</span>
<span id="cb140-23"><a href="generalized-linear-models-glm.html#cb140-23" tabindex="-1"></a><span class="do">## [1] 359.9635</span></span></code></pre></div>
<p>The related Pearson statistic, <span class="math inline">\(X\)</span>, is the sum of the squared <em>Pearson residuals</em>, <span class="math inline">\(pr_i = \epsilon_i / \sqrt{\hat{\pi}_i}\)</span>, the raw residual scaled by dividing by the estimated standard deviation of a binomial distribution with 1 trial. I don’t see this calculated in the <code>residual()</code> functions. You can do it yourself.</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="generalized-linear-models-glm.html#cb141-1" tabindex="-1"></a>(x2 <span class="ot">&lt;-</span> <span class="fu">sum</span>((e <span class="sc">/</span> <span class="fu">sqrt</span>(pi))<span class="sc">^</span><span class="dv">2</span>))</span>
<span id="cb141-2"><a href="generalized-linear-models-glm.html#cb141-2" tabindex="-1"></a><span class="do">## [1] 406.0656</span></span></code></pre></div>
<p>The deviance and Pearson statistic are distributed chi-squared with <span class="math inline">\((N - p)(r - 1)\)</span> degrees of freedom where <span class="math inline">\(p\)</span> = 4 predictor variables (3 SES levels + intercept), and <span class="math inline">\(r\)</span> = 3 levels of the dependent variable for 392 degrees of freedom. The deviance and Pearson tests for lack of fit calculate the probability of the test statistic. The null hypothesis is that the model is correct. Neither test rejects the null hypothesis.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="generalized-linear-models-glm.html#cb142-1" tabindex="-1"></a><span class="co"># Deviance test for lack of fit</span></span>
<span id="cb142-2"><a href="generalized-linear-models-glm.html#cb142-2" tabindex="-1"></a>(N <span class="ot">&lt;-</span> <span class="fu">nrow</span>(cs2<span class="sc">$</span>dat))</span>
<span id="cb142-3"><a href="generalized-linear-models-glm.html#cb142-3" tabindex="-1"></a><span class="do">## [1] 200</span></span>
<span id="cb142-4"><a href="generalized-linear-models-glm.html#cb142-4" tabindex="-1"></a>(r <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">levels</span>(cs2<span class="sc">$</span>dat<span class="sc">$</span>prog)))</span>
<span id="cb142-5"><a href="generalized-linear-models-glm.html#cb142-5" tabindex="-1"></a><span class="do">## [1] 3</span></span>
<span id="cb142-6"><a href="generalized-linear-models-glm.html#cb142-6" tabindex="-1"></a>(p <span class="ot">&lt;-</span> <span class="fu">length</span>(<span class="fu">coef</span>(cs2<span class="sc">$</span>result)) <span class="sc">/</span> (r <span class="sc">-</span> <span class="dv">1</span>)) <span class="co"># coefficients for each level, so divide by # levels</span></span>
<span id="cb142-7"><a href="generalized-linear-models-glm.html#cb142-7" tabindex="-1"></a><span class="do">## [1] 4</span></span>
<span id="cb142-8"><a href="generalized-linear-models-glm.html#cb142-8" tabindex="-1"></a>(df <span class="ot">&lt;-</span> (N <span class="sc">-</span> p) <span class="sc">*</span> (r <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb142-9"><a href="generalized-linear-models-glm.html#cb142-9" tabindex="-1"></a><span class="do">## [1] 392</span></span>
<span id="cb142-10"><a href="generalized-linear-models-glm.html#cb142-10" tabindex="-1"></a></span>
<span id="cb142-11"><a href="generalized-linear-models-glm.html#cb142-11" tabindex="-1"></a><span class="fu">pchisq</span>(g2, df, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb142-12"><a href="generalized-linear-models-glm.html#cb142-12" tabindex="-1"></a><span class="do">## [1] 0.8755302</span></span>
<span id="cb142-13"><a href="generalized-linear-models-glm.html#cb142-13" tabindex="-1"></a></span>
<span id="cb142-14"><a href="generalized-linear-models-glm.html#cb142-14" tabindex="-1"></a><span class="fu">pchisq</span>(x2, df, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb142-15"><a href="generalized-linear-models-glm.html#cb142-15" tabindex="-1"></a><span class="do">## [1] 0.3014625</span></span></code></pre></div>
<p>You can do the same calculations for the intercept-only model.</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="generalized-linear-models-glm.html#cb143-1" tabindex="-1"></a>io <span class="ot">&lt;-</span> <span class="fu">multinom_reg</span>() <span class="sc">%&gt;%</span> <span class="fu">fit</span>(prog <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> cs2<span class="sc">$</span>dat) <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>()</span>
<span id="cb143-2"><a href="generalized-linear-models-glm.html#cb143-2" tabindex="-1"></a></span>
<span id="cb143-3"><a href="generalized-linear-models-glm.html#cb143-3" tabindex="-1"></a><span class="fu">deviance</span>(io)</span>
<span id="cb143-4"><a href="generalized-linear-models-glm.html#cb143-4" tabindex="-1"></a><span class="do">## [1] 408.1933</span></span>
<span id="cb143-5"><a href="generalized-linear-models-glm.html#cb143-5" tabindex="-1"></a></span>
<span id="cb143-6"><a href="generalized-linear-models-glm.html#cb143-6" tabindex="-1"></a><span class="co"># degrees of freedom</span></span>
<span id="cb143-7"><a href="generalized-linear-models-glm.html#cb143-7" tabindex="-1"></a>((<span class="fu">nrow</span>(cs2<span class="sc">$</span>dat) <span class="sc">-</span> <span class="fu">length</span>(<span class="fu">coef</span>(io)) <span class="sc">/</span> (r <span class="sc">-</span> <span class="dv">1</span>)) <span class="sc">*</span> (r <span class="sc">-</span> <span class="dv">1</span>))</span>
<span id="cb143-8"><a href="generalized-linear-models-glm.html#cb143-8" tabindex="-1"></a><span class="do">## [1] 398</span></span></code></pre></div>
<p>The log-likelihood measures the unexplained variability in the model. The <strong>likelihood ratio test</strong> compares the log likelihood of the fitted model to the intercept-only model. You can use <code>lmtest::lrtest()</code> to test. <code>anova()</code> does the same thing using the residual deviance, <span class="math inline">\(G2 = -2 \times \mathrm{log likelihood}\)</span>, although it does not seem to work with the <code>nnet</code> engine.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="generalized-linear-models-glm.html#cb144-1" tabindex="-1"></a>(cs2<span class="sc">$</span>lrtest <span class="ot">&lt;-</span> lmtest<span class="sc">::</span><span class="fu">lrtest</span>(io, cs2<span class="sc">$</span>result))</span></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: prog ~ 1
## Model 2: prog ~ ses + write
##   #Df  LogLik Df Chisq Pr(&gt;Chisq)    
## 1   2 -204.10                        
## 2   8 -179.98  6 48.23  1.063e-08 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="generalized-linear-models-glm.html#cb146-1" tabindex="-1"></a><span class="co"># (cs2$lrtest &lt;- anova(io, cs2$result, type = &quot;I&quot;, test = &quot;LR&quot;))</span></span></code></pre></div>
<p>The difference in deviances is <span class="math inline">\(LR\)</span> = 48.23 with 6 degrees of freedom. This is distributed chi-squared, with <em>p</em>-value = 1.063e-08. The deviance test for lack of fit concludes that the model fits significantly better than an empty (intercept-only) model, <span class="math inline">\(\chi^2\)</span>(6) = 48.23, p &lt; .001.</p>
<p>You can use <code>lmtest::lrtest()</code> to perform likelihood ratio tests on the significance of the predictors too. The likelihood ratio test compares the log likelihood with and without the predictor. Unfortunately, this does not seem to work within the <code>parsnip</code> framework.</p>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="generalized-linear-models-glm.html#cb147-1" tabindex="-1"></a><span class="co"># (cs2$lrtest_ses &lt;- lmtest::lrtest(cs2$result, &quot;ses&quot;))</span></span>
<span id="cb147-2"><a href="generalized-linear-models-glm.html#cb147-2" tabindex="-1"></a>no_ses <span class="ot">&lt;-</span> <span class="fu">multinom_reg</span>() <span class="sc">%&gt;%</span> <span class="fu">fit</span>(prog <span class="sc">~</span> write, <span class="at">data =</span> cs2<span class="sc">$</span>dat) <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>()</span>
<span id="cb147-3"><a href="generalized-linear-models-glm.html#cb147-3" tabindex="-1"></a>(cs2<span class="sc">$</span>lrtest_ses <span class="ot">&lt;-</span> lmtest<span class="sc">::</span><span class="fu">lrtest</span>(cs2<span class="sc">$</span>result, no_ses))</span>
<span id="cb147-4"><a href="generalized-linear-models-glm.html#cb147-4" tabindex="-1"></a><span class="do">## Likelihood ratio test</span></span>
<span id="cb147-5"><a href="generalized-linear-models-glm.html#cb147-5" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb147-6"><a href="generalized-linear-models-glm.html#cb147-6" tabindex="-1"></a><span class="do">## Model 1: prog ~ ses + write</span></span>
<span id="cb147-7"><a href="generalized-linear-models-glm.html#cb147-7" tabindex="-1"></a><span class="do">## Model 2: prog ~ write</span></span>
<span id="cb147-8"><a href="generalized-linear-models-glm.html#cb147-8" tabindex="-1"></a><span class="do">##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)  </span></span>
<span id="cb147-9"><a href="generalized-linear-models-glm.html#cb147-9" tabindex="-1"></a><span class="do">## 1   8 -179.98                       </span></span>
<span id="cb147-10"><a href="generalized-linear-models-glm.html#cb147-10" tabindex="-1"></a><span class="do">## 2   4 -185.51 -4 11.058    0.02592 *</span></span>
<span id="cb147-11"><a href="generalized-linear-models-glm.html#cb147-11" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb147-12"><a href="generalized-linear-models-glm.html#cb147-12" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb147-13"><a href="generalized-linear-models-glm.html#cb147-13" tabindex="-1"></a></span>
<span id="cb147-14"><a href="generalized-linear-models-glm.html#cb147-14" tabindex="-1"></a><span class="co"># (cs2$lrtest_write &lt;- lmtest::lrtest(cs2$fit_nnet, &quot;write&quot;))</span></span>
<span id="cb147-15"><a href="generalized-linear-models-glm.html#cb147-15" tabindex="-1"></a>no_write <span class="ot">&lt;-</span> <span class="fu">multinom_reg</span>() <span class="sc">%&gt;%</span> <span class="fu">fit</span>(prog <span class="sc">~</span> ses, <span class="at">data =</span> cs2<span class="sc">$</span>dat) <span class="sc">%&gt;%</span> <span class="fu">extract_fit_engine</span>()</span>
<span id="cb147-16"><a href="generalized-linear-models-glm.html#cb147-16" tabindex="-1"></a>(cs2<span class="sc">$</span>lrtest_write <span class="ot">&lt;-</span> lmtest<span class="sc">::</span><span class="fu">lrtest</span>(cs2<span class="sc">$</span>result, no_write))</span>
<span id="cb147-17"><a href="generalized-linear-models-glm.html#cb147-17" tabindex="-1"></a><span class="do">## Likelihood ratio test</span></span>
<span id="cb147-18"><a href="generalized-linear-models-glm.html#cb147-18" tabindex="-1"></a><span class="do">## </span></span>
<span id="cb147-19"><a href="generalized-linear-models-glm.html#cb147-19" tabindex="-1"></a><span class="do">## Model 1: prog ~ ses + write</span></span>
<span id="cb147-20"><a href="generalized-linear-models-glm.html#cb147-20" tabindex="-1"></a><span class="do">## Model 2: prog ~ ses</span></span>
<span id="cb147-21"><a href="generalized-linear-models-glm.html#cb147-21" tabindex="-1"></a><span class="do">##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)    </span></span>
<span id="cb147-22"><a href="generalized-linear-models-glm.html#cb147-22" tabindex="-1"></a><span class="do">## 1   8 -179.98                         </span></span>
<span id="cb147-23"><a href="generalized-linear-models-glm.html#cb147-23" tabindex="-1"></a><span class="do">## 2   6 -195.71 -2 31.447  1.484e-07 ***</span></span>
<span id="cb147-24"><a href="generalized-linear-models-glm.html#cb147-24" tabindex="-1"></a><span class="do">## ---</span></span>
<span id="cb147-25"><a href="generalized-linear-models-glm.html#cb147-25" tabindex="-1"></a><span class="do">## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span></code></pre></div>
<p>Both SES, <span class="math inline">\(X^2\)</span> = 11.058, <em>p</em> = 0.026, and writing score <span class="math inline">\(X^2\)</span> = 31.447, <em>p</em> = 1.484e-07, had significant effects on the program.</p>
<p>Logistic regression does not have a direct R-squared statistic like OLS does (the proportion of variance explained by the model). However, there are some analogs, called pseudo R-squared. You’ll encounter three pseudo R-squared measures: Cox and Snell, Nagelkerke, and McFadden. This one does not work for the <code>nnet</code> engine.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="generalized-linear-models-glm.html#cb148-1" tabindex="-1"></a><span class="co"># DescTools::PseudoR2(cs2$result, which = c(&quot;CoxSnell&quot;, &quot;Nagelkerke&quot;, &quot;McFadden&quot;))</span></span></code></pre></div>
<p>Accuracy measures formed by the cross-tabulation of observed and predicted classes is the better model fit diagnostic the the pseudo r-squares.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="generalized-linear-models-glm.html#cb149-1" tabindex="-1"></a>cs2<span class="sc">$</span>conf_mat <span class="ot">&lt;-</span></span>
<span id="cb149-2"><a href="generalized-linear-models-glm.html#cb149-2" tabindex="-1"></a>  cs2<span class="sc">$</span>fit <span class="sc">%&gt;%</span> </span>
<span id="cb149-3"><a href="generalized-linear-models-glm.html#cb149-3" tabindex="-1"></a>  <span class="fu">augment</span>(<span class="at">new_data =</span> cs2<span class="sc">$</span>dat_normalized) <span class="sc">%&gt;%</span></span>
<span id="cb149-4"><a href="generalized-linear-models-glm.html#cb149-4" tabindex="-1"></a>  <span class="co"># conf_mat requires truth to be first level of the factor variable.</span></span>
<span id="cb149-5"><a href="generalized-linear-models-glm.html#cb149-5" tabindex="-1"></a>  <span class="co"># mutate(across(c(prog, .pred_class), ~fct_relevel(., &quot;academic&quot;))) %&gt;%</span></span>
<span id="cb149-6"><a href="generalized-linear-models-glm.html#cb149-6" tabindex="-1"></a>  <span class="fu">conf_mat</span>(<span class="at">truth =</span> prog, <span class="at">estimate =</span> .pred_class)</span>
<span id="cb149-7"><a href="generalized-linear-models-glm.html#cb149-7" tabindex="-1"></a></span>
<span id="cb149-8"><a href="generalized-linear-models-glm.html#cb149-8" tabindex="-1"></a>cs2<span class="sc">$</span>conf_mat</span></code></pre></div>
<pre><code>##           Truth
## Prediction academic general vocation
##   academic       92      27       23
##   general         4       7        4
##   vocation        9      11       23</code></pre>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="generalized-linear-models-glm.html#cb151-1" tabindex="-1"></a>cs2<span class="sc">$</span>conf_mat <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## # A tibble: 13 × 3
##    .metric              .estimator .estimate
##    &lt;chr&gt;                &lt;chr&gt;          &lt;dbl&gt;
##  1 accuracy             multiclass     0.61 
##  2 kap                  multiclass     0.299
##  3 sens                 macro          0.497
##  4 spec                 macro          0.763
##  5 ppv                  macro          0.550
##  6 npv                  macro          0.799
##  7 mcc                  multiclass     0.320
##  8 j_index              macro          0.260
##  9 bal_accuracy         macro          0.630
## 10 detection_prevalence macro          0.333
## 11 precision            macro          0.550
## 12 recall               macro          0.497
## 13 f_meas               macro          0.491</code></pre>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="generalized-linear-models-glm.html#cb153-1" tabindex="-1"></a>cs1<span class="sc">$</span>conf_mat <span class="sc">%&gt;%</span> <span class="fu">autoplot</span>()</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-108-1.png" width="672" /></p>
<p>The model accuracy, 61.0%, is the percent of observations correctly classified. The sensitivities are the accuracy with regard to predicting positive cases in each level of the dependent variable. The specificities are the accuracy with regard to predicting negative cases. The prevalences are the proportion of cases that were positive.</p>
<p>Finally, plot the <a href="https://community.tibco.com/wiki/gains-vs-roc-curves-do-you-understand-difference">gain curve or ROC curve</a>. In the <strong>gain curve</strong>, the x-axis is the fraction of items seen when sorted by the predicted value, and the y-axis is the cumulatively summed true outcome. The “wizard” curve is the gain curve when the data is sorted by the true outcome. If the model’s gain curve is close to the wizard curve, then the model predicts the response well. The gray area is the “gain” over a random prediction.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="generalized-linear-models-glm.html#cb154-1" tabindex="-1"></a>cs2<span class="sc">$</span>dat_normalized <span class="sc">%&gt;%</span></span>
<span id="cb154-2"><a href="generalized-linear-models-glm.html#cb154-2" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(cs2<span class="sc">$</span>fit, <span class="at">new_data =</span> cs2<span class="sc">$</span>dat_normalized, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb154-3"><a href="generalized-linear-models-glm.html#cb154-3" tabindex="-1"></a>  <span class="co"># event_level = &quot;second&quot; sets the second level as success</span></span>
<span id="cb154-4"><a href="generalized-linear-models-glm.html#cb154-4" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">gain_curve</span>(.pred_academic, .pred_general, .pred_vocation, </span>
<span id="cb154-5"><a href="generalized-linear-models-glm.html#cb154-5" tabindex="-1"></a>                        <span class="at">truth =</span> prog, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb154-6"><a href="generalized-linear-models-glm.html#cb154-6" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb154-7"><a href="generalized-linear-models-glm.html#cb154-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Gain Curve&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-109-1.png" width="672" /></p>
<p>105 of the 200 participants were in the academic program.</p>
<ul>
<li>The gain curve encountered 52 academic programs (50%) within the first 72 observations (36%). It encountered all 105 cases on the 189th observation.</li>
<li>The bottom of the grey area is the outcome of a random model. Only half the academic program cases would be observed within 50% of the observations.<br />
</li>
<li>The top of the grey area is the outcome of the perfect model, the “wizard curve”. Half the academic program cases would be observed in 52.5/200=26.25% of the observations.</li>
</ul>
<p>The <strong>ROC</strong> (Receiver Operating Characteristics) curve plots sensitivity vs specificity at varying cut-off values for the probability ranging from 0 to 1. Ideally, you want very little trade-off between sensitivity and specificity, with a curve hugging the left and top axes.</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="generalized-linear-models-glm.html#cb155-1" tabindex="-1"></a>cs2<span class="sc">$</span>dat_normalized <span class="sc">%&gt;%</span></span>
<span id="cb155-2"><a href="generalized-linear-models-glm.html#cb155-2" tabindex="-1"></a>  <span class="fu">bind_cols</span>(<span class="fu">predict</span>(cs2<span class="sc">$</span>fit, <span class="at">new_data =</span> cs2<span class="sc">$</span>dat_normalized, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb155-3"><a href="generalized-linear-models-glm.html#cb155-3" tabindex="-1"></a>  <span class="co"># event_level = &quot;second&quot; sets the second level as success</span></span>
<span id="cb155-4"><a href="generalized-linear-models-glm.html#cb155-4" tabindex="-1"></a>  yardstick<span class="sc">::</span><span class="fu">roc_curve</span>(.pred_academic, .pred_general, .pred_vocation, </span>
<span id="cb155-5"><a href="generalized-linear-models-glm.html#cb155-5" tabindex="-1"></a>                        <span class="at">truth =</span> prog, <span class="at">event_level =</span> <span class="st">&quot;second&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb155-6"><a href="generalized-linear-models-glm.html#cb155-6" tabindex="-1"></a>  <span class="fu">autoplot</span>() <span class="sc">+</span></span>
<span id="cb155-7"><a href="generalized-linear-models-glm.html#cb155-7" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Gain Curve&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-110-1.png" width="672" /></p>
</div>
<div id="reporting-1" class="section level3 unnumbered hasAnchor">
<h3>Reporting<a href="generalized-linear-models-glm.html#reporting-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<blockquote>
<p>A multinomial logistic regression was performed to ascertain the effects of socioeconomic status (ses) and writing score on the likelihood that participants are enrolled in an academic, general, or vocation program. Linearity of the continuous variables with respect to the logit of the dependent variable was assessed via the Box-Tidwell (1962) procedure. A Bonferroni correction was applied using all eight terms in the model resulting in statistical significance being accepted when <em>p</em> &lt; 0.00625 (Tabachnick &amp; Fidell, 2014). Based on this assessment, the continuous <code>write</code> independent variable was found to be linearly related to the logit of the dependent variable levels. There were two standardized residuals with value of 2.20 and 2.59 standard deviations, which were kept in the analysis. The multinomial logistic regression model was statistically significant, <span class="math inline">\(\chi^2\)</span>(6) = 48.23, p &lt; .001. The model correctly classified 61% of cases. Sensitivity was 50%, specificity was 76%, positive predictive value was 55% and negative predictive value was 80%. The <code>write</code> predictor variable was statistically significant for both outcome levels and high SES was statistically significant for the general program (as shown in Table 1). A 1SD increase in the writing score was associated with a (1 - 0.58) decrease in the odds of choosing a general program instead of academic and a (1 - 0.34) decrease in the odds of choosing a vocation program over academic. A high SEC was associated with a (1 - 0.31) decrease in the odds of chooseing a general program over academic.</p>
</blockquote>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="generalized-linear-models-glm.html#cb156-1" tabindex="-1"></a>gtsummary<span class="sc">::</span><span class="fu">tbl_regression</span>(</span>
<span id="cb156-2"><a href="generalized-linear-models-glm.html#cb156-2" tabindex="-1"></a>  cs2<span class="sc">$</span>result,</span>
<span id="cb156-3"><a href="generalized-linear-models-glm.html#cb156-3" tabindex="-1"></a>  <span class="at">exponentiate =</span> <span class="cn">TRUE</span></span>
<span id="cb156-4"><a href="generalized-linear-models-glm.html#cb156-4" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb156-5"><a href="generalized-linear-models-glm.html#cb156-5" tabindex="-1"></a>  gtsummary<span class="sc">::</span><span class="fu">as_flex_table</span>() <span class="sc">%&gt;%</span></span>
<span id="cb156-6"><a href="generalized-linear-models-glm.html#cb156-6" tabindex="-1"></a>  flextable<span class="sc">::</span><span class="fu">theme_apa</span>()</span></code></pre></div>
<div class="tabwid tabwid_left"><style>.cl-f914edec{}.cl-f90dcd82{font-family:'Times New Roman';font-size:11pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f90dcd96{font-family:'Times New Roman';font-size:6.6pt;font-weight:bold;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3.3pt;}.cl-f90dcd97{font-family:'Times New Roman';font-size:10pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;}.cl-f90dcd98{font-family:'Times New Roman';font-size:6pt;font-weight:normal;font-style:normal;text-decoration:none;color:rgba(0, 0, 0, 1.00);background-color:transparent;position: relative;bottom:3pt;}.cl-f910b0d8{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:2pt;padding-top:2pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-f910b0e2{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:5pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-f910b0ec{margin:0;text-align:center;border-bottom: 0 solid rgba(0, 0, 0, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);padding-bottom:5pt;padding-top:5pt;padding-left:15pt;padding-right:5pt;line-height: 2;background-color:transparent;}.cl-f910c30c{width:0.947in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c316{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c317{width:0.556in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c320{width:0.903in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c321{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c322{width:0.947in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c32a{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c32b{width:0.556in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c334{width:0.903in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c33e{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0 solid rgba(0, 0, 0, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c33f{width:0.947in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c340{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c341{width:0.556in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c352{width:0.903in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c353{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c354{width:0.947in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c35c{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c35d{width:0.556in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c35e{width:0.903in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c35f{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c366{width:0.947in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c367{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c370{width:0.556in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c371{width:0.903in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c372{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(102, 102, 102, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c37a{width:0.947in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c37b{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c37c{width:0.556in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c384{width:0.903in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c38e{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 0.75pt solid rgba(0, 0, 0, 1.00);border-top: 0.75pt solid rgba(102, 102, 102, 1.00);border-left: 0 solid rgba(0, 0, 0, 1.00);border-right: 0 solid rgba(0, 0, 0, 1.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c38f{width:0.947in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c390{width:1.304in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c398{width:0.556in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c3a2{width:0.903in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}.cl-f910c3a3{width:0.82in;background-color:transparent;vertical-align: middle;border-bottom: 0 solid rgba(255, 255, 255, 0.00);border-top: 0 solid rgba(255, 255, 255, 0.00);border-left: 0 solid rgba(255, 255, 255, 0.00);border-right: 0 solid rgba(255, 255, 255, 0.00);margin-bottom:0;margin-top:0;margin-left:0;margin-right:0;}</style><table data-quarto-disable-processing='true' class='cl-f914edec'><thead><tr style="overflow-wrap:break-word;"><th class="cl-f910c30c"><p class="cl-f910b0d8"><span class="cl-f90dcd82">Outcome</span></p></th><th class="cl-f910c316"><p class="cl-f910b0d8"><span class="cl-f90dcd82">Characteristic</span></p></th><th class="cl-f910c317"><p class="cl-f910b0d8"><span class="cl-f90dcd82">OR</span><span class="cl-f90dcd96">1</span></p></th><th class="cl-f910c320"><p class="cl-f910b0d8"><span class="cl-f90dcd82">95% CI</span><span class="cl-f90dcd96">1</span></p></th><th class="cl-f910c321"><p class="cl-f910b0d8"><span class="cl-f90dcd82">p-value</span></p></th></tr></thead><tbody><tr style="overflow-wrap:break-word;"><td class="cl-f910c322"><p class="cl-f910b0e2"><span class="cl-f90dcd97">general</span></p></td><td class="cl-f910c32a"><p class="cl-f910b0e2"><span class="cl-f90dcd97">ses</span></p></td><td class="cl-f910c32b"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c334"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c33e"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c33f"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c340"><p class="cl-f910b0ec"><span class="cl-f90dcd97">low</span></p></td><td class="cl-f910c341"><p class="cl-f910b0e2"><span class="cl-f90dcd97">—</span></p></td><td class="cl-f910c352"><p class="cl-f910b0e2"><span class="cl-f90dcd97">—</span></p></td><td class="cl-f910c353"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c354"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c35c"><p class="cl-f910b0ec"><span class="cl-f90dcd97">middle</span></p></td><td class="cl-f910c35d"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.59</span></p></td><td class="cl-f910c35e"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.25, 1.40</span></p></td><td class="cl-f910c35f"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.2</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c366"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c367"><p class="cl-f910b0ec"><span class="cl-f90dcd97">high</span></p></td><td class="cl-f910c370"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.31</span></p></td><td class="cl-f910c371"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.11, 0.86</span></p></td><td class="cl-f910c372"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.024</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c354"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c35c"><p class="cl-f910b0e2"><span class="cl-f90dcd97">write</span></p></td><td class="cl-f910c35d"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.58</span></p></td><td class="cl-f910c35e"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.39, 0.86</span></p></td><td class="cl-f910c35f"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.007</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c33f"><p class="cl-f910b0e2"><span class="cl-f90dcd97">vocation</span></p></td><td class="cl-f910c340"><p class="cl-f910b0e2"><span class="cl-f90dcd97">ses</span></p></td><td class="cl-f910c341"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c352"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c353"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c33f"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c340"><p class="cl-f910b0ec"><span class="cl-f90dcd97">low</span></p></td><td class="cl-f910c341"><p class="cl-f910b0e2"><span class="cl-f90dcd97">—</span></p></td><td class="cl-f910c352"><p class="cl-f910b0e2"><span class="cl-f90dcd97">—</span></p></td><td class="cl-f910c353"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c354"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c35c"><p class="cl-f910b0ec"><span class="cl-f90dcd97">middle</span></p></td><td class="cl-f910c35d"><p class="cl-f910b0e2"><span class="cl-f90dcd97">1.34</span></p></td><td class="cl-f910c35e"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.53, 3.40</span></p></td><td class="cl-f910c35f"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.5</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c366"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c367"><p class="cl-f910b0ec"><span class="cl-f90dcd97">high</span></p></td><td class="cl-f910c370"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.37</span></p></td><td class="cl-f910c371"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.12, 1.20</span></p></td><td class="cl-f910c372"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.10</span></p></td></tr><tr style="overflow-wrap:break-word;"><td class="cl-f910c37a"><p class="cl-f910b0e2"><span class="cl-f90dcd97"></span></p></td><td class="cl-f910c37b"><p class="cl-f910b0e2"><span class="cl-f90dcd97">write</span></p></td><td class="cl-f910c37c"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.34</span></p></td><td class="cl-f910c384"><p class="cl-f910b0e2"><span class="cl-f90dcd97">0.23, 0.51</span></p></td><td class="cl-f910c38e"><p class="cl-f910b0e2"><span class="cl-f90dcd97">&lt;0.001</span></p></td></tr></tbody><tfoot><tr style="overflow-wrap:break-word;"><td  colspan="5"class="cl-f910c38f"><p class="cl-f910b0e2"><span class="cl-f90dcd98">1</span><span class="cl-f90dcd97">OR = Odds Ratio, CI = Confidence Interval</span></p></td></tr></tfoot></table></div>
</div>
</div>
<div id="ordinallogistic" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Ordinal Logistic Regression<a href="generalized-linear-models-glm.html#ordinallogistic" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ordinal logistic regression, also call cumulative link model (CLM), is a generalized linear model (GZLM), an extension of the general linear model (GLM) to non-continuous outcome variables. There are many approaches to ordinal logistic regression, including cumulative, adjacent, and continuation categories, but the most popular is the <strong>cumulative odds ordinal logistic regression with proportional odds</strong>.<a href="#fn14" class="footnote-ref" id="fnref14"><sup>14</sup></a>. The model for ordinal response random variable <span class="math inline">\(Y_i\)</span> with <span class="math inline">\(J\)</span> levels is</p>
<p><span class="math display">\[\gamma_{ij} = F(\eta_{ij}), \hspace{5 mm} \eta_{ij} = \theta_j - x_i^\mathrm{T}\beta, \hspace{5 mm} i = 1, \ldots, n, \hspace{5 mm} j = 1, \ldots, J-1\]</span></p>
<p>where <span class="math inline">\(\gamma_{ij} = P(Y_i \le j) = \pi_{i1} + \cdots + \pi_{ij}\)</span>. <span class="math inline">\(\eta_{ij}\)</span> is a linear predictor with <span class="math inline">\(J-1\)</span> intercepts. <span class="math inline">\(F\)</span> is the inverse link function. The regression models the logit link function of <span class="math inline">\(\gamma_{ij}\)</span>.</p>
<p><span class="math display">\[\mathrm{logit}(\gamma_{ij}) = \log \left[\frac{P(Y_i \le j)}{P(Y_i \gt j)} \right] = \theta_j - x_i^\mathrm{T}\beta\]</span>
The cumulative logit is the log-odds of the cumulative probabilities that the response is in category <span class="math inline">\(\le j\)</span> versus <span class="math inline">\(\gt j\)</span>. <span class="math inline">\(\theta_j\)</span> is the log-odds when <span class="math inline">\(x_i^\mathrm{T}=0\)</span> and <span class="math inline">\(\beta\)</span> is the increase in the log odds attributed to a one unit increase in <span class="math inline">\(x_i^\mathrm{T}\)</span>. Notice <span class="math inline">\(\beta\)</span> is the same for all <span class="math inline">\(j\)</span>. The exponential of the predicted value is the odds. Solve this for the probability,</p>
<p><span class="math display">\[P(Y_i \gt j) = \frac{\mathrm{exp}(\hat{y}_i)}{1 + \mathrm{exp}(\hat{y}_i)}.\]</span></p>
<p>The exponential of <span class="math inline">\(\beta\)</span> is the odds ratio of <span class="math inline">\(x_1^\mathrm{T} - x_0^\mathrm{T}\)</span>. Solve this for the odds ratio</p>
<p><span class="math display">\[\mathrm{OR} = \frac{\mathrm{exp}(\theta_j - x_1^\mathrm{T}\beta)}{\mathrm{exp}(\theta_j - x_2^\mathrm{T}\beta)} = \mathrm{exp}(\beta(x_1^\mathrm{T} - x_0^\mathrm{T}))\]</span></p>
<p>If <span class="math inline">\(x\)</span> is a binary factor factor, then <span class="math inline">\(\exp(\beta)\)</span> is the odds ratio of <span class="math inline">\(x=1\)</span> vs <span class="math inline">\(x=0\)</span>. Thus the odds-ratio is <em>proportional</em> to the difference between values of <span class="math inline">\(x\)</span> and <span class="math inline">\(\beta\)</span> is the constant of proportionality.</p>
<p>The model is estimated with a regularized Newton-Raphson algorithm with step-halving (line search) using analytic expressions for the gradient and Hessian of the negative log-likelihood function. This is beyond me, but the upshot is that the estimation is an iterative maximization exercise, not a formulaic matrix algebra process. It is possible for the model estimation to fail to converge on a maximum.</p>
<p>You will sometimes encounter discussion about the <em>latent variable</em>. That is just the underlying quality you are trying to measure. If you rate something a 4 on a 5-level Likert scale, 4 is the expression of your valuation, the latent variable. Your precise valuation is somewhere between 3 and 5 on a continuous scale. The link function defines the distribution of the latent variable.</p>
<p>There are variations on the ordinal model. Structured thresholds impose restrictions on <span class="math inline">\(\theta_j\)</span>, for example requiring equal distances between levels. Partial proportional odds allow <span class="math inline">\(\theta_j\)</span> to vary with nominal predictors. You can also use link functions other than logit.</p>
<p>There are two assumptions underling ordinal logistic regression: (a) no multicollinearity, and (b) proportional odds.</p>
<div id="cs3" class="section level3 unnumbered hasAnchor">
<h3>Case Study<a href="generalized-linear-models-glm.html#cs3" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>This case study uses the <a href="https://statistics.laerd.com/">Laerd Statistics</a> article on ordinal logistic regression <a href="https://statistics.laerd.com/premium/spss/spss-files/ordinal-logistic-regression.sav">data set</a>. A study investigates the relationship between attitude toward tax levels and participant values and background. 192 participants in a study responded to the statement “Taxes are too high” on a 4-level Likert scale (<code>tax_too_high</code>, <em>Strongly Disagree</em>, <em>Disagree</em>, <em>Agree</em>, <em>Strongly Agree</em>). Participant attributes include business owner (<em>Y</em>|<em>N</em>), age, and political affiliation (<em>Liberal</em>, <em>Conservative</em>, <em>Labor</em>).</p>
<div class="sourceCode" id="cb157"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb157-1"><a href="generalized-linear-models-glm.html#cb157-1" tabindex="-1"></a>cs3 <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb157-2"><a href="generalized-linear-models-glm.html#cb157-2" tabindex="-1"></a></span>
<span id="cb157-3"><a href="generalized-linear-models-glm.html#cb157-3" tabindex="-1"></a>cs3<span class="sc">$</span>dat <span class="ot">&lt;-</span> foreign<span class="sc">::</span><span class="fu">read.spss</span>(<span class="st">&quot;./input/ordinal-logistic-regression.sav&quot;</span>, <span class="at">to.data.frame =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb157-4"><a href="generalized-linear-models-glm.html#cb157-4" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">tax_too_high =</span> <span class="fu">factor</span>(tax_too_high, <span class="at">ordered =</span> <span class="cn">TRUE</span>),</span>
<span id="cb157-5"><a href="generalized-linear-models-glm.html#cb157-5" tabindex="-1"></a>         <span class="at">biz_owner =</span> <span class="fu">fct_relevel</span>(biz_owner, <span class="st">&quot;No&quot;</span>, <span class="st">&quot;Yes&quot;</span>),</span>
<span id="cb157-6"><a href="generalized-linear-models-glm.html#cb157-6" tabindex="-1"></a>         <span class="at">politics =</span> <span class="fu">fct_relevel</span>(politics, <span class="st">&quot;Lab&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb157-7"><a href="generalized-linear-models-glm.html#cb157-7" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span><span class="fu">c</span>(biz_friends, uni_educated, income))</span>
<span id="cb157-8"><a href="generalized-linear-models-glm.html#cb157-8" tabindex="-1"></a></span>
<span id="cb157-9"><a href="generalized-linear-models-glm.html#cb157-9" tabindex="-1"></a>cs3<span class="sc">$</span>dat <span class="sc">%&gt;%</span> </span>
<span id="cb157-10"><a href="generalized-linear-models-glm.html#cb157-10" tabindex="-1"></a>  gtsummary<span class="sc">::</span><span class="fu">tbl_summary</span>(</span>
<span id="cb157-11"><a href="generalized-linear-models-glm.html#cb157-11" tabindex="-1"></a>  <span class="at">by =</span> politics, </span>
<span id="cb157-12"><a href="generalized-linear-models-glm.html#cb157-12" tabindex="-1"></a>  <span class="at">statistic =</span> <span class="fu">list</span>(gtsummary<span class="sc">::</span><span class="fu">all_continuous</span>() <span class="sc">~</span> <span class="st">&quot;{mean} ({sd})&quot;</span>)</span>
<span id="cb157-13"><a href="generalized-linear-models-glm.html#cb157-13" tabindex="-1"></a>)</span></code></pre></div>
<div id="hcdtlvqjtk" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#hcdtlvqjtk table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#hcdtlvqjtk thead, #hcdtlvqjtk tbody, #hcdtlvqjtk tfoot, #hcdtlvqjtk tr, #hcdtlvqjtk td, #hcdtlvqjtk th {
  border-style: none;
}

#hcdtlvqjtk p {
  margin: 0;
  padding: 0;
}

#hcdtlvqjtk .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#hcdtlvqjtk .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#hcdtlvqjtk .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#hcdtlvqjtk .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#hcdtlvqjtk .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hcdtlvqjtk .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hcdtlvqjtk .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#hcdtlvqjtk .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#hcdtlvqjtk .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#hcdtlvqjtk .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#hcdtlvqjtk .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#hcdtlvqjtk .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#hcdtlvqjtk .gt_spanner_row {
  border-bottom-style: hidden;
}

#hcdtlvqjtk .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#hcdtlvqjtk .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#hcdtlvqjtk .gt_from_md > :first-child {
  margin-top: 0;
}

#hcdtlvqjtk .gt_from_md > :last-child {
  margin-bottom: 0;
}

#hcdtlvqjtk .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#hcdtlvqjtk .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#hcdtlvqjtk .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#hcdtlvqjtk .gt_row_group_first td {
  border-top-width: 2px;
}

#hcdtlvqjtk .gt_row_group_first th {
  border-top-width: 2px;
}

#hcdtlvqjtk .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hcdtlvqjtk .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#hcdtlvqjtk .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#hcdtlvqjtk .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hcdtlvqjtk .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#hcdtlvqjtk .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#hcdtlvqjtk .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#hcdtlvqjtk .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#hcdtlvqjtk .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#hcdtlvqjtk .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hcdtlvqjtk .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#hcdtlvqjtk .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#hcdtlvqjtk .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#hcdtlvqjtk .gt_left {
  text-align: left;
}

#hcdtlvqjtk .gt_center {
  text-align: center;
}

#hcdtlvqjtk .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#hcdtlvqjtk .gt_font_normal {
  font-weight: normal;
}

#hcdtlvqjtk .gt_font_bold {
  font-weight: bold;
}

#hcdtlvqjtk .gt_font_italic {
  font-style: italic;
}

#hcdtlvqjtk .gt_super {
  font-size: 65%;
}

#hcdtlvqjtk .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#hcdtlvqjtk .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#hcdtlvqjtk .gt_indent_1 {
  text-indent: 5px;
}

#hcdtlvqjtk .gt_indent_2 {
  text-indent: 10px;
}

#hcdtlvqjtk .gt_indent_3 {
  text-indent: 15px;
}

#hcdtlvqjtk .gt_indent_4 {
  text-indent: 20px;
}

#hcdtlvqjtk .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Characteristic&lt;/strong&gt;"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Lab&lt;/strong&gt;, N = 62&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>Lab</strong>, N = 62<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Lib&lt;/strong&gt;, N = 54&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>Lib</strong>, N = 54<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Con&lt;/strong&gt;, N = 76&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>Con</strong>, N = 76<span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="label" class="gt_row gt_left">biz_owner</td>
<td headers="stat_1" class="gt_row gt_center">36 (58%)</td>
<td headers="stat_2" class="gt_row gt_center">26 (48%)</td>
<td headers="stat_3" class="gt_row gt_center">47 (62%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">age</td>
<td headers="stat_1" class="gt_row gt_center">37.4 (5.6)</td>
<td headers="stat_2" class="gt_row gt_center">35.4 (5.8)</td>
<td headers="stat_3" class="gt_row gt_center">37.2 (4.8)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">tax_too_high</td>
<td headers="stat_1" class="gt_row gt_center"><br /></td>
<td headers="stat_2" class="gt_row gt_center"><br /></td>
<td headers="stat_3" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Strongly Disagree</td>
<td headers="stat_1" class="gt_row gt_center">10 (16%)</td>
<td headers="stat_2" class="gt_row gt_center">10 (19%)</td>
<td headers="stat_3" class="gt_row gt_center">4 (5.3%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Disagree</td>
<td headers="stat_1" class="gt_row gt_center">13 (21%)</td>
<td headers="stat_2" class="gt_row gt_center">16 (30%)</td>
<td headers="stat_3" class="gt_row gt_center">9 (12%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Agree</td>
<td headers="stat_1" class="gt_row gt_center">28 (45%)</td>
<td headers="stat_2" class="gt_row gt_center">21 (39%)</td>
<td headers="stat_3" class="gt_row gt_center">42 (55%)</td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Strongly Agree</td>
<td headers="stat_1" class="gt_row gt_center">11 (18%)</td>
<td headers="stat_2" class="gt_row gt_center">7 (13%)</td>
<td headers="stat_3" class="gt_row gt_center">21 (28%)</td></tr>
  </tbody>
  
  <tfoot class="gt_footnotes">
    <tr>
      <td class="gt_footnote" colspan="4"><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span> n (%); Mean (SD)</td>
    </tr>
  </tfoot>
</table>
</div>
<p><br></p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="generalized-linear-models-glm.html#cb158-1" tabindex="-1"></a>cs3<span class="sc">$</span>dat <span class="sc">%&gt;%</span></span>
<span id="cb158-2"><a href="generalized-linear-models-glm.html#cb158-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">age =</span> <span class="fu">case_when</span>(age <span class="sc">&lt;</span> <span class="fu">quantile</span>(age, .<span class="dv">33</span>) <span class="sc">~</span> <span class="st">&quot;young&quot;</span>,</span>
<span id="cb158-3"><a href="generalized-linear-models-glm.html#cb158-3" tabindex="-1"></a>                         age <span class="sc">&lt;</span> <span class="fu">quantile</span>(age, .<span class="dv">67</span>) <span class="sc">~</span> <span class="st">&quot;middle&quot;</span>,</span>
<span id="cb158-4"><a href="generalized-linear-models-glm.html#cb158-4" tabindex="-1"></a>                         <span class="cn">TRUE</span> <span class="sc">~</span> <span class="st">&quot;old&quot;</span>),</span>
<span id="cb158-5"><a href="generalized-linear-models-glm.html#cb158-5" tabindex="-1"></a>         <span class="at">age =</span> <span class="fu">factor</span>(age, <span class="at">levels =</span> <span class="fu">c</span>(<span class="st">&quot;young&quot;</span>, <span class="st">&quot;middle&quot;</span>, <span class="st">&quot;old&quot;</span>))) <span class="sc">%&gt;%</span></span>
<span id="cb158-6"><a href="generalized-linear-models-glm.html#cb158-6" tabindex="-1"></a>  <span class="fu">count</span>(tax_too_high, biz_owner, age, politics) <span class="sc">%&gt;%</span></span>
<span id="cb158-7"><a href="generalized-linear-models-glm.html#cb158-7" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> tax_too_high, <span class="at">y =</span> n, <span class="at">fill =</span> biz_owner)) <span class="sc">+</span></span>
<span id="cb158-8"><a href="generalized-linear-models-glm.html#cb158-8" tabindex="-1"></a>  <span class="fu">geom_col</span>(<span class="at">position =</span> <span class="fu">position_dodge2</span>(<span class="at">preserve =</span> <span class="st">&quot;single&quot;</span>)) <span class="sc">+</span></span>
<span id="cb158-9"><a href="generalized-linear-models-glm.html#cb158-9" tabindex="-1"></a>  <span class="fu">facet_grid</span>(<span class="at">rows =</span> <span class="fu">vars</span>(age), <span class="at">cols =</span> <span class="fu">vars</span>(politics), <span class="at">space =</span> <span class="st">&quot;free&quot;</span>) <span class="sc">+</span></span>
<span id="cb158-10"><a href="generalized-linear-models-glm.html#cb158-10" tabindex="-1"></a>  <span class="fu">scale_x_discrete</span>(<span class="at">labels =</span> <span class="cf">function</span> (x) <span class="fu">str_wrap</span>(x, <span class="at">width =</span> <span class="dv">10</span>)) <span class="sc">+</span></span>
<span id="cb158-11"><a href="generalized-linear-models-glm.html#cb158-11" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span></span>
<span id="cb158-12"><a href="generalized-linear-models-glm.html#cb158-12" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;bottom&quot;</span>) <span class="sc">+</span></span>
<span id="cb158-13"><a href="generalized-linear-models-glm.html#cb158-13" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Taxes too high?&quot;</span>,</span>
<span id="cb158-14"><a href="generalized-linear-models-glm.html#cb158-14" tabindex="-1"></a>       <span class="at">subtitle =</span> <span class="st">&quot;Reponse count by business owner, age, and politics.&quot;</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-113-1.png" width="672" /></p>
</div>
<div id="fit-the-model-2" class="section level3 unnumbered hasAnchor">
<h3>Fit the Model<a href="generalized-linear-models-glm.html#fit-the-model-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Fit a cumulative link model for the cumulative probability of the <span class="math inline">\(i\)</span>th response falling in <span class="math inline">\(j\)</span>th category or below where <span class="math inline">\(i\)</span> indexes the (<span class="math inline">\(n = 192\)</span>) responses, <span class="math inline">\(j = 1, \ldots, J\)</span> indexes the (<span class="math inline">\(J = 4\)</span>) response categories, and <span class="math inline">\(\theta_j\)</span> is the threshold for the <span class="math inline">\(j\)</span>th cumulative logit.</p>
<p><span class="math display">\[\mathrm{logit}(P(Y_i \le j)) = \theta_j - \beta_1(\mathrm{politics}_i) - \beta_2(\mathrm{biz\_owner}_i) - \beta_3(\mathrm{age}_i)\]</span></p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="generalized-linear-models-glm.html#cb159-1" tabindex="-1"></a>cs3<span class="sc">$</span>fmla <span class="ot">&lt;-</span> <span class="fu">formula</span>(tax_too_high <span class="sc">~</span> biz_owner <span class="sc">+</span> age <span class="sc">+</span> politics)</span>
<span id="cb159-2"><a href="generalized-linear-models-glm.html#cb159-2" tabindex="-1"></a></span>
<span id="cb159-3"><a href="generalized-linear-models-glm.html#cb159-3" tabindex="-1"></a>cs3<span class="sc">$</span>result <span class="ot">&lt;-</span> ordinal<span class="sc">::</span><span class="fu">clm</span>(cs3<span class="sc">$</span>fmla, <span class="at">data =</span> cs3<span class="sc">$</span>dat)</span>
<span id="cb159-4"><a href="generalized-linear-models-glm.html#cb159-4" tabindex="-1"></a></span>
<span id="cb159-5"><a href="generalized-linear-models-glm.html#cb159-5" tabindex="-1"></a>cs3<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">summary</span>()</span></code></pre></div>
<pre><code>## formula: tax_too_high ~ biz_owner + age + politics
## data:    cs3$dat
## 
##  link  threshold nobs logLik  AIC    niter max.grad cond.H 
##  logit flexible  192  -197.62 409.23 6(0)  3.14e-12 3.2e+05
## 
## Coefficients:
##              Estimate Std. Error z value Pr(&gt;|z|)    
## biz_ownerYes  0.66462    0.28894   2.300 0.021435 *  
## age           0.24189    0.03260   7.421 1.17e-13 ***
## politicsLib   0.03695    0.36366   0.102 0.919072    
## politicsCon   1.16142    0.34554   3.361 0.000776 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Threshold coefficients:
##                            Estimate Std. Error z value
## Strongly Disagree|Disagree    7.026      1.166   6.024
## Disagree|Agree                8.766      1.231   7.119
## Agree|Strongly Agree         11.653      1.357   8.590</code></pre>
<p>The summary object shows several fit statistics. More about these in the fit evaluation section below. The Coefficients table is the familiar parameter estimates. The coefficient estimate for <code>biz_ownerYes</code> is 0.665 with standard error 0.289, <span class="math inline">\(z = \hat{\beta} / se =\)</span> 2.300, and <span class="math inline">\(p = 2 \cdot P(Z&gt;z) =\)</span> 0.021. Some programs (e.g., SPSS) also show the Wald chi-squared statistic, <span class="math inline">\(z^2 =\)</span> 5.291. The square of a normal variable has a <span class="math inline">\(\chi^2\)</span> distribution, so the <em>p</em> value for the Wald chi-squared statistic is <code>pchisq(z^2, df = 1)</code> = 0.021.</p>
<p>The Threshold coefficients table are the intercepts, or cut-points. The first cut-point is the log-odds of response level <em>Strongly Disagree</em> (or less) vs greater than <em>Strongly Disagree</em> when all factor variables are at their reference level and the continuous vars are at 0.</p>
<p>There may be interaction effects between <code>biz_owner</code> and <code>politics</code>. You can check this by comparing the log likelihood to the saturated model with a likelihood ratio test.</p>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="generalized-linear-models-glm.html#cb161-1" tabindex="-1"></a>saturated <span class="ot">&lt;-</span> ordinal<span class="sc">::</span><span class="fu">clm</span>(tax_too_high <span class="sc">~</span> biz_owner<span class="sc">*</span>politics <span class="sc">+</span> age, <span class="at">data =</span> cs3<span class="sc">$</span>dat)</span>
<span id="cb161-2"><a href="generalized-linear-models-glm.html#cb161-2" tabindex="-1"></a></span>
<span id="cb161-3"><a href="generalized-linear-models-glm.html#cb161-3" tabindex="-1"></a>(cs3<span class="sc">$</span>sat_anova <span class="ot">&lt;-</span> <span class="fu">anova</span>(cs3<span class="sc">$</span>result, saturated))</span></code></pre></div>
<pre><code>## Likelihood ratio tests of cumulative link models:
##  
##            formula:                                  link: threshold:
## cs3$result cs3$fmla                                  logit flexible  
## saturated  tax_too_high ~ biz_owner * politics + age logit flexible  
## 
##            no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)
## cs3$result      7 409.23 -197.62                      
## saturated       9 411.75 -196.87  1.4805  2      0.477</code></pre>
<p>The likelihood ratio test indicates the main-effects model fits about the same as the saturated model, <span class="math inline">\(\chi^2\)</span>(2) = 1.48, <em>p</em> = 0.477)</p>
</div>
<div id="assumptions-2" class="section level3 unnumbered hasAnchor">
<h3>Assumptions<a href="generalized-linear-models-glm.html#assumptions-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cumulative odds ordinal logistic regression with proportional odds models require a) no multicollinearity, and b) proportional odds.</p>
<p><strong>Multicollinearity</strong> occurs when two or more independent variables are <em>highly correlated</em> so that they do not provide unique or independent information in the regression model. Multicollinearity inflates the variances of the estimated coefficients, resulting in larger confidence intervals. The usual interpretation of a slope coefficient as the change in the mean response per unit increase in the predictor when all the other predictors are held constant breaks down because changing one predictor <em>necessarily</em> changes other predictors.</p>
<p>Test for multicollinearity with variance inflation factors (VIF). The VIF is the inflation percentage of the parameter variance due to multicollinearity. E.g., a VIF of 1.9 means the parameter variance is 90% larger than what it would be if it was not correlated with other predictors.</p>
<p>Predictor k’s variance, <span class="math inline">\(Var(\hat{\beta_k})\)</span>, is inflated by a factor of</p>
<p><span class="math display">\[\mathrm{VIF}_k = \frac{1}{1 - R_k^2}\]</span></p>
<p>due to collinearity with other predictors, where <span class="math inline">\(R_k^2\)</span> is the <span class="math inline">\(R^2\)</span> of a regression of the <span class="math inline">\(k^{th}\)</span> predictor on the remaining predictors. If predictor <span class="math inline">\(k\)</span> is unrelated to the other variables, <span class="math inline">\(R_k^2 = 0\)</span> and <span class="math inline">\(VIF = 1\)</span> (no variance inflation). If 100% of the variance in predictor <span class="math inline">\(k\)</span> is explained by the other predictors, then <span class="math inline">\(R_k^2 = 1\)</span> and <span class="math inline">\(VIF = \infty\)</span>. The rule of thumb is that <span class="math inline">\(VIF \le 5\)</span> is acceptable.</p>
<div class="sourceCode" id="cb163"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb163-1"><a href="generalized-linear-models-glm.html#cb163-1" tabindex="-1"></a><span class="co"># Cannot use CLM model with vif(). Re-express as a linear model.</span></span>
<span id="cb163-2"><a href="generalized-linear-models-glm.html#cb163-2" tabindex="-1"></a><span class="fu">lm</span>(<span class="fu">as.numeric</span>(tax_too_high) <span class="sc">~</span> politics <span class="sc">+</span> biz_owner <span class="sc">+</span> age, <span class="at">dat =</span> cs3<span class="sc">$</span>dat) <span class="sc">%&gt;%</span></span>
<span id="cb163-3"><a href="generalized-linear-models-glm.html#cb163-3" tabindex="-1"></a>  car<span class="sc">::</span><span class="fu">vif</span>()</span></code></pre></div>
<pre><code>##               GVIF Df GVIF^(1/(2*Df))
## politics  1.035831  2        1.008840
## biz_owner 1.023642  1        1.011752
## age       1.036491  1        1.018082</code></pre>
<p>The VIFs in column GVIF are all below 5, so this model is not compromised by multicollinearity.</p>
<p>The <strong>proportional odds</strong> assumption means the independent variable effects are constant across each cumulative split of the ordinal dependent variable. Test for proportional odds using a full <a href="https://stats.idre.ucla.edu/other/mult-pkg/faq/general/faqhow-are-the-likelihood-ratio-wald-and-lagrange-multiplier-score-tests-different-andor-similar/">likelihood ratio test</a> comparing the proportional odds model with a multinomial logit model, also called an unconstrained baseline logit model. This is also called the <em>test of parallel lines</em>. The multinomial logit model fits a slope to each of the <span class="math inline">\(J – 1\)</span> levels. The proportional odds model is nested within the multinomial model, so you can use a likelihood ratio test to see if the models are statistically different. Fit the proportional odds model and a multinomial model using <code>VGAM::vglm()</code> and capture the log likelihoods and degrees of freedom. Perform a likelihood ratio test on the differences in log likelihoods, <span class="math inline">\(D = -2 \mathrm{loglik}(\beta)\)</span>.</p>
<div class="sourceCode" id="cb165"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb165-1"><a href="generalized-linear-models-glm.html#cb165-1" tabindex="-1"></a>cs3<span class="sc">$</span>vglm_ordinal     <span class="ot">&lt;-</span> VGAM<span class="sc">::</span><span class="fu">vglm</span>(cs3<span class="sc">$</span>fmla, VGAM<span class="sc">::</span>propodds,   <span class="at">data =</span> cs3<span class="sc">$</span>dat)</span>
<span id="cb165-2"><a href="generalized-linear-models-glm.html#cb165-2" tabindex="-1"></a></span>
<span id="cb165-3"><a href="generalized-linear-models-glm.html#cb165-3" tabindex="-1"></a>cs3<span class="sc">$</span>vglm_multinomial <span class="ot">&lt;-</span> VGAM<span class="sc">::</span><span class="fu">vglm</span>(cs3<span class="sc">$</span>fmla, VGAM<span class="sc">::</span>cumulative, <span class="at">data =</span> cs3<span class="sc">$</span>dat)</span>
<span id="cb165-4"><a href="generalized-linear-models-glm.html#cb165-4" tabindex="-1"></a></span>
<span id="cb165-5"><a href="generalized-linear-models-glm.html#cb165-5" tabindex="-1"></a>(cs3<span class="sc">$</span>po_lrt <span class="ot">&lt;-</span> VGAM<span class="sc">::</span><span class="fu">lrtest</span>(cs3<span class="sc">$</span>vglm_multinomial, cs3<span class="sc">$</span>vglm_ordinal))</span></code></pre></div>
<pre><code>## Likelihood ratio test
## 
## Model 1: tax_too_high ~ biz_owner + age + politics
## Model 2: tax_too_high ~ biz_owner + age + politics
##   #Df  LogLik Df  Chisq Pr(&gt;Chisq)
## 1 561 -193.31                     
## 2 569 -197.62  8 8.6197     0.3754</code></pre>
<blockquote>
<p>The assumption of proportional odds was met, as assessed by a full likelihood ratio test comparing the fit of the proportional odds model to a model with varying location parameters, <span class="math inline">\(\chi^2\)</span>(8) = 8.620, <em>p</em> = 0.375.</p>
</blockquote>
<p>Another option is the partial proportional odds test. This test locates specific variables causing the rejection of proportional odds.</p>
<div class="sourceCode" id="cb167"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb167-1"><a href="generalized-linear-models-glm.html#cb167-1" tabindex="-1"></a>(cs3<span class="sc">$</span>po_lrt2 <span class="ot">&lt;-</span> ordinal<span class="sc">::</span><span class="fu">clm</span>(cs3<span class="sc">$</span>fmla, <span class="at">data =</span> cs3<span class="sc">$</span>dat) <span class="sc">%&gt;%</span> ordinal<span class="sc">::</span><span class="fu">nominal_test</span>())</span></code></pre></div>
<pre><code>## Tests of nominal effects
## 
## formula: tax_too_high ~ biz_owner + age + politics
##           Df  logLik    AIC     LRT Pr(&gt;Chi)
## &lt;none&gt;       -197.62 409.23                 
## biz_owner  2 -197.34 412.67 0.55974   0.7559
## age                                         
## politics   4 -196.20 414.40 2.83415   0.5860</code></pre>
<blockquote>
<p>The assumption of proportional odds was met, as assessed by a full likelihood ratio test comparing the fit of the proportional odds model to a model with varying location parameters for business owner, <span class="math inline">\(\chi^2\)</span>(2) = 0.560, <em>p</em> = 0.756 and politics, <span class="math inline">\(\chi^2\)</span>(4) = 2.834, <em>p</em> = 0.586.</p>
</blockquote>
</div>
<div id="evaluate-the-fit-2" class="section level3 unnumbered hasAnchor">
<h3>Evaluate the Fit<a href="generalized-linear-models-glm.html#evaluate-the-fit-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>There are three ways to assess overall model fit: The Deviance and Pearson goodness-of-fit tests of the overall model fit; the Cox and Snell, Nagelkerke, and McFadden pseudo R measures of explained variance; and the likelihood ratio test comparing the model fit to the intercept-only model. However, these tests rely on large frequencies in each <em>cell</em>, that is, each possible combination of predictor values. Overall goodness-of-fit statistics should be treated with suspicion when a continuous independent variable is present and/or there are a large number of cells with zero frequency.</p>
<p>The <strong>Pearson goodness-of-fit</strong> statistic is <span class="math inline">\(X^2 = \sum \frac{(O_{ij} - E_{ij})^2}{E_{ij}}\)</span> where <span class="math inline">\(i\)</span> is the observation number and <span class="math inline">\(j\)</span> is the response variable level. It is a summary of the Pearson residuals, the difference between the observed and expected cell counts, <span class="math inline">\(O_{ij} - E_{ij}\)</span>. The <strong>deviance goodness-of-fit</strong> statistic is the difference in fit between the model and a full model; a full model being a model that fits the data perfectly, <span class="math inline">\(G^2 = 2 \sum_{ij} O_{ij} \log \left( \frac{O_{ij}}{E_{ij}} \right)\)</span>. Neither of these tests are reliable if there are many cells with zero frequencies and/or small expected frequencies and are generally not recommended. Generally, the chi-squared test requires a frequency count of at least 5 per cell.</p>
<div class="sourceCode" id="cb169"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb169-1"><a href="generalized-linear-models-glm.html#cb169-1" tabindex="-1"></a><span class="co"># Observed combinations of model vars</span></span>
<span id="cb169-2"><a href="generalized-linear-models-glm.html#cb169-2" tabindex="-1"></a>cs3<span class="sc">$</span>cell_patterns <span class="ot">&lt;-</span> </span>
<span id="cb169-3"><a href="generalized-linear-models-glm.html#cb169-3" tabindex="-1"></a>  cs3<span class="sc">$</span>dat <span class="sc">%&gt;%</span> <span class="fu">count</span>(biz_owner, age, politics, tax_too_high) <span class="sc">%&gt;%</span> <span class="fu">nrow</span>()</span>
<span id="cb169-4"><a href="generalized-linear-models-glm.html#cb169-4" tabindex="-1"></a></span>
<span id="cb169-5"><a href="generalized-linear-models-glm.html#cb169-5" tabindex="-1"></a><span class="co"># Observed combinations of predictor vars * levels of response var</span></span>
<span id="cb169-6"><a href="generalized-linear-models-glm.html#cb169-6" tabindex="-1"></a>cs3<span class="sc">$</span>covariate_patterns <span class="ot">&lt;-</span> </span>
<span id="cb169-7"><a href="generalized-linear-models-glm.html#cb169-7" tabindex="-1"></a>  cs3<span class="sc">$</span>dat <span class="sc">%&gt;%</span> <span class="fu">count</span>(biz_owner, age, politics) <span class="sc">%&gt;%</span> <span class="fu">nrow</span>()</span>
<span id="cb169-8"><a href="generalized-linear-models-glm.html#cb169-8" tabindex="-1"></a>cs3<span class="sc">$</span>possible_cells <span class="ot">&lt;-</span> </span>
<span id="cb169-9"><a href="generalized-linear-models-glm.html#cb169-9" tabindex="-1"></a>  cs3<span class="sc">$</span>covariate_patterns <span class="sc">*</span> <span class="fu">length</span>(<span class="fu">levels</span>(cs3<span class="sc">$</span>dat<span class="sc">$</span>tax_too_high))</span>
<span id="cb169-10"><a href="generalized-linear-models-glm.html#cb169-10" tabindex="-1"></a></span>
<span id="cb169-11"><a href="generalized-linear-models-glm.html#cb169-11" tabindex="-1"></a><span class="co"># 1 - ratio of observed to possible</span></span>
<span id="cb169-12"><a href="generalized-linear-models-glm.html#cb169-12" tabindex="-1"></a>cs3<span class="sc">$</span>pct_freq_zero <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> cs3<span class="sc">$</span>cell_patterns <span class="sc">/</span> cs3<span class="sc">$</span>possible_cells</span></code></pre></div>
<p>There are 137 observed combinations of model variables (predictors), and 372 possible combinations (predictors * outcome levels), so 63.2% of cells have zero frequencies. Ideally, zero frequencies should be less than 20%, so if you were to use the deviance or Pearson tests, you would need to report this. The results below are contradictory and bogus. I think you’d only use this test if you didn’t have continuous predictor variables.</p>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="generalized-linear-models-glm.html#cb170-1" tabindex="-1"></a>observed <span class="ot">&lt;-</span> cs3<span class="sc">$</span>dat <span class="sc">%&gt;%</span> </span>
<span id="cb170-2"><a href="generalized-linear-models-glm.html#cb170-2" tabindex="-1"></a>  <span class="fu">count</span>(biz_owner, age, politics, tax_too_high) <span class="sc">%&gt;%</span></span>
<span id="cb170-3"><a href="generalized-linear-models-glm.html#cb170-3" tabindex="-1"></a>  <span class="fu">pivot_wider</span>(<span class="at">names_from =</span> tax_too_high, <span class="at">values_from =</span> n, <span class="at">values_fill =</span> <span class="dv">0</span>) <span class="sc">%&gt;%</span></span>
<span id="cb170-4"><a href="generalized-linear-models-glm.html#cb170-4" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(</span>
<span id="cb170-5"><a href="generalized-linear-models-glm.html#cb170-5" tabindex="-1"></a>    <span class="at">cols =</span> <span class="st">`</span><span class="at">Strongly Disagree</span><span class="st">`</span><span class="sc">:</span><span class="st">`</span><span class="at">Strongly Agree</span><span class="st">`</span>, </span>
<span id="cb170-6"><a href="generalized-linear-models-glm.html#cb170-6" tabindex="-1"></a>    <span class="at">names_to =</span> <span class="st">&quot;outcome&quot;</span>, </span>
<span id="cb170-7"><a href="generalized-linear-models-glm.html#cb170-7" tabindex="-1"></a>    <span class="at">values_to =</span> <span class="st">&quot;observed&quot;</span></span>
<span id="cb170-8"><a href="generalized-linear-models-glm.html#cb170-8" tabindex="-1"></a>  )</span>
<span id="cb170-9"><a href="generalized-linear-models-glm.html#cb170-9" tabindex="-1"></a></span>
<span id="cb170-10"><a href="generalized-linear-models-glm.html#cb170-10" tabindex="-1"></a>expected <span class="ot">&lt;-</span> <span class="fu">bind_cols</span>(</span>
<span id="cb170-11"><a href="generalized-linear-models-glm.html#cb170-11" tabindex="-1"></a>  cs3<span class="sc">$</span>dat, </span>
<span id="cb170-12"><a href="generalized-linear-models-glm.html#cb170-12" tabindex="-1"></a>  cs3<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">predict</span>(<span class="at">newdata =</span> cs3<span class="sc">$</span>dat <span class="sc">%&gt;%</span> <span class="fu">select</span>(<span class="sc">-</span><span class="st">&quot;tax_too_high&quot;</span>)) <span class="sc">%&gt;%</span> <span class="fu">data.frame</span>()</span>
<span id="cb170-13"><a href="generalized-linear-models-glm.html#cb170-13" tabindex="-1"></a>) <span class="sc">%&gt;%</span></span>
<span id="cb170-14"><a href="generalized-linear-models-glm.html#cb170-14" tabindex="-1"></a>  <span class="fu">rename_with</span>(<span class="sc">~</span><span class="fu">str_remove</span>(., <span class="st">&quot;fit</span><span class="sc">\\</span><span class="st">.&quot;</span>), <span class="fu">starts_with</span>(<span class="st">&quot;fit&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb170-15"><a href="generalized-linear-models-glm.html#cb170-15" tabindex="-1"></a>  <span class="fu">rename_with</span>(<span class="sc">~</span><span class="fu">str_replace</span>(., <span class="st">&quot;</span><span class="sc">\\</span><span class="st">.&quot;</span>, <span class="st">&quot; &quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb170-16"><a href="generalized-linear-models-glm.html#cb170-16" tabindex="-1"></a>  <span class="fu">summarize</span>(<span class="at">.by =</span> <span class="fu">c</span>(biz_owner, age, politics), </span>
<span id="cb170-17"><a href="generalized-linear-models-glm.html#cb170-17" tabindex="-1"></a>            <span class="fu">across</span>(<span class="st">`</span><span class="at">Strongly Disagree</span><span class="st">`</span><span class="sc">:</span><span class="st">`</span><span class="at">Strongly Agree</span><span class="st">`</span>, sum)) <span class="sc">%&gt;%</span></span>
<span id="cb170-18"><a href="generalized-linear-models-glm.html#cb170-18" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="st">`</span><span class="at">Strongly Disagree</span><span class="st">`</span><span class="sc">:</span><span class="st">`</span><span class="at">Strongly Agree</span><span class="st">`</span>, <span class="at">names_to =</span> <span class="st">&quot;outcome&quot;</span>, <span class="at">values_to =</span> <span class="st">&quot;expected&quot;</span>)</span>
<span id="cb170-19"><a href="generalized-linear-models-glm.html#cb170-19" tabindex="-1"></a></span>
<span id="cb170-20"><a href="generalized-linear-models-glm.html#cb170-20" tabindex="-1"></a>obs_exp <span class="ot">&lt;-</span> observed <span class="sc">%&gt;%</span></span>
<span id="cb170-21"><a href="generalized-linear-models-glm.html#cb170-21" tabindex="-1"></a>  <span class="fu">inner_join</span>(expected, <span class="at">by =</span> <span class="fu">c</span>(<span class="st">&quot;politics&quot;</span>, <span class="st">&quot;biz_owner&quot;</span>, <span class="st">&quot;age&quot;</span>, <span class="st">&quot;outcome&quot;</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb170-22"><a href="generalized-linear-models-glm.html#cb170-22" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">epsilon_sq =</span> (observed <span class="sc">-</span> expected)<span class="sc">^</span><span class="dv">2</span>,</span>
<span id="cb170-23"><a href="generalized-linear-models-glm.html#cb170-23" tabindex="-1"></a>         <span class="at">chi_sq =</span> epsilon_sq <span class="sc">/</span> expected,</span>
<span id="cb170-24"><a href="generalized-linear-models-glm.html#cb170-24" tabindex="-1"></a>         <span class="at">g_sq =</span> <span class="dv">2</span> <span class="sc">*</span> observed <span class="sc">*</span> <span class="fu">log</span>((observed<span class="fl">+.0001</span>) <span class="sc">/</span> expected)</span>
<span id="cb170-25"><a href="generalized-linear-models-glm.html#cb170-25" tabindex="-1"></a>  )</span>
<span id="cb170-26"><a href="generalized-linear-models-glm.html#cb170-26" tabindex="-1"></a></span>
<span id="cb170-27"><a href="generalized-linear-models-glm.html#cb170-27" tabindex="-1"></a>cs3<span class="sc">$</span>chisq <span class="ot">&lt;-</span> <span class="fu">list</span>()</span>
<span id="cb170-28"><a href="generalized-linear-models-glm.html#cb170-28" tabindex="-1"></a>cs3<span class="sc">$</span>chisq<span class="sc">$</span>X2 <span class="ot">=</span> <span class="fu">sum</span>(obs_exp<span class="sc">$</span>chi_sq)</span>
<span id="cb170-29"><a href="generalized-linear-models-glm.html#cb170-29" tabindex="-1"></a>cs3<span class="sc">$</span>chisq<span class="sc">$</span>G2 <span class="ot">=</span> <span class="fu">sum</span>(obs_exp<span class="sc">$</span>g_sq)</span>
<span id="cb170-30"><a href="generalized-linear-models-glm.html#cb170-30" tabindex="-1"></a>cs3<span class="sc">$</span>chisq<span class="sc">$</span>df <span class="ot">=</span> cs3<span class="sc">$</span>covariate_patterns <span class="sc">*</span> (<span class="fu">length</span>(<span class="fu">levels</span>(cs3<span class="sc">$</span>dat<span class="sc">$</span>tax_too_high)) <span class="sc">-</span> <span class="dv">1</span>) <span class="sc">-</span> <span class="dv">7</span></span>
<span id="cb170-31"><a href="generalized-linear-models-glm.html#cb170-31" tabindex="-1"></a>cs3<span class="sc">$</span>chisq<span class="sc">$</span>X2_p.value <span class="ot">=</span> <span class="fu">pchisq</span>(cs3<span class="sc">$</span>chisq<span class="sc">$</span>X2, <span class="at">df =</span> cs3<span class="sc">$</span>chisq<span class="sc">$</span>df, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb170-32"><a href="generalized-linear-models-glm.html#cb170-32" tabindex="-1"></a>cs3<span class="sc">$</span>chisq<span class="sc">$</span>G2_p.value <span class="ot">=</span> <span class="fu">pchisq</span>(cs3<span class="sc">$</span>chisq<span class="sc">$</span>G2, <span class="at">df =</span> cs3<span class="sc">$</span>chisq<span class="sc">$</span>df, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<blockquote>
<p>The Pearson goodness-of-fit test indicated that the model was <em>not</em> a good fit to the observed data, <span class="math inline">\(\chi^2\)</span>(272) = 745.4, <em>p</em> &lt; .001$. The deviance goodness-of-fit test indicated that the model was a good fit to the observed data, <span class="math inline">\(G^2\)</span>(272) = 232.6, <em>p</em> = 0.960.</p>
</blockquote>
<p>There are a number of measures in ordinal regression that attempt to provide a similar “variance explained” measure as that provided in ordinary least-squares linear regression. However, these measures do not have the direct interpretation that they do in ordinary linear regression and are often, therefore, referred to as <strong>“pseudo” R2 measures</strong>. The three most common measures (Cox and Snell, Nagelkerke, and McFadden) are not particularly good and not universally used. It is presented in the SPSS output, so you might encounter it in published work.</p>
<div class="sourceCode" id="cb171"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb171-1"><a href="generalized-linear-models-glm.html#cb171-1" tabindex="-1"></a>cs3<span class="sc">$</span>nagelkerke <span class="ot">&lt;-</span> rcompanion<span class="sc">::</span><span class="fu">nagelkerke</span>(cs3<span class="sc">$</span>result)</span>
<span id="cb171-2"><a href="generalized-linear-models-glm.html#cb171-2" tabindex="-1"></a>cs3<span class="sc">$</span>nagelkerke<span class="sc">$</span>Pseudo.R.squared.for.model.vs.null</span></code></pre></div>
<pre><code>##                              Pseudo.R.squared
## McFadden                             0.181957
## Cox and Snell (ML)                   0.367369
## Nagelkerke (Cragg and Uhler)         0.399641</code></pre>
<p>The best way to assess model fit is the <strong>likelihood ratio test</strong> comparing the model to an intercept-only model. The difference in the -2 log likelihood between the models has a <span class="math inline">\(\chi^2\)</span> distribution with degrees of freedom equal to the difference in the number of parameters.</p>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="generalized-linear-models-glm.html#cb173-1" tabindex="-1"></a>intercept_only <span class="ot">&lt;-</span> ordinal<span class="sc">::</span><span class="fu">clm</span>(tax_too_high <span class="sc">~</span> <span class="dv">1</span>, <span class="at">data =</span> cs3<span class="sc">$</span>dat)</span>
<span id="cb173-2"><a href="generalized-linear-models-glm.html#cb173-2" tabindex="-1"></a>cs3<span class="sc">$</span>lrt <span class="ot">&lt;-</span> <span class="fu">anova</span>(cs3<span class="sc">$</span>result, intercept_only)</span>
<span id="cb173-3"><a href="generalized-linear-models-glm.html#cb173-3" tabindex="-1"></a>cs3<span class="sc">$</span>lrt</span></code></pre></div>
<pre><code>## Likelihood ratio tests of cumulative link models:
##  
##                formula:         link: threshold:
## intercept_only tax_too_high ~ 1 logit flexible  
## cs3$result     cs3$fmla         logit flexible  
## 
##                no.par    AIC  logLik LR.stat df Pr(&gt;Chisq)    
## intercept_only      3 489.14 -241.57                          
## cs3$result          7 409.23 -197.62  87.911  4  &lt; 2.2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<p>The table shows the log likelihoods of the two models. LR.stat is the difference between 2 * the logLik values.</p>
<blockquote>
<p>The final model statistically significantly predicted the dependent variable over and above the intercept-only model, <span class="math inline">\(\chi^2(4)\)</span> = 87.9, <em>p</em> = 0.000.</p>
</blockquote>
</div>
<div id="interpret-results" class="section level3 unnumbered hasAnchor">
<h3>Interpret Results<a href="generalized-linear-models-glm.html#interpret-results" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Return to the model summary.</p>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="generalized-linear-models-glm.html#cb175-1" tabindex="-1"></a><span class="fu">tidy</span>(cs3<span class="sc">$</span>clm)</span></code></pre></div>
<pre><code>## # A tibble: 0 × 0</code></pre>
<p>The coefficients for <code>biz_owner</code>, <code>age</code>, and politics are positive. Positive parameters <em>increase</em> the likelihood of stronger agreement with the statement. In this case, discontent with taxes are higher for business owners, increase with age, and are higher for Liberal Democrats and Conservatives relative to the Labor Party. The expected cumulative log-odds of declaring <span class="math inline">\(\le j\)</span> level of agreement with the statement for the baseline group (<code>biz_ownerNo</code>, <code>age = 0</code>, <code>politicsLib</code>) is for <span class="math inline">\(j = 1\)</span> (Strongly Disagree), for <span class="math inline">\(j = 2\)</span> (Disagree), and for <span class="math inline">\(j = 3\)</span> (Agree).</p>
<p>You could solve the logit equation for</p>
<p><span class="math display">\[\pi_j = \frac{\mathrm{exp}(Y_i)} {1 + \mathrm{exp}(Y_i)}\]</span>
to get the cumulative probabilities for each level. That’s what <code>predict(type = "cum.prob")</code> does. But it might be more intuitive to work with individual probabilities, the lagged differences to get the individual probabilities for each <span class="math inline">\(j\)</span>. That’s what <code>predict(type = "prob")</code> does. I like to play with predicted values to get a sense of the outcome distributions. In this case, I’ll take the median <code>age</code>, and each combination of <code>biz_owner</code> and <code>politics</code>.</p>
<div class="sourceCode" id="cb177"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb177-1"><a href="generalized-linear-models-glm.html#cb177-1" tabindex="-1"></a>new_data <span class="ot">&lt;-</span> cs3<span class="sc">$</span>dat <span class="sc">%&gt;%</span> </span>
<span id="cb177-2"><a href="generalized-linear-models-glm.html#cb177-2" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">age =</span> <span class="fu">median</span>(cs3<span class="sc">$</span>dat<span class="sc">$</span>age)) <span class="sc">%&gt;%</span> </span>
<span id="cb177-3"><a href="generalized-linear-models-glm.html#cb177-3" tabindex="-1"></a>  <span class="fu">expand</span>(age, politics, biz_owner)</span>
<span id="cb177-4"><a href="generalized-linear-models-glm.html#cb177-4" tabindex="-1"></a></span>
<span id="cb177-5"><a href="generalized-linear-models-glm.html#cb177-5" tabindex="-1"></a>preds <span class="ot">&lt;-</span> <span class="fu">predict</span>(cs3<span class="sc">$</span>result, <span class="at">newdata =</span> new_data, <span class="at">type =</span> <span class="st">&quot;prob&quot;</span>)[[<span class="st">&quot;fit&quot;</span>]] <span class="sc">%&gt;%</span> <span class="fu">as.data.frame</span>()</span>
<span id="cb177-6"><a href="generalized-linear-models-glm.html#cb177-6" tabindex="-1"></a></span>
<span id="cb177-7"><a href="generalized-linear-models-glm.html#cb177-7" tabindex="-1"></a><span class="fu">bind_cols</span>(new_data, preds) <span class="sc">%&gt;%</span></span>
<span id="cb177-8"><a href="generalized-linear-models-glm.html#cb177-8" tabindex="-1"></a>  <span class="fu">pivot_longer</span>(<span class="at">cols =</span> <span class="st">`</span><span class="at">Strongly Disagree</span><span class="st">`</span><span class="sc">:</span><span class="st">`</span><span class="at">Strongly Agree</span><span class="st">`</span>) <span class="sc">%&gt;%</span> </span>
<span id="cb177-9"><a href="generalized-linear-models-glm.html#cb177-9" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">name =</span> <span class="fu">factor</span>(name, <span class="at">levels =</span> <span class="fu">levels</span>(cs3<span class="sc">$</span>dat<span class="sc">$</span>tax_too_high))) <span class="sc">%&gt;%</span></span>
<span id="cb177-10"><a href="generalized-linear-models-glm.html#cb177-10" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">y =</span> politics, <span class="at">x =</span> value, <span class="at">fill =</span> <span class="fu">fct_rev</span>(name))) <span class="sc">+</span></span>
<span id="cb177-11"><a href="generalized-linear-models-glm.html#cb177-11" tabindex="-1"></a>  <span class="fu">geom_col</span>() <span class="sc">+</span></span>
<span id="cb177-12"><a href="generalized-linear-models-glm.html#cb177-12" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">label =</span> scales<span class="sc">::</span><span class="fu">percent</span>(value, <span class="at">accuracy =</span> <span class="dv">1</span>)), </span>
<span id="cb177-13"><a href="generalized-linear-models-glm.html#cb177-13" tabindex="-1"></a>            <span class="at">size =</span> <span class="dv">3</span>, <span class="at">position =</span> <span class="fu">position_stack</span>(<span class="at">vjust=</span><span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb177-14"><a href="generalized-linear-models-glm.html#cb177-14" tabindex="-1"></a>  <span class="fu">facet_grid</span>(<span class="sc">~</span><span class="fu">paste</span>(<span class="st">&quot;Bus Owner = &quot;</span>, biz_owner)) <span class="sc">+</span></span>
<span id="cb177-15"><a href="generalized-linear-models-glm.html#cb177-15" tabindex="-1"></a>  <span class="fu">scale_fill_grey</span>(<span class="at">start =</span> <span class="fl">0.5</span>, <span class="at">end =</span> <span class="fl">0.8</span>) <span class="sc">+</span></span>
<span id="cb177-16"><a href="generalized-linear-models-glm.html#cb177-16" tabindex="-1"></a>  <span class="fu">theme_bw</span>() <span class="sc">+</span> </span>
<span id="cb177-17"><a href="generalized-linear-models-glm.html#cb177-17" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">legend.position =</span> <span class="st">&quot;top&quot;</span>,</span>
<span id="cb177-18"><a href="generalized-linear-models-glm.html#cb177-18" tabindex="-1"></a>        <span class="at">axis.text.x =</span> <span class="fu">element_blank</span>(),</span>
<span id="cb177-19"><a href="generalized-linear-models-glm.html#cb177-19" tabindex="-1"></a>        <span class="at">axis.ticks.x =</span> <span class="fu">element_blank</span>()) <span class="sc">+</span></span>
<span id="cb177-20"><a href="generalized-linear-models-glm.html#cb177-20" tabindex="-1"></a>  <span class="fu">guides</span>(<span class="at">fill =</span> <span class="fu">guide_legend</span>(<span class="at">reverse =</span> <span class="cn">TRUE</span>)) <span class="sc">+</span></span>
<span id="cb177-21"><a href="generalized-linear-models-glm.html#cb177-21" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Taxes too High for Conservative Business Owners?&quot;</span>, </span>
<span id="cb177-22"><a href="generalized-linear-models-glm.html#cb177-22" tabindex="-1"></a>       <span class="at">x =</span> <span class="cn">NULL</span>, <span class="at">fill =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<p><img src="supervised-ml_files/figure-html/unnamed-chunk-124-1.png" width="624" /></p>
<p>You will want to establish whether <code>politics</code> is statistically significant overall before exploring any specific contrasts. The ANOVA procedure with type I test reports an overall test of significance for each variable entered into the model.</p>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="generalized-linear-models-glm.html#cb178-1" tabindex="-1"></a>(cs3<span class="sc">$</span>anovaI <span class="ot">&lt;-</span> <span class="fu">anova</span>(cs3<span class="sc">$</span>result, <span class="at">type =</span> <span class="st">&quot;I&quot;</span>))</span></code></pre></div>
<pre><code>## Type I Analysis of Deviance Table with Wald chi-square tests
## 
##           Df  Chisq Pr(&gt;Chisq)    
## biz_owner  1 13.201  0.0002798 ***
## age        1 57.413  3.533e-14 ***
## politics   2 14.636  0.0006635 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
<blockquote>
<p>The political party last voted for has a statistically significant effect on the prediction of whether tax is thought to be too high, Wald <span class="math inline">\(\chi^2\)</span>(2) = 14.6, <em>p</em> = 0.001.</p>
</blockquote>
<p>The best way to work with the data is with the <code>tidy(exponentiate = TRUE)</code> version.</p>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="generalized-linear-models-glm.html#cb180-1" tabindex="-1"></a>cs3<span class="sc">$</span>tidy <span class="ot">&lt;-</span> cs3<span class="sc">$</span>result <span class="sc">%&gt;%</span> <span class="fu">tidy</span>(<span class="at">conf.int =</span> <span class="cn">TRUE</span>, <span class="at">exponentiate =</span> <span class="cn">TRUE</span>)</span>
<span id="cb180-2"><a href="generalized-linear-models-glm.html#cb180-2" tabindex="-1"></a>cs3<span class="sc">$</span>tidy</span></code></pre></div>
<pre><code>## # A tibble: 7 × 8
##   term        estimate std.error statistic  p.value conf.low conf.high coef.type
##   &lt;chr&gt;          &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt;    
## 1 Strongly D…   1.13e3    1.17       6.02  1.70e- 9   NA         NA    intercept
## 2 Disagree|A…   6.41e3    1.23       7.12  1.08e-12   NA         NA    intercept
## 3 Agree|Stro…   1.15e5    1.36       8.59  8.72e-18   NA         NA    intercept
## 4 biz_ownerY…   1.94e0    0.289      2.30  2.14e- 2    1.11       3.44 location 
## 5 age           1.27e0    0.0326     7.42  1.17e-13    1.20       1.36 location 
## 6 politicsLib   1.04e0    0.364      0.102 9.19e- 1    0.508      2.12 location 
## 7 politicsCon   3.19e0    0.346      3.36  7.76e- 4    1.63       6.35 location</code></pre>
<p>Then you can summarize the table in words.</p>
<blockquote>
<p>The odds of business owners considering tax to be too high was 1.944 (95% CI, 1.107 to 3.443) times that of non-business owners, a statistically significant effect, <em>z</em> = 2.300, <em>p</em> = 0.021.</p>
</blockquote>
<blockquote>
<p>The odds of Conservative voters considering tax to be too high was 3.194 (95% CI, 1.635 to 6.351) times that of Labour voters, a statistically significant effect, <em>z</em> = 3.361, <em>p</em> = 0.001. The odds of Liberal Democrat voters considering tax to be too high was similar to that of Labour voters (odds ratio of 1.038 (95% CI, 0.508 to 2.121), <em>p</em> = 0.919.</p>
</blockquote>
<blockquote>
<p>An increase in age (expressed in years) was associated with an increase in the odds of considering tax too high, with an odds ratio of 1.274 (95% CI, 1.197 to 1.360), <em>z</em> = 7.421, <em>p</em> = 0.000.</p>
</blockquote>
</div>
<div id="reporting-2" class="section level3 unnumbered hasAnchor">
<h3>Reporting<a href="generalized-linear-models-glm.html#reporting-2" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Here is the complete write-up.</p>
<blockquote>
<p>A cumulative odds ordinal logistic regression with proportional odds was run to determine the effect of business ownership, political party voted for, and age, on the belief that taxes are too high. There were proportional odds, as assessed by a full likelihood ratio test comparing the fitted model to a model with varying location parameters, <span class="math inline">\(\chi^2\)</span>(8) = 8.620, <em>p</em> = 0.375. The final model statistically significantly predicted the dependent variable over and above the intercept-only model, <span class="math inline">\(\chi^2(4)\)</span> = 87.9, <em>p</em> = 0.000. The odds of business owners considering tax to be too high was 1.944 (95% CI, 1.107 to 3.443) times that of non-business owners, a statistically significant effect, <em>z</em> = 2.300, <em>p</em> = 0.021. The political party last voted for has a statistically significant effect on the prediction of whether tax is thought to be too high, Wald <span class="math inline">\(\chi^2\)</span>(2) = 14.6, <em>p</em> = 0.001. The odds of Conservative voters considering tax to be too high was 3.194 (95% CI, 1.635 to 6.351) times that of Labour voters, a statistically significant effect, <em>z</em> = 3.361, <em>p</em> = 0.001. The odds of Liberal Democrat voters considering tax to be too high was similar to that of Labour voters (odds ratio of 1.038 (95% CI, 0.508 to 2.121), <em>p</em> = 0.919. An increase in age (expressed in years) was associated with an increase in the odds of considering tax too high, with an odds ratio of 1.274 (95% CI, 1.197 to 1.360), <em>z</em> = 7.421, <em>p</em> = 0.000.</p>
</blockquote>
<p>Package <strong>gtsummary</strong> shows a nice summary table.</p>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="generalized-linear-models-glm.html#cb182-1" tabindex="-1"></a>gtsummary<span class="sc">::</span><span class="fu">tbl_regression</span>(cs3<span class="sc">$</span>result)</span></code></pre></div>
<div id="zjxvwzkays" style="padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;">
<style>#zjxvwzkays table {
  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';
  -webkit-font-smoothing: antialiased;
  -moz-osx-font-smoothing: grayscale;
}

#zjxvwzkays thead, #zjxvwzkays tbody, #zjxvwzkays tfoot, #zjxvwzkays tr, #zjxvwzkays td, #zjxvwzkays th {
  border-style: none;
}

#zjxvwzkays p {
  margin: 0;
  padding: 0;
}

#zjxvwzkays .gt_table {
  display: table;
  border-collapse: collapse;
  line-height: normal;
  margin-left: auto;
  margin-right: auto;
  color: #333333;
  font-size: 16px;
  font-weight: normal;
  font-style: normal;
  background-color: #FFFFFF;
  width: auto;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #A8A8A8;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #A8A8A8;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
}

#zjxvwzkays .gt_caption {
  padding-top: 4px;
  padding-bottom: 4px;
}

#zjxvwzkays .gt_title {
  color: #333333;
  font-size: 125%;
  font-weight: initial;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-color: #FFFFFF;
  border-bottom-width: 0;
}

#zjxvwzkays .gt_subtitle {
  color: #333333;
  font-size: 85%;
  font-weight: initial;
  padding-top: 3px;
  padding-bottom: 5px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-color: #FFFFFF;
  border-top-width: 0;
}

#zjxvwzkays .gt_heading {
  background-color: #FFFFFF;
  text-align: center;
  border-bottom-color: #FFFFFF;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#zjxvwzkays .gt_bottom_border {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#zjxvwzkays .gt_col_headings {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
}

#zjxvwzkays .gt_col_heading {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 6px;
  padding-left: 5px;
  padding-right: 5px;
  overflow-x: hidden;
}

#zjxvwzkays .gt_column_spanner_outer {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: normal;
  text-transform: inherit;
  padding-top: 0;
  padding-bottom: 0;
  padding-left: 4px;
  padding-right: 4px;
}

#zjxvwzkays .gt_column_spanner_outer:first-child {
  padding-left: 0;
}

#zjxvwzkays .gt_column_spanner_outer:last-child {
  padding-right: 0;
}

#zjxvwzkays .gt_column_spanner {
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: bottom;
  padding-top: 5px;
  padding-bottom: 5px;
  overflow-x: hidden;
  display: inline-block;
  width: 100%;
}

#zjxvwzkays .gt_spanner_row {
  border-bottom-style: hidden;
}

#zjxvwzkays .gt_group_heading {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  text-align: left;
}

#zjxvwzkays .gt_empty_group_heading {
  padding: 0.5px;
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  vertical-align: middle;
}

#zjxvwzkays .gt_from_md > :first-child {
  margin-top: 0;
}

#zjxvwzkays .gt_from_md > :last-child {
  margin-bottom: 0;
}

#zjxvwzkays .gt_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  margin: 10px;
  border-top-style: solid;
  border-top-width: 1px;
  border-top-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 1px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 1px;
  border-right-color: #D3D3D3;
  vertical-align: middle;
  overflow-x: hidden;
}

#zjxvwzkays .gt_stub {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
}

#zjxvwzkays .gt_stub_row_group {
  color: #333333;
  background-color: #FFFFFF;
  font-size: 100%;
  font-weight: initial;
  text-transform: inherit;
  border-right-style: solid;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
  padding-left: 5px;
  padding-right: 5px;
  vertical-align: top;
}

#zjxvwzkays .gt_row_group_first td {
  border-top-width: 2px;
}

#zjxvwzkays .gt_row_group_first th {
  border-top-width: 2px;
}

#zjxvwzkays .gt_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#zjxvwzkays .gt_first_summary_row {
  border-top-style: solid;
  border-top-color: #D3D3D3;
}

#zjxvwzkays .gt_first_summary_row.thick {
  border-top-width: 2px;
}

#zjxvwzkays .gt_last_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#zjxvwzkays .gt_grand_summary_row {
  color: #333333;
  background-color: #FFFFFF;
  text-transform: inherit;
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
}

#zjxvwzkays .gt_first_grand_summary_row {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-top-style: double;
  border-top-width: 6px;
  border-top-color: #D3D3D3;
}

#zjxvwzkays .gt_last_grand_summary_row_top {
  padding-top: 8px;
  padding-bottom: 8px;
  padding-left: 5px;
  padding-right: 5px;
  border-bottom-style: double;
  border-bottom-width: 6px;
  border-bottom-color: #D3D3D3;
}

#zjxvwzkays .gt_striped {
  background-color: rgba(128, 128, 128, 0.05);
}

#zjxvwzkays .gt_table_body {
  border-top-style: solid;
  border-top-width: 2px;
  border-top-color: #D3D3D3;
  border-bottom-style: solid;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
}

#zjxvwzkays .gt_footnotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#zjxvwzkays .gt_footnote {
  margin: 0px;
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#zjxvwzkays .gt_sourcenotes {
  color: #333333;
  background-color: #FFFFFF;
  border-bottom-style: none;
  border-bottom-width: 2px;
  border-bottom-color: #D3D3D3;
  border-left-style: none;
  border-left-width: 2px;
  border-left-color: #D3D3D3;
  border-right-style: none;
  border-right-width: 2px;
  border-right-color: #D3D3D3;
}

#zjxvwzkays .gt_sourcenote {
  font-size: 90%;
  padding-top: 4px;
  padding-bottom: 4px;
  padding-left: 5px;
  padding-right: 5px;
}

#zjxvwzkays .gt_left {
  text-align: left;
}

#zjxvwzkays .gt_center {
  text-align: center;
}

#zjxvwzkays .gt_right {
  text-align: right;
  font-variant-numeric: tabular-nums;
}

#zjxvwzkays .gt_font_normal {
  font-weight: normal;
}

#zjxvwzkays .gt_font_bold {
  font-weight: bold;
}

#zjxvwzkays .gt_font_italic {
  font-style: italic;
}

#zjxvwzkays .gt_super {
  font-size: 65%;
}

#zjxvwzkays .gt_footnote_marks {
  font-size: 75%;
  vertical-align: 0.4em;
  position: initial;
}

#zjxvwzkays .gt_asterisk {
  font-size: 100%;
  vertical-align: 0;
}

#zjxvwzkays .gt_indent_1 {
  text-indent: 5px;
}

#zjxvwzkays .gt_indent_2 {
  text-indent: 10px;
}

#zjxvwzkays .gt_indent_3 {
  text-indent: 15px;
}

#zjxvwzkays .gt_indent_4 {
  text-indent: 20px;
}

#zjxvwzkays .gt_indent_5 {
  text-indent: 25px;
}
</style>
<table class="gt_table" data-quarto-disable-processing="false" data-quarto-bootstrap="false">
  <thead>
    
    <tr class="gt_col_headings">
      <th class="gt_col_heading gt_columns_bottom_border gt_left" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;Characteristic&lt;/strong&gt;"><strong>Characteristic</strong></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;log(OR)&lt;/strong&gt;&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>log(OR)</strong><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;95% CI&lt;/strong&gt;&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;"><strong>95% CI</strong><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span></th>
      <th class="gt_col_heading gt_columns_bottom_border gt_center" rowspan="1" colspan="1" scope="col" id="&lt;strong&gt;p-value&lt;/strong&gt;"><strong>p-value</strong></th>
    </tr>
  </thead>
  <tbody class="gt_table_body">
    <tr><td headers="label" class="gt_row gt_left">biz_owner</td>
<td headers="estimate" class="gt_row gt_center"><br /></td>
<td headers="ci" class="gt_row gt_center"><br /></td>
<td headers="p.value" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    No</td>
<td headers="estimate" class="gt_row gt_center">—</td>
<td headers="ci" class="gt_row gt_center">—</td>
<td headers="p.value" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Yes</td>
<td headers="estimate" class="gt_row gt_center">0.66</td>
<td headers="ci" class="gt_row gt_center">0.10, 1.2</td>
<td headers="p.value" class="gt_row gt_center">0.021</td></tr>
    <tr><td headers="label" class="gt_row gt_left">age</td>
<td headers="estimate" class="gt_row gt_center">0.24</td>
<td headers="ci" class="gt_row gt_center">0.18, 0.31</td>
<td headers="p.value" class="gt_row gt_center"><0.001</td></tr>
    <tr><td headers="label" class="gt_row gt_left">politics</td>
<td headers="estimate" class="gt_row gt_center"><br /></td>
<td headers="ci" class="gt_row gt_center"><br /></td>
<td headers="p.value" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Lab</td>
<td headers="estimate" class="gt_row gt_center">—</td>
<td headers="ci" class="gt_row gt_center">—</td>
<td headers="p.value" class="gt_row gt_center"><br /></td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Lib</td>
<td headers="estimate" class="gt_row gt_center">0.04</td>
<td headers="ci" class="gt_row gt_center">-0.68, 0.75</td>
<td headers="p.value" class="gt_row gt_center">>0.9</td></tr>
    <tr><td headers="label" class="gt_row gt_left">    Con</td>
<td headers="estimate" class="gt_row gt_center">1.2</td>
<td headers="ci" class="gt_row gt_center">0.49, 1.8</td>
<td headers="p.value" class="gt_row gt_center"><0.001</td></tr>
  </tbody>
  
  <tfoot class="gt_footnotes">
    <tr>
      <td class="gt_footnote" colspan="4"><span class="gt_footnote_marks" style="white-space:nowrap;font-style:italic;font-weight:normal;"><sup>1</sup></span> OR = Odds Ratio, CI = Confidence Interval</td>
    </tr>
  </tfoot>
</table>
</div>
</div>
</div>
<div id="poissonregression" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Poisson Regression<a href="generalized-linear-models-glm.html#poissonregression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Poisson models count data, like “traffic tickets per day”, or “website hits per day”. The response is an expected <em>rate</em> or intensity. For count data, specify the generalized model, this time with <code>family = poisson</code> or <code>family = quasipoisson</code>.</p>
<p>Recall that the probability of achieving a count <span class="math inline">\(y\)</span> when the expected rate is <span class="math inline">\(\lambda\)</span> is distributed</p>
<p><span class="math display">\[P(Y = y|\lambda) = \frac{e^{-\lambda} \lambda^y}{y!}.\]</span></p>
<p>The poisson regression model is</p>
<p><span class="math display">\[\lambda = \exp(X \beta).\]</span></p>
<p>You can solve this for <span class="math inline">\(y\)</span> to get</p>
<p><span class="math display">\[y = X\beta = \ln(\lambda).\]</span></p>
<p>That is, the model predicts the log of the response rate. For a sample of size <em>n</em>, the likelihood function is</p>
<p><span class="math display">\[L(\beta; y, X) = \prod_{i=1}^n \frac{e^{-\exp({X_i\beta})}\exp({X_i\beta})^{y_i}}{y_i!}.\]</span></p>
<p>The log-likelihood is</p>
<p><span class="math display">\[l(\beta) = \sum_{i=1}^n (y_i X_i \beta - \sum_{i=1}^n\exp(X_i\beta) - \sum_{i=1}^n\log(y_i!).\]</span></p>
<p>Maximizing the log-likelihood has no closed-form solution, so the coefficient estimates are found through interatively reweighted least squares.</p>
<p>Poisson processes assume the variance of the response variable equals its mean. “Equals” means the mean and variance are of a similar order of magnitude. If that assumption does not hold, use the quasi-poisson. Use Poisson regression for large datasets. If the predicted counts are much greater than zero (&gt;30), the linear regression will work fine. Whereas RMSE is not useful for logistic models, it is a good metric in Poisson.</p>
<div id="cs4" class="section level3 unnumbered hasAnchor">
<h3>Case Study 4<a href="generalized-linear-models-glm.html#cs4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dataset <code>fire</code> contains response variable <code>injuries</code> counting the number of injuries during the month and one explanatory variable, the month <code>mo</code>.</p>
<div class="sourceCode" id="cb183"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb183-1"><a href="generalized-linear-models-glm.html#cb183-1" tabindex="-1"></a>fire <span class="ot">&lt;-</span> <span class="fu">read_csv</span>(<span class="at">file =</span> <span class="st">&quot;C:/Users/mpfol/OneDrive/Documents/Data Science/Data/CivilInjury_0.csv&quot;</span>)</span>
<span id="cb183-2"><a href="generalized-linear-models-glm.html#cb183-2" tabindex="-1"></a>fire <span class="ot">&lt;-</span> fire <span class="sc">%&gt;%</span> </span>
<span id="cb183-3"><a href="generalized-linear-models-glm.html#cb183-3" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mo =</span> <span class="fu">as.POSIXlt</span>(<span class="st">`</span><span class="at">Injury Date</span><span class="st">`</span>)<span class="sc">$</span>mon <span class="sc">+</span> <span class="dv">1</span>) <span class="sc">%&gt;%</span></span>
<span id="cb183-4"><a href="generalized-linear-models-glm.html#cb183-4" tabindex="-1"></a>  <span class="fu">rename</span>(<span class="at">dt =</span> <span class="st">`</span><span class="at">Injury Date</span><span class="st">`</span>,</span>
<span id="cb183-5"><a href="generalized-linear-models-glm.html#cb183-5" tabindex="-1"></a>         <span class="at">injuries =</span> <span class="st">`</span><span class="at">Total Injuries</span><span class="st">`</span>)</span>
<span id="cb183-6"><a href="generalized-linear-models-glm.html#cb183-6" tabindex="-1"></a><span class="fu">str</span>(fire)</span></code></pre></div>
<p>In a situation like this where there the relationship is bivariate, start with a visualization.</p>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="generalized-linear-models-glm.html#cb184-1" tabindex="-1"></a><span class="fu">ggplot</span>(fire, <span class="fu">aes</span>(<span class="at">x =</span> mo, <span class="at">y =</span> injuries)) <span class="sc">+</span></span>
<span id="cb184-2"><a href="generalized-linear-models-glm.html#cb184-2" tabindex="-1"></a>  <span class="fu">geom_jitter</span>() <span class="sc">+</span></span>
<span id="cb184-3"><a href="generalized-linear-models-glm.html#cb184-3" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span> <span class="st">&quot;glm&quot;</span>, <span class="at">method.args =</span> <span class="fu">list</span>(<span class="at">family =</span> <span class="st">&quot;poisson&quot;</span>)) <span class="sc">+</span></span>
<span id="cb184-4"><a href="generalized-linear-models-glm.html#cb184-4" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">title =</span> <span class="st">&quot;Injuries by Month&quot;</span>)</span></code></pre></div>
<p>Fit a poisson regression in R using <code>glm(formula, data, family = poisson)</code>. But first, check whether the mean and variance of <code>injuries</code> are the same magnitude? If not, then use <code>family = quasipoisson</code>.</p>
<div class="sourceCode" id="cb185"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb185-1"><a href="generalized-linear-models-glm.html#cb185-1" tabindex="-1"></a><span class="fu">mean</span>(fire<span class="sc">$</span>injuries)</span>
<span id="cb185-2"><a href="generalized-linear-models-glm.html#cb185-2" tabindex="-1"></a><span class="fu">var</span>(fire<span class="sc">$</span>injuries)</span></code></pre></div>
<p>They are of the same magnitude, so fit the regression with <code>family = poisson</code>.</p>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="generalized-linear-models-glm.html#cb186-1" tabindex="-1"></a>m2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(injuries <span class="sc">~</span> mo, <span class="at">family =</span> poisson, <span class="at">data =</span> fire)</span>
<span id="cb186-2"><a href="generalized-linear-models-glm.html#cb186-2" tabindex="-1"></a><span class="fu">summary</span>(m2)</span></code></pre></div>
<p>The <em>predicted</em> value <span class="math inline">\(\hat{y}\)</span> is the estimated <strong>log</strong> of the response variable,</p>
<p><span class="math display">\[\hat{y} = X \hat{\beta} = \ln (\lambda).\]</span></p>
<p>Suppose <code>mo</code> is January (mo = <code>), then the log of</code>injuries` is <span class="math inline">\(\hat{y} = 0.323787\)</span>. Or, more intuitively, the expected count of injuries is <span class="math inline">\(\exp(0.323787) = 1.38\)</span></p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="generalized-linear-models-glm.html#cb187-1" tabindex="-1"></a><span class="fu">predict</span>(m2, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">mo=</span><span class="dv">1</span>))</span>
<span id="cb187-2"><a href="generalized-linear-models-glm.html#cb187-2" tabindex="-1"></a><span class="fu">predict</span>(m2, <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">mo=</span><span class="dv">1</span>), <span class="at">type =</span> <span class="st">&quot;response&quot;</span>)</span></code></pre></div>
<p>Here is a plot of the predicted counts in red.</p>
<div class="sourceCode" id="cb188"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb188-1"><a href="generalized-linear-models-glm.html#cb188-1" tabindex="-1"></a><span class="fu">augment</span>(m2, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb188-2"><a href="generalized-linear-models-glm.html#cb188-2" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> mo, <span class="at">y =</span> injuries)) <span class="sc">+</span></span>
<span id="cb188-3"><a href="generalized-linear-models-glm.html#cb188-3" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb188-4"><a href="generalized-linear-models-glm.html#cb188-4" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">y =</span> .fitted), <span class="at">color =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span> </span>
<span id="cb188-5"><a href="generalized-linear-models-glm.html#cb188-5" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">limits =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="cn">NA</span>)) <span class="sc">+</span></span>
<span id="cb188-6"><a href="generalized-linear-models-glm.html#cb188-6" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Month&quot;</span>,</span>
<span id="cb188-7"><a href="generalized-linear-models-glm.html#cb188-7" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Injuries&quot;</span>,</span>
<span id="cb188-8"><a href="generalized-linear-models-glm.html#cb188-8" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Poisson Fitted Line Plot&quot;</span>)</span></code></pre></div>
<p>Evaluate a logistic model fit with an analysis of deviance.</p>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="generalized-linear-models-glm.html#cb189-1" tabindex="-1"></a>(perf <span class="ot">&lt;-</span> <span class="fu">glance</span>(m2))</span>
<span id="cb189-2"><a href="generalized-linear-models-glm.html#cb189-2" tabindex="-1"></a>(pseudoR2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">-</span> perf<span class="sc">$</span>deviance <span class="sc">/</span> perf<span class="sc">$</span>null.deviance)</span></code></pre></div>
<p>The deviance of the null model (no regressors) is 139.9. The deviance of the full model is 132.2. The psuedo-R2 is very low at .05. How about the RMSE?</p>
<div class="sourceCode" id="cb190"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb190-1"><a href="generalized-linear-models-glm.html#cb190-1" tabindex="-1"></a><span class="fu">RMSE</span>(<span class="at">pred =</span> <span class="fu">predict</span>(m2, <span class="at">type =</span> <span class="st">&quot;response&quot;</span>), <span class="at">obs =</span> fire<span class="sc">$</span>injuries)</span></code></pre></div>
<p>The average prediction error is about 0.99. That’s almost as much as the variance of <code>injuries</code> - i.e., just predicting the mean of <code>injuries</code> would be almost as good! Use the <code>GainCurvePlot()</code> function to plot the gain curve.</p>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="generalized-linear-models-glm.html#cb191-1" tabindex="-1"></a><span class="fu">augment</span>(m2, <span class="at">type.predict =</span> <span class="st">&quot;response&quot;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb191-2"><a href="generalized-linear-models-glm.html#cb191-2" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> injuries, <span class="at">y =</span> .fitted)) <span class="sc">+</span></span>
<span id="cb191-3"><a href="generalized-linear-models-glm.html#cb191-3" tabindex="-1"></a>  <span class="fu">geom_point</span>() <span class="sc">+</span></span>
<span id="cb191-4"><a href="generalized-linear-models-glm.html#cb191-4" tabindex="-1"></a>  <span class="fu">geom_smooth</span>(<span class="at">method =</span><span class="st">&quot;lm&quot;</span>) <span class="sc">+</span></span>
<span id="cb191-5"><a href="generalized-linear-models-glm.html#cb191-5" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Actual&quot;</span>,</span>
<span id="cb191-6"><a href="generalized-linear-models-glm.html#cb191-6" tabindex="-1"></a>       <span class="at">y =</span> <span class="st">&quot;Predicted&quot;</span>,</span>
<span id="cb191-7"><a href="generalized-linear-models-glm.html#cb191-7" tabindex="-1"></a>       <span class="at">title =</span> <span class="st">&quot;Poisson Fitted vs Actual&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb192"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb192-1"><a href="generalized-linear-models-glm.html#cb192-1" tabindex="-1"></a><span class="fu">augment</span>(m2) <span class="sc">%&gt;%</span> <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span> </span>
<span id="cb192-2"><a href="generalized-linear-models-glm.html#cb192-2" tabindex="-1"></a>  <span class="fu">GainCurvePlot</span>(<span class="at">xvar =</span> <span class="st">&quot;.fitted&quot;</span>, <span class="at">truthVar =</span> <span class="st">&quot;injuries&quot;</span>, <span class="at">title =</span> <span class="st">&quot;Poisson Model&quot;</span>)</span></code></pre></div>
<p>It seems that <code>mo</code> was a poor predictor of <code>injuries</code>.</p>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="generalized-linear-models-glm.html#cb193-1" tabindex="-1"></a><span class="fu">library</span>(broom)  <span class="co"># for augment()</span></span>
<span id="cb193-2"><a href="generalized-linear-models-glm.html#cb193-2" tabindex="-1"></a><span class="fu">library</span>(WVPlots)  <span class="co"># for GainCurvePlot()</span></span>
<span id="cb193-3"><a href="generalized-linear-models-glm.html#cb193-3" tabindex="-1"></a><span class="fu">library</span>(caret)  <span class="co"># for RMSE()</span></span>
<span id="cb193-4"><a href="generalized-linear-models-glm.html#cb193-4" tabindex="-1"></a><span class="fu">library</span>(foreign)</span>
<span id="cb193-5"><a href="generalized-linear-models-glm.html#cb193-5" tabindex="-1"></a><span class="fu">library</span>(readr)</span>
<span id="cb193-6"><a href="generalized-linear-models-glm.html#cb193-6" tabindex="-1"></a><span class="fu">library</span>(gtsummary)</span>
<span id="cb193-7"><a href="generalized-linear-models-glm.html#cb193-7" tabindex="-1"></a><span class="fu">library</span>(nnet)</span>
<span id="cb193-8"><a href="generalized-linear-models-glm.html#cb193-8" tabindex="-1"></a><span class="fu">library</span>(VGAM)</span>
<span id="cb193-9"><a href="generalized-linear-models-glm.html#cb193-9" tabindex="-1"></a><span class="fu">library</span>(mlogit)</span>
<span id="cb193-10"><a href="generalized-linear-models-glm.html#cb193-10" tabindex="-1"></a><span class="fu">library</span>(ordinal)</span>
<span id="cb193-11"><a href="generalized-linear-models-glm.html#cb193-11" tabindex="-1"></a><span class="fu">library</span>(scales)</span>
<span id="cb193-12"><a href="generalized-linear-models-glm.html#cb193-12" tabindex="-1"></a><span class="fu">library</span>(glue)</span></code></pre></div>

</div>
</div>
</div>
<h3>References<a href="references-1.html#references-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-Agresti2013" class="csl-entry">
Agresti, Alan. 2013. <em>Categorical Data Analysis</em>. 3rd ed. Wiley. <a href="https://www.amazon.com/Categorical-Analysis-Wiley-Probability-Statistics-ebook-dp-B00CAYUFM2/dp/B00CAYUFM2/ref=mt_kindle?_encoding=UTF8&amp;me=&amp;qid=">https://www.amazon.com/Categorical-Analysis-Wiley-Probability-Statistics-ebook-dp-B00CAYUFM2/dp/B00CAYUFM2/ref=mt_kindle?_encoding=UTF8&amp;me=&amp;qid=</a>.
</div>
<div id="ref-Molner2020" class="csl-entry">
Molnar, Christoph. 2020. <em>Interpretable Machine Learning</em>. <a href="https://christophm.github.io/interpretable-ml-book/">https://christophm.github.io/interpretable-ml-book/</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="4">
<li id="fn4"><p>These notes are primarily from PSU’s <a href="https://online.stat.psu.edu/stat504">Analysis of Discrete Data</a> which uses Alan Agresti’s <strong>Categorical Data Analysis</strong> <span class="citation">(<a href="#ref-Agresti2013">Agresti 2013</a>)</span>. I also reviewed PSU’s <a href="https://newonlinecourses.science.psu.edu/stat501/lesson/15">Regression Methods</a>, DataCamp’s <a href="https://www.datacamp.com/courses/generalized-linear-models-in-r">Generalized Linear Models in R</a>, DataCamp’s <a href="https://www.datacamp.com/courses/multiple-and-logistic-regression">Multiple and Logistic Regression</a>, and <strong>Interpretable machine learning</strong> <span class="citation">(<a href="#ref-Molner2020">Molnar 2020</a>)</span>.<a href="generalized-linear-models-glm.html#fnref4" class="footnote-back">↩︎</a></p></li>
<li id="fn5"><p>The related probit regression link function is <span class="math inline">\(f(E(Y|X)) = \Phi^{-1}(E(Y|X)) = \Phi^{-1}(\pi)\)</span>. The difference between the logistic and probit link function is theoretical, and <a href="https://www.theanalysisfactor.com/the-difference-between-logistic-and-probit-regression/">the practical significance is slight</a>. You can safely ignore probit.<a href="generalized-linear-models-glm.html#fnref5" class="footnote-back">↩︎</a></p></li>
<li id="fn6"><p>Notes from <a href="https://machinelearningmastery.com/logistic-regression-with-maximum-likelihood-estimation/">Machine Learning Mastery</a>.<a href="generalized-linear-models-glm.html#fnref6" class="footnote-back">↩︎</a></p></li>
<li id="fn7"><p><a href="https://data.library.virginia.edu/understanding-deviance-residuals/">UVA</a> discusses the four types of residuals you can calculate from a binary logistic regression.<a href="generalized-linear-models-glm.html#fnref7" class="footnote-back">↩︎</a></p></li>
<li id="fn8"><p>See probability notes on the binomial distribution <a href="https://bookdown.org/mpfoley1973/probability/binomial.html">here</a><a href="generalized-linear-models-glm.html#fnref8" class="footnote-back">↩︎</a></p></li>
<li id="fn9"><p><a href="https://towardsdatascience.com/assumptions-of-logistic-regression-clearly-explained-44d85a22b290">This article</a> suggests using three standard deviations for an outliers threshold.<a href="generalized-linear-models-glm.html#fnref9" class="footnote-back">↩︎</a></p></li>
<li id="fn10"><p>Nice explanation <a href="https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/">here</a>. Sounds like you should use pseudo R2 for model comparison, not for reporting goodness of fit<a href="generalized-linear-models-glm.html#fnref10" class="footnote-back">↩︎</a></p></li>
<li id="fn11"><p>These notes rely on the course notes from <a href="https://online.stat.psu.edu/stat504/">PSU STAT 504, Analysis of Discrete Data</a> and <a href="https://stats.oarc.ucla.edu/r/dae/multinomial-logistic-regression/">UCLA</a>.<a href="generalized-linear-models-glm.html#fnref11" class="footnote-back">↩︎</a></p></li>
<li id="fn12"><p>Cook’s distance measures how much predicted values change when observation <em>i</em> is removed from the data. <a href="https://towardsdatascience.com/assumptions-of-logistic-regression-clearly-explained-44d85a22b290">This article</a> suggests using three standard deviations for an outliers threshold.<a href="generalized-linear-models-glm.html#fnref12" class="footnote-back">↩︎</a></p></li>
<li id="fn13"><p>Nice write-up <a href="https://stats.oarc.ucla.edu/other/mult-pkg/faq/general/faq-what-are-pseudo-r-squareds/">here</a>. Sounds like you should use pseudo R2 for model comparison, not for reporting goodness of fit<a href="generalized-linear-models-glm.html#fnref13" class="footnote-back">↩︎</a></p></li>
<li id="fn14"><p>These notes rely on <a href="https://data.library.virginia.edu/fitting-and-interpreting-a-proportional-odds-model/">UVA</a>, <a href="https://online.stat.psu.edu/stat504/">PSU</a>, <a href="https://statistics.laerd.com/spss-tutorials/ordinal-regression-using-spss-statistics.php">Laerd</a>, and the CLM package <a href="https://cran.r-project.org/web/packages/ordinal/vignettes/clm_article.pdf">article vignette</a><a href="generalized-linear-models-glm.html#fnref14" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="ordinary-least-squares.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="mixed-effects-models.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["supervised-ml.pdf", "supervised-ml.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
